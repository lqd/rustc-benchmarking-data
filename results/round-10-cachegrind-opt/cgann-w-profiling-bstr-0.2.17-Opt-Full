--------------------------------------------------------------------------------
I1 cache:         65536 B, 64 B, 4-way associative
D1 cache:         32768 B, 64 B, 8-way associative
LL cache:         67108864 B, 64 B, 64-way associative
Command:          /usr/home/liquid/.rustup/toolchains/w-profiling/bin/rustc --crate-name bstr --edition=2018 src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts,future-incompat --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -C embed-bitcode=no -C debuginfo=2 --cfg feature="default" --cfg feature="lazy_static" --cfg feature="regex-automata" --cfg feature="std" --cfg feature="unicode" -C metadata=b34f00dadd8dbc62 -C extra-filename=-b34f00dadd8dbc62 --out-dir /usr/home/liquid/tmp/.tmpYLLVrb/target/release/deps -L dependency=/usr/home/liquid/tmp/.tmpYLLVrb/target/release/deps --extern lazy_static=/usr/home/liquid/tmp/.tmpYLLVrb/target/release/deps/liblazy_static-acbc88c1e386fb33.rmeta --extern memchr=/usr/home/liquid/tmp/.tmpYLLVrb/target/release/deps/libmemchr-194a96c3e4619dee.rmeta --extern regex_automata=/usr/home/liquid/tmp/.tmpYLLVrb/target/release/deps/libregex_automata-cc94d52a2c56b816.rmeta -Adeprecated -Aunknown-lints -Zincremental-verify-ich
Data file:        results/cgout-w-profiling-bstr-0.2.17-Opt-Full
Events recorded:  Ir
Events shown:     Ir
Event sort order: Ir
Thresholds:       0.1
Include dirs:     
User annotated:   
Auto-annotation:  on

--------------------------------------------------------------------------------
Ir                     
--------------------------------------------------------------------------------
8,681,354,245 (100.0%)  PROGRAM TOTALS

--------------------------------------------------------------------------------
Ir                    file:function
--------------------------------------------------------------------------------
420,128,369 ( 4.84%)  ???:llvm::BitstreamCursor::readRecord(unsigned int, llvm::SmallVectorImpl<unsigned long>&, llvm::StringRef*)
252,553,187 ( 2.91%)  ./malloc/malloc.c:_int_free
228,926,570 ( 2.64%)  ./malloc/malloc.c:_int_malloc
155,834,809 ( 1.80%)  ./malloc/malloc.c:malloc
119,678,421 ( 1.38%)  ???:llvm::FPPassManager::runOnFunction(llvm::Function&)
 90,358,607 ( 1.04%)  ???:combineInstructionsOverFunction(llvm::Function&, llvm::InstCombineWorklist&, llvm::AAResults*, llvm::AssumptionCache&, llvm::TargetLibraryInfo&, llvm::TargetTransformInfo&, llvm::DominatorTree&, llvm::OptimizationRemarkEmitter&, llvm::BlockFrequencyInfo*, llvm::ProfileSummaryInfo*, unsigned int, llvm::LoopInfo*)
 87,562,687 ( 1.01%)  ???:llvm::InstCombinerImpl::run()
 80,760,119 ( 0.93%)  ./malloc/malloc.c:free
 72,693,592 ( 0.84%)  ???:llvm::AnalysisManager<llvm::Function>::getResultImpl(llvm::AnalysisKey*, llvm::Function&)
 69,996,330 ( 0.81%)  ???:llvm::AnalysisManager<llvm::Function>::invalidate(llvm::Function&, llvm::PreservedAnalyses const&)
 54,508,635 ( 0.63%)  ???:llvm::SelectionDAG::Combine(llvm::CombineLevel, llvm::AAResults*, llvm::CodeGenOpt::Level)
 52,600,982 ( 0.61%)  ./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:__memcpy_avx_unaligned_erms
 45,654,895 ( 0.53%)  ???:llvm::AttributeList::addAttributes(llvm::LLVMContext&, unsigned int, llvm::AttrBuilder const&) const
 42,785,040 ( 0.49%)  ./string/../sysdeps/x86_64/multiarch/memcmp-avx2-movbe.S:__memcmp_avx2_movbe
 42,583,991 ( 0.49%)  ???:(anonymous namespace)::Verifier::visitMDNode(llvm::MDNode const&, (anonymous namespace)::Verifier::AreDebugLocsAllowed)
 40,827,652 ( 0.47%)  ???:llvm::MetadataTracking::track(void*, llvm::Metadata&, llvm::PointerUnion<llvm::MetadataAsValue*, llvm::Metadata*>)
 40,239,216 ( 0.46%)  ???:computeKnownBits(llvm::Value const*, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&) [clone .llvm.15619146473165121143]
 37,034,502 ( 0.43%)  ???:runCVP(llvm::Module&) [clone .llvm.11785992503873176614]
 36,704,804 ( 0.42%)  ???:llvm::TargetLibraryInfoImpl::getLibFunc(llvm::Function const&, llvm::LibFunc&) const
 36,460,184 ( 0.42%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::CalculateFromScratch(llvm::DominatorTreeBase<llvm::BasicBlock, false>&, llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::BatchUpdateInfo*)
 36,397,966 ( 0.42%)  ???:llvm::ValueHandleBase::AddToUseList()
 35,486,598 ( 0.41%)  ???:(anonymous namespace)::ModuleBitcodeWriter::writeConstants(unsigned int, unsigned int, bool)
 34,795,092 ( 0.40%)  ???:(anonymous namespace)::Verifier::visitCallBase(llvm::CallBase&)
 33,761,912 ( 0.39%)  ./malloc/malloc.c:malloc_consolidate
 33,305,588 ( 0.38%)  ???:llvm::removeUnreachableBlocks(llvm::Function&, llvm::DomTreeUpdater*, llvm::MemorySSAUpdater*)
 32,511,308 ( 0.37%)  ???:llvm::SimplifyInstruction(llvm::Instruction*, llvm::SimplifyQuery const&, llvm::OptimizationRemarkEmitter*)
 32,291,408 ( 0.37%)  ???:(anonymous namespace)::Verifier::visitInstruction(llvm::Instruction&)
 32,201,319 ( 0.37%)  ???:llvm::InlineFunction(llvm::CallBase&, llvm::InlineFunctionInfo&, llvm::AAResults*, bool, llvm::Function*)
 31,414,504 ( 0.36%)  ???:llvm::SHA1::hashBlock()
 31,290,266 ( 0.36%)  ???:llvm::DataLayout::getAlignment(llvm::Type*, bool) const
 31,065,611 ( 0.36%)  ???:llvm::DataLayout::getTypeSizeInBits(llvm::Type*) const
 29,758,639 ( 0.34%)  ???:bool llvm::DenseMapBase<llvm::DenseMap<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*, llvm::DenseMapInfo<(anonymous namespace)::SimpleValue>, llvm::detail::DenseMapPair<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*> >, (anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*, llvm::DenseMapInfo<(anonymous namespace)::SimpleValue>, llvm::detail::DenseMapPair<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*> >::LookupBucketFor<(anonymous namespace)::SimpleValue>((anonymous namespace)::SimpleValue const&, llvm::detail::DenseMapPair<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*> const*&) const
 28,763,846 ( 0.33%)  ???:llvm::CallBase::getArgOperand(unsigned int) const
 27,624,998 ( 0.32%)  ???:computeKnownBitsFromOperator(llvm::Operator const*, llvm::APInt const&, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&)
 27,518,335 ( 0.32%)  ???:llvm::InstCombinerImpl::visitCallInst(llvm::CallInst&)
 27,454,007 ( 0.32%)  ???:llvm::ConstantDataSequential::getImpl(llvm::StringRef, llvm::Type*)
 26,321,222 ( 0.30%)  ???:void llvm::BitstreamWriter::EmitRecordWithAbbrevImpl<unsigned long>(unsigned int, llvm::ArrayRef<unsigned long>, llvm::StringRef, llvm::Optional<unsigned int>)
 25,588,212 ( 0.29%)  ???:(anonymous namespace)::EarlyCSE::run() [clone .llvm.7062997131228810369]
 25,471,844 ( 0.29%)  ???:llvm::isNonEscapingLocalObject(llvm::Value const*, llvm::SmallDenseMap<llvm::Value const*, bool, 8u, llvm::DenseMapInfo<llvm::Value const*>, llvm::detail::DenseMapPair<llvm::Value const*, bool> >*)
 25,189,893 ( 0.29%)  ???:computeKnownBits(llvm::Value const*, llvm::APInt const&, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&)
 24,873,488 ( 0.29%)  ./malloc/malloc.c:unlink_chunk.constprop.0
 24,742,872 ( 0.29%)  /tmp/gcc-build/x86_64-unknown-linux-gnu/libstdc++-v3/libsupc++/../../../../gcc-5.5.0/libstdc++-v3/libsupc++/new_op.cc:operator new(unsigned long)
 24,167,771 ( 0.28%)  ???:(anonymous namespace)::LazyValueInfoImpl::solve() [clone .llvm.4316243980339171764]
 24,153,276 ( 0.28%)  ???:llvm::AttributeList::get(llvm::LLVMContext&, llvm::ArrayRef<llvm::AttributeList>)
 23,491,339 ( 0.27%)  ./string/../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:__memset_avx2_erms
 23,280,515 ( 0.27%)  ???:(anonymous namespace)::MachineCopyPropagation::runOnMachineFunction(llvm::MachineFunction&)
 23,108,346 ( 0.27%)  ???:(anonymous namespace)::PruningFunctionCloner::CloneBlock(llvm::BasicBlock const*, llvm::ilist_iterator<llvm::ilist_detail::node_options<llvm::Instruction, true, false, void>, false, true>, std::vector<llvm::BasicBlock const*, std::allocator<llvm::BasicBlock const*> >&)
 22,320,946 ( 0.26%)  ???:llvm::PMDataManager::verifyPreservedAnalysis(llvm::Pass*)
 22,293,309 ( 0.26%)  ???:SimplifyICmpInst(unsigned int, llvm::Value*, llvm::Value*, llvm::SimplifyQuery const&, unsigned int) [clone .llvm.1619516508949622737]
 21,617,243 ( 0.25%)  ???:llvm::LiveVariables::runOnBlock(llvm::MachineBasicBlock*, unsigned int)
 21,539,931 ( 0.25%)  ???:llvm::InstCombinerImpl::visitICmpInst(llvm::ICmpInst&)
 21,014,114 ( 0.24%)  ???:computeKnownBitsFromAssume(llvm::Value const*, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&)
 20,982,424 ( 0.24%)  ???:llvm::coro::declaresIntrinsics(llvm::Module const&, std::initializer_list<llvm::StringRef>)
 20,575,681 ( 0.24%)  ???:llvm::SmallPtrSetImplBase::insert_imp_big(void const*)
 20,325,866 ( 0.23%)  ???:llvm::MemorySSA::buildMemorySSA(llvm::BatchAAResults&)
 19,901,876 ( 0.23%)  ???:llvm::BasicAAResult::alias(llvm::MemoryLocation const&, llvm::MemoryLocation const&, llvm::AAQueryInfo&)
 19,642,794 ( 0.23%)  ???:llvm::MachineInstr::addOperand(llvm::MachineFunction&, llvm::MachineOperand const&)
 19,351,661 ( 0.22%)  ???:updateCGAndAnalysisManagerForPass(llvm::LazyCallGraph&, llvm::LazyCallGraph::SCC&, llvm::LazyCallGraph::Node&, llvm::AnalysisManager<llvm::LazyCallGraph::SCC, llvm::LazyCallGraph&>&, llvm::CGSCCUpdateResult&, llvm::AnalysisManager<llvm::Function>&, bool) [clone .llvm.5426518467876156712]
 19,347,271 ( 0.22%)  ./string/../sysdeps/x86_64/multiarch/strcmp-avx2.S:__strncmp_avx2
 18,060,236 ( 0.21%)  ???:(anonymous namespace)::LazyValueInfoImpl::getEdgeValue(llvm::Value*, llvm::BasicBlock*, llvm::BasicBlock*, llvm::Instruction*) [clone .llvm.4316243980339171764]
 17,833,630 ( 0.21%)  ???:llvm::AttributeSetNode::get(llvm::LLVMContext&, llvm::AttrBuilder const&)
 17,680,738 ( 0.20%)  ???:runImpl(llvm::Function&, llvm::LazyValueInfo*, llvm::DominatorTree*, llvm::SimplifyQuery const&) [clone .llvm.16011871802505272439]
 17,588,925 ( 0.20%)  ???:llvm::detail::PassModel<llvm::Function, llvm::PassManager<llvm::Function, llvm::AnalysisManager<llvm::Function>>, llvm::PreservedAnalyses, llvm::AnalysisManager<llvm::Function>>::run(llvm::Function&, llvm::AnalysisManager<llvm::Function>&)
 17,389,579 ( 0.20%)  ???:(anonymous namespace)::AggressiveDeadCodeElimination::performDeadCodeElimination()
 17,229,776 ( 0.20%)  ???:llvm::ScalarEvolution::getAddExpr(llvm::SmallVectorImpl<llvm::SCEV const*>&, llvm::SCEV::NoWrapFlags, unsigned int)
 17,033,364 ( 0.20%)  ???:llvm::DemandedBits::isInstructionDead(llvm::Instruction*)
 16,526,374 ( 0.19%)  ???:llvm::simplifyCFG(llvm::BasicBlock*, llvm::TargetTransformInfo const&, llvm::DomTreeUpdater*, llvm::SimplifyCFGOptions const&, llvm::ArrayRef<llvm::WeakVH>)
 16,442,212 ( 0.19%)  ???:(anonymous namespace)::BitcodeReader::parseFunctionBody(llvm::Function*)
 15,607,769 ( 0.18%)  ???:llvm::LivePhysRegs::stepBackward(llvm::MachineInstr const&)
 15,103,930 ( 0.17%)  ???:llvm::SROA::runOnAlloca(llvm::AllocaInst&)
 14,901,277 ( 0.17%)  /usr/home/liquid/rust/worktree-benchmarking/library/core/src/ascii.rs:core::ascii::escape_default
 14,755,730 ( 0.17%)  ???:(anonymous namespace)::DeadMachineInstructionElim::eliminateDeadMI(llvm::MachineFunction&)
 14,554,863 ( 0.17%)  ???:llvm::raw_svector_ostream::write_impl(char const*, unsigned long)
 14,476,236 ( 0.17%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::runSemiNCA(llvm::DominatorTreeBase<llvm::BasicBlock, false>&, unsigned int)
 14,257,350 ( 0.16%)  ???:llvm::FoldingSetBase::FindNodeOrInsertPos(llvm::FoldingSetNodeID const&, void*&, llvm::FoldingSetBase::FoldingSetInfo const&)
 14,252,534 ( 0.16%)  ???:llvm::SelectionDAGISel::SelectCodeCommon(llvm::SDNode*, unsigned char const*, unsigned int)
 14,062,273 ( 0.16%)  ???:llvm::MDNode::MDNode(llvm::LLVMContext&, unsigned int, llvm::Metadata::StorageType, llvm::ArrayRef<llvm::Metadata*>, llvm::ArrayRef<llvm::Metadata*>)
 13,800,343 ( 0.16%)  ./string/../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:__memset_avx2_unaligned_erms
 13,743,879 ( 0.16%)  ???:llvm::Type::getPrimitiveSizeInBits() const
 13,741,449 ( 0.16%)  ???:(anonymous namespace)::ModuleBitcodeWriter::writeInstruction(llvm::Instruction const&, unsigned int, llvm::SmallVectorImpl<unsigned int>&)
 13,575,500 ( 0.16%)  ???:llvm::GVN::processBlock(llvm::BasicBlock*)
 13,571,708 ( 0.16%)  ???:(anonymous namespace)::eliminateDeadStores(llvm::Function&, llvm::AAResults&, llvm::MemorySSA&, llvm::DominatorTree&, llvm::PostDominatorTree&, llvm::TargetLibraryInfo const&, llvm::LoopInfo const&) [clone .llvm.5769264623867638418]
 13,385,536 ( 0.15%)  ./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:__memcpy_sse2_unaligned_erms
 13,341,619 ( 0.15%)  ???:(anonymous namespace)::Verifier::verifyFunctionAttrs(llvm::FunctionType*, llvm::AttributeList, llvm::Value const*, bool)
 13,334,386 ( 0.15%)  ???:(anonymous namespace)::SimplifyCFGOpt::simplifyCondBranch(llvm::BranchInst*, llvm::IRBuilder<llvm::ConstantFolder, llvm::IRBuilderDefaultInserter>&)
 13,257,536 ( 0.15%)  /usr/home/liquid/rust/worktree-benchmarking/library/core/src/ascii.rs:<core::ascii::EscapeDefault as core::iter::traits::iterator::Iterator>::next
 13,198,189 ( 0.15%)  /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs:<hashbrown::map::RawEntryBuilderMut<rustc_middle::ty::context::Interned<rustc_middle::ty::TyS>, (), core::hash::BuildHasherDefault<rustc_hash::FxHasher>>>::from_hash::<hashbrown::map::equivalent<rustc_middle::ty::sty::TyKind, rustc_middle::ty::context::Interned<rustc_middle::ty::TyS>>::{closure#0}>
 13,055,885 ( 0.15%)  ???:llvm::LLVMContextImpl::~LLVMContextImpl()
 12,939,065 ( 0.15%)  ???:(anonymous namespace)::BitcodeReader::parseConstants()
 12,838,540 ( 0.15%)  ???:llvm::ReassociatePass::BuildRankMap(llvm::Function&, llvm::ReversePostOrderTraversal<llvm::Function*, llvm::GraphTraits<llvm::Function*> >&)
 12,822,997 ( 0.15%)  ???:llvm::AttributeList::addAttribute(llvm::LLVMContext&, unsigned int, llvm::Attribute::AttrKind) const
 12,768,893 ( 0.15%)  ???:llvm::SimplifyGEPInst(llvm::Type*, llvm::ArrayRef<llvm::Value*>, llvm::SimplifyQuery const&)
 12,640,633 ( 0.15%)  ???:llvm::TargetTransformInfo::Model<llvm::X86TTIImpl>::getUserCost(llvm::User const*, llvm::ArrayRef<llvm::Value const*>, llvm::TargetTransformInfo::TargetCostKind)
 12,578,469 ( 0.14%)  ???:llvm::DILocation::getImpl(llvm::LLVMContext&, unsigned int, unsigned int, llvm::Metadata*, llvm::Metadata*, bool, llvm::Metadata::StorageType, bool)
 12,550,742 ( 0.14%)  ???:???
 12,541,978 ( 0.14%)  ???:llvm::FindFunctionBackedges(llvm::Function const&, llvm::SmallVectorImpl<std::pair<llvm::BasicBlock const*, llvm::BasicBlock const*> >&)
 12,529,008 ( 0.14%)  ???:llvm::hashing::detail::hash_combine_recursive_helper::combine(unsigned long, char*, char*)
 12,500,353 ( 0.14%)  ???:isKnownNonZero(llvm::Value const*, llvm::APInt const&, unsigned int, (anonymous namespace)::Query const&) [clone .llvm.15619146473165121143]
 12,122,447 ( 0.14%)  ???:llvm::LiveVariables::HandleRegMask(llvm::MachineOperand const&)
 12,085,383 ( 0.14%)  ???:(anonymous namespace)::Mapper::mapValue(llvm::Value const*) [clone .llvm.12166235158543170009]
 11,816,989 ( 0.14%)  ???:(anonymous namespace)::CVPLatticeFunc::ComputeInstructionState(llvm::Instruction&, llvm::DenseMap<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > >, (anonymous namespace)::CVPLatticeVal, llvm::DenseMapInfo<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > > >, llvm::detail::DenseMapPair<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > >, (anonymous namespace)::CVPLatticeVal> >&, llvm::SparseSolver<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > >, (anonymous namespace)::CVPLatticeVal, llvm::LatticeKeyInfo<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > > > >&)
 11,804,268 ( 0.14%)  ./string/../sysdeps/x86_64/multiarch/strlen-avx2.S:__strlen_avx2
 11,557,207 ( 0.13%)  ???:llvm::MCObjectStreamer::emitBytes(llvm::StringRef)
 11,538,529 ( 0.13%)  ???:llvm::Value::stripAndAccumulateConstantOffsets(llvm::DataLayout const&, llvm::APInt&, bool, llvm::function_ref<bool (llvm::Value&, llvm::APInt&)>) const
 11,480,774 ( 0.13%)  ???:llvm::Intrinsic::getDeclaration(llvm::Module*, unsigned int, llvm::ArrayRef<llvm::Type*>)
 11,438,240 ( 0.13%)  /usr/home/liquid/rust/worktree-benchmarking/library/alloc/src/vec/mod.rs:<core::iter::adapters::map::Map<core::slice::iter::Iter<u8>, <u8 as core::clone::Clone>::clone> as core::iter::traits::iterator::Iterator>::fold::<(), core::iter::adapters::map::map_fold<u8, core::ascii::EscapeDefault, (), core::ascii::escape_default, <core::iter::adapters::flatten::FlattenCompat<_, _> as core::iter::traits::iterator::Iterator>::fold::flatten<core::ascii::EscapeDefault, (), core::iter::adapters::map::map_fold<u8, char, (), <u8 as core::convert::Into<char>>::into, core::iter::traits::iterator::Iterator::for_each::call<char, <alloc::string::String as core::iter::traits::collect::Extend<char>>::extend<core::iter::adapters::map::Map<core::iter::adapters::flatten::FlatMap<core::iter::adapters::cloned::Cloned<core::slice::iter::Iter<u8>>, core::ascii::EscapeDefault, core::ascii::escape_default>, <u8 as core::convert::Into<char>>::into>>::{closure#0}>::{closure#0}>::{closure#0}>::{closure#0}>::{closure#0}>
 11,416,964 ( 0.13%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, true> >::CalculateFromScratch(llvm::DominatorTreeBase<llvm::BasicBlock, true>&, llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, true> >::BatchUpdateInfo*)
 11,272,293 ( 0.13%)  ???:void std::__introsort_loop<llvm::ValueEnumerator::MDIndex*, long, __gnu_cxx::__ops::_Iter_comp_iter<llvm::ValueEnumerator::organizeMetadata()::$_3> >(llvm::ValueEnumerator::MDIndex*, llvm::ValueEnumerator::MDIndex*, long, __gnu_cxx::__ops::_Iter_comp_iter<llvm::ValueEnumerator::organizeMetadata()::$_3>)
 11,063,064 ( 0.13%)  /usr/home/liquid/rust/worktree-benchmarking/library/core/src/option.rs:<rustc_const_eval::interpret::intern::InternVisitor<rustc_const_eval::const_eval::machine::CompileTimeInterpreter> as rustc_const_eval::interpret::visitor::ValueVisitor<rustc_const_eval::const_eval::machine::CompileTimeInterpreter>>::walk_aggregate::<core::iter::adapters::map::Map<core::iter::adapters::map::Map<core::ops::range::Range<u64>, <rustc_const_eval::interpret::eval_context::InterpCx<rustc_const_eval::const_eval::machine::CompileTimeInterpreter>>::mplace_array_fields::{closure#0}>, <rustc_const_eval::interpret::intern::InternVisitor<rustc_const_eval::const_eval::machine::CompileTimeInterpreter> as rustc_const_eval::interpret::visitor::ValueVisitor<rustc_const_eval::const_eval::machine::CompileTimeInterpreter>>::walk_value::{closure#1}>>
 10,899,458 ( 0.13%)  /usr/home/liquid/rust/worktree-benchmarking/library/core/src/iter/traits/iterator.rs:<core::iter::adapters::map::Map<core::slice::iter::Iter<u8>, <u8 as core::clone::Clone>::clone> as core::iter::traits::iterator::Iterator>::fold::<(), core::iter::adapters::map::map_fold<u8, core::ascii::EscapeDefault, (), core::ascii::escape_default, <core::iter::adapters::flatten::FlattenCompat<_, _> as core::iter::traits::iterator::Iterator>::fold::flatten<core::ascii::EscapeDefault, (), core::iter::adapters::map::map_fold<u8, char, (), <u8 as core::convert::Into<char>>::into, core::iter::traits::iterator::Iterator::for_each::call<char, <alloc::string::String as core::iter::traits::collect::Extend<char>>::extend<core::iter::adapters::map::Map<core::iter::adapters::flatten::FlatMap<core::iter::adapters::cloned::Cloned<core::slice::iter::Iter<u8>>, core::ascii::EscapeDefault, core::ascii::escape_default>, <u8 as core::convert::Into<char>>::into>>::{closure#0}>::{closure#0}>::{closure#0}>::{closure#0}>::{closure#0}>
 10,791,758 ( 0.12%)  ???:llvm::MD5::final(llvm::MD5::MD5Result&)
 10,636,642 ( 0.12%)  /usr/home/liquid/rust/worktree-benchmarking/compiler/rustc_const_eval/src/interpret/intern.rs:<rustc_const_eval::interpret::intern::InternVisitor<rustc_const_eval::const_eval::machine::CompileTimeInterpreter> as rustc_const_eval::interpret::visitor::ValueVisitor<rustc_const_eval::const_eval::machine::CompileTimeInterpreter>>::visit_value
 10,607,177 ( 0.12%)  ???:llvm::InstCombinerImpl::visitLoadInst(llvm::LoadInst&)
 10,484,311 ( 0.12%)  ???:llvm::ScalarEvolution::getSCEV(llvm::Value*)
 10,422,979 ( 0.12%)  ./malloc/malloc.c:realloc
 10,391,045 ( 0.12%)  ???:llvm::InstCombinerImpl::SimplifyDemandedUseBits(llvm::Value*, llvm::APInt, llvm::KnownBits&, unsigned int, llvm::Instruction*)
 10,355,698 ( 0.12%)  ???:llvm::MCExpr::evaluateAsRelocatableImpl(llvm::MCValue&, llvm::MCAssembler const*, llvm::MCAsmLayout const*, llvm::MCFixup const*, llvm::DenseMap<llvm::MCSection const*, unsigned long, llvm::DenseMapInfo<llvm::MCSection const*>, llvm::detail::DenseMapPair<llvm::MCSection const*, unsigned long> > const*, bool) const
 10,355,692 ( 0.12%)  ???:llvm::SCCPInstVisitor::solve()
 10,309,636 ( 0.12%)  ./elf/dl-lookup.c:_dl_lookup_symbol_x
 10,283,344 ( 0.12%)  ???:llvm::PassRegistry::enumerateWith(llvm::PassRegistrationListener*)
 10,250,584 ( 0.12%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, true> >::FindRoots(llvm::DominatorTreeBase<llvm::BasicBlock, true> const&, llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, true> >::BatchUpdateInfo*)
 10,193,996 ( 0.12%)  ???:bool llvm::DenseMapBase<llvm::DenseMap<llvm::DILocation*, llvm::detail::DenseSetEmpty, llvm::MDNodeInfo<llvm::DILocation>, llvm::detail::DenseSetPair<llvm::DILocation*> >, llvm::DILocation*, llvm::detail::DenseSetEmpty, llvm::MDNodeInfo<llvm::DILocation>, llvm::detail::DenseSetPair<llvm::DILocation*> >::LookupBucketFor<llvm::DILocation*>(llvm::DILocation* const&, llvm::detail::DenseSetPair<llvm::DILocation*> const*&) const
 10,123,071 ( 0.12%)  ???:llvm::ReplaceableMetadataImpl::replaceAllUsesWith(llvm::Metadata*)
  9,888,113 ( 0.11%)  ???:llvm::Type::isSizedDerivedType(llvm::SmallPtrSetImpl<llvm::Type*>*) const
  9,783,552 ( 0.11%)  ???:llvm::PMDataManager::removeNotPreservedAnalysis(llvm::Pass*)
  9,683,211 ( 0.11%)  ???:llvm::MDString::get(llvm::LLVMContext&, llvm::StringRef)
  9,557,716 ( 0.11%)  ???:llvm::ConstantRange::makeExactICmpRegion(llvm::CmpInst::Predicate, llvm::APInt const&)
  9,513,722 ( 0.11%)  ???:llvm::InstCombinerImpl::visitBitCast(llvm::BitCastInst&)
  9,456,821 ( 0.11%)  ???:llvm::ScalarEvolution::getRangeRef(llvm::SCEV const*, llvm::ScalarEvolution::RangeSignHint)
  9,456,282 ( 0.11%)  ./stdlib/msort.c:msort_with_tmp.part.0
  9,447,597 ( 0.11%)  ???:llvm::TargetLoweringBase::getTypeConversion(llvm::LLVMContext&, llvm::EVT) const
  9,415,608 ( 0.11%)  ???:llvm::JumpThreadingPass::runImpl(llvm::Function&, llvm::TargetLibraryInfo*, llvm::LazyValueInfo*, llvm::AAResults*, llvm::DomTreeUpdater*, bool, std::unique_ptr<llvm::BlockFrequencyInfo, std::default_delete<llvm::BlockFrequencyInfo> >, std::unique_ptr<llvm::BranchProbabilityInfo, std::default_delete<llvm::BranchProbabilityInfo> >)
  9,283,954 ( 0.11%)  ???:llvm::MDTuple::getImpl(llvm::LLVMContext&, llvm::ArrayRef<llvm::Metadata*>, llvm::Metadata::StorageType, bool)
  9,226,687 ( 0.11%)  ???:llvm::SROA::splitAlloca(llvm::AllocaInst&, llvm::sroa::AllocaSlices&)
  9,200,832 ( 0.11%)  ???:llvm::DIExpression::ExprOperand::getSize() const
  9,194,516 ( 0.11%)  ???:llvm::ScheduleDAGSDNodes::BuildSchedUnits()
  9,116,879 ( 0.11%)  ???:llvm::MetadataAsValue::get(llvm::LLVMContext&, llvm::Metadata*)
  9,060,649 ( 0.10%)  ???:(anonymous namespace)::LazyValueInfoImpl::getValueInBlock(llvm::Value*, llvm::BasicBlock*, llvm::Instruction*) [clone .llvm.4316243980339171764]
  8,922,517 ( 0.10%)  ???:(anonymous namespace)::BitcodeReader::parseModule(unsigned long, bool, llvm::function_ref<llvm::Optional<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > (llvm::StringRef)>)
  8,871,448 ( 0.10%)  ???:llvm::FoldingSetNodeID::AddInteger(unsigned int)
  8,789,254 ( 0.10%)  ???:llvm::InstCombinerImpl::visitStoreInst(llvm::StoreInst&)

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/library/core/src/option.rs
--------------------------------------------------------------------------------
Ir                  

-- line 504 ----------------------------------------
         .           use crate::panicking::{panic, panic_str};
         .           use crate::pin::Pin;
         .           use crate::{
         .               convert, hint, mem,
         .               ops::{self, ControlFlow, Deref, DerefMut},
         .           };
         .           
         .           /// The `Option` type. See [the module level documentation](self) for more.
 2,589,042 ( 0.03%)  #[derive(Copy, PartialEq, PartialOrd, Eq, Ord, Debug, Hash)]
         .           #[rustc_diagnostic_item = "Option"]
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           pub enum Option<T> {
         .               /// No value.
         .               #[lang = "None"]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               None,
         .               /// Some value of type `T`.
         .               #[lang = "Some"]
         .               #[stable(feature = "rust1", since = "1.0.0")]
     4,467 ( 0.00%)      Some(#[stable(feature = "rust1", since = "1.0.0")] T),
         .           }
         .           
         .           /////////////////////////////////////////////////////////////////////////////
         .           // Type implementation
         .           /////////////////////////////////////////////////////////////////////////////
         .           
         .           impl<T> Option<T> {
         .               /////////////////////////////////////////////////////////////////////////
-- line 531 ----------------------------------------
-- line 543 ----------------------------------------
         .               /// let x: Option<u32> = None;
         .               /// assert_eq!(x.is_some(), false);
         .               /// ```
         .               #[must_use = "if you intended to assert that this has a value, consider `.unwrap()` instead"]
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_stable(feature = "const_option", since = "1.48.0")]
         .               pub const fn is_some(&self) -> bool {
 2,066,350 ( 0.02%)          matches!(*self, Some(_))
         .               }
         .           
         .               /// Returns `true` if the option is a [`Some`] wrapping a value matching the predicate.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// #![feature(is_some_with)]
-- line 559 ----------------------------------------
-- line 616 ----------------------------------------
         .               /// // then consume *that* with `map`, leaving `text` on the stack.
         .               /// let text_length: Option<usize> = text.as_ref().map(|s| s.len());
         .               /// println!("still can print text: {:?}", text);
         .               /// ```
         .               #[inline]
         .               #[rustc_const_stable(feature = "const_option", since = "1.48.0")]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub const fn as_ref(&self) -> Option<&T> {
 3,548,447 ( 0.04%)          match *self {
         .                       Some(ref x) => Some(x),
         .                       None => None,
         .                   }
         .               }
         .           
         .               /// Converts from `&mut Option<T>` to `Option<&mut T>`.
         .               ///
         .               /// # Examples
-- line 632 ----------------------------------------
-- line 638 ----------------------------------------
         .               ///     None => {},
         .               /// }
         .               /// assert_eq!(x, Some(42));
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option", issue = "67441")]
         .               pub const fn as_mut(&mut self) -> Option<&mut T> {
   840,644 ( 0.01%)          match *self {
         .                       Some(ref mut x) => Some(x),
         .                       None => None,
         .                   }
         .               }
         .           
         .               /// Converts from <code>[Pin]<[&]Option\<T>></code> to <code>Option<[Pin]<[&]T>></code>.
         .               ///
         .               /// [&]: reference "shared reference"
-- line 654 ----------------------------------------
-- line 705 ----------------------------------------
         .               /// let x: Option<&str> = None;
         .               /// x.expect("fruits are healthy"); // panics with `fruits are healthy`
         .               /// ```
         .               #[inline]
         .               #[track_caller]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option", issue = "67441")]
         .               pub const fn expect(self, msg: &str) -> T {
 1,042,034 ( 0.01%)          match self {
   494,831 ( 0.01%)              Some(val) => val,
         .                       None => expect_failed(msg),
         .                   }
         .               }
         .           
         .               /// Returns the contained [`Some`] value, consuming the `self` value.
         .               ///
         .               /// Because this function may panic, its use is generally discouraged.
         .               /// Instead, prefer to use pattern matching and handle the [`None`]
-- line 722 ----------------------------------------
-- line 742 ----------------------------------------
         .               /// let x: Option<&str> = None;
         .               /// assert_eq!(x.unwrap(), "air"); // fails
         .               /// ```
         .               #[inline]
         .               #[track_caller]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option", issue = "67441")]
         .               pub const fn unwrap(self) -> T {
 2,351,735 ( 0.03%)          match self {
   516,975 ( 0.01%)              Some(val) => val,
         .                       None => panic("called `Option::unwrap()` on a `None` value"),
         .                   }
         .               }
         .           
         .               /// Returns the contained [`Some`] value or a provided default.
         .               ///
         .               /// Arguments passed to `unwrap_or` are eagerly evaluated; if you are passing
         .               /// the result of a function call, it is recommended to use [`unwrap_or_else`],
-- line 759 ----------------------------------------
-- line 769 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn unwrap_or(self, default: T) -> T
         .               where
         .                   T: ~const Drop,
         .               {
   774,726 ( 0.01%)          match self {
         .                       Some(x) => x,
     3,508 ( 0.00%)              None => default,
         .                   }
    28,023 ( 0.00%)      }
         .           
         .               /// Returns the contained [`Some`] value or computes it from a closure.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// let k = 10;
         .               /// assert_eq!(Some(4).unwrap_or_else(|| 2 * k), 4);
         .               /// assert_eq!(None.unwrap_or_else(|| 2 * k), 20);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
       402 ( 0.00%)      pub const fn unwrap_or_else<F>(self, f: F) -> T
         .               where
         .                   F: ~const FnOnce() -> T,
         .                   F: ~const Drop,
         .               {
   991,222 ( 0.01%)          match self {
    91,052 ( 0.00%)              Some(x) => x,
     5,198 ( 0.00%)              None => f(),
         .                   }
     3,456 ( 0.00%)      }
         .           
         .               /// Returns the contained [`Some`] value or a default.
         .               ///
         .               /// Consumes the `self` argument then, if [`Some`], returns the contained
         .               /// value, otherwise if [`None`], returns the [default value] for that
         .               /// type.
         .               ///
         .               /// # Examples
-- line 812 ----------------------------------------
-- line 831 ----------------------------------------
         .               /// [`FromStr`]: crate::str::FromStr
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn unwrap_or_default(self) -> T
         .               where
         .                   T: ~const Default,
         .               {
     4,877 ( 0.00%)          match self {
     5,515 ( 0.00%)              Some(x) => x,
         .                       None => Default::default(),
         .                   }
       207 ( 0.00%)      }
         .           
         .               /// Returns the contained [`Some`] value, consuming the `self` value,
         .               /// without checking that the value is not [`None`].
         .               ///
         .               /// # Safety
         .               ///
         .               /// Calling this method on [`None`] is *[undefined behavior]*.
         .               ///
-- line 851 ----------------------------------------
-- line 892 ----------------------------------------
         .               /// // `Option::map` takes self *by value*, consuming `maybe_some_string`
         .               /// let maybe_some_len = maybe_some_string.map(|s| s.len());
         .               ///
         .               /// assert_eq!(maybe_some_len, Some(13));
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
     3,822 ( 0.00%)      pub const fn map<U, F>(self, f: F) -> Option<U>
         .               where
         .                   F: ~const FnOnce(T) -> U,
         .                   F: ~const Drop,
         .               {
 3,030,757 ( 0.03%)          match self {
11,712,367 ( 0.13%)              Some(x) => Some(f(x)),
    72,861 ( 0.00%)              None => None,
         .                   }
    89,836 ( 0.00%)      }
         .           
         .               /// Calls the provided closure with a reference to the contained value (if [`Some`]).
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// #![feature(result_option_inspect)]
         .               ///
-- line 917 ----------------------------------------
-- line 960 ----------------------------------------
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn map_or<U, F>(self, default: U, f: F) -> U
         .               where
         .                   F: ~const FnOnce(T) -> U,
         .                   F: ~const Drop,
         .                   U: ~const Drop,
         .               {
   555,608 ( 0.01%)          match self {
    55,948 ( 0.00%)              Some(t) => f(t),
     5,671 ( 0.00%)              None => default,
         .                   }
         .               }
         .           
         .               /// Computes a default function result (if none), or
         .               /// applies a different function to the contained value (if any).
         .               ///
         .               /// # Examples
         .               ///
-- line 978 ----------------------------------------
-- line 990 ----------------------------------------
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn map_or_else<U, D, F>(self, default: D, f: F) -> U
         .               where
         .                   D: ~const FnOnce() -> U,
         .                   D: ~const Drop,
         .                   F: ~const FnOnce(T) -> U,
         .                   F: ~const Drop,
         .               {
    41,914 ( 0.00%)          match self {
    13,245 ( 0.00%)              Some(t) => f(t),
         .                       None => default(),
         .                   }
         .               }
         .           
         .               /// Transforms the `Option<T>` into a [`Result<T, E>`], mapping [`Some(v)`] to
         .               /// [`Ok(v)`] and [`None`] to [`Err(err)`].
         .               ///
         .               /// Arguments passed to `ok_or` are eagerly evaluated; if you are passing the
-- line 1007 ----------------------------------------
-- line 1024 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn ok_or<E>(self, err: E) -> Result<T, E>
         .               where
         .                   E: ~const Drop,
         .               {
   311,563 ( 0.00%)          match self {
     2,152 ( 0.00%)              Some(v) => Ok(v),
     1,028 ( 0.00%)              None => Err(err),
         .                   }
         .               }
         .           
         .               /// Transforms the `Option<T>` into a [`Result<T, E>`], mapping [`Some(v)`] to
         .               /// [`Ok(v)`] and [`None`] to [`Err(err())`].
         .               ///
         .               /// [`Ok(v)`]: Ok
         .               /// [`Err(err())`]: Err
-- line 1042 ----------------------------------------
-- line 1049 ----------------------------------------
         .               /// assert_eq!(x.ok_or_else(|| 0), Ok("foo"));
         .               ///
         .               /// let x: Option<&str> = None;
         .               /// assert_eq!(x.ok_or_else(|| 0), Err(0));
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
       112 ( 0.00%)      pub const fn ok_or_else<E, F>(self, err: F) -> Result<T, E>
         .               where
         .                   F: ~const FnOnce() -> E,
         .                   F: ~const Drop,
         .               {
    50,243 ( 0.00%)          match self {
    45,220 ( 0.00%)              Some(v) => Ok(v),
    15,199 ( 0.00%)              None => Err(err()),
         .                   }
       140 ( 0.00%)      }
         .           
         .               /// Converts from `Option<T>` (or `&Option<T>`) to `Option<&T::Target>`.
         .               ///
         .               /// Leaves the original Option in-place, creating a new one with a reference
         .               /// to the original one, additionally coercing the contents via [`Deref`].
         .               ///
         .               /// # Examples
         .               ///
-- line 1074 ----------------------------------------
-- line 1080 ----------------------------------------
         .               /// assert_eq!(x.as_deref(), None);
         .               /// ```
         .               #[stable(feature = "option_deref", since = "1.40.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn as_deref(&self) -> Option<&T::Target>
         .               where
         .                   T: ~const Deref,
         .               {
    17,870 ( 0.00%)          match self.as_ref() {
         .                       Some(t) => Some(t.deref()),
         .                       None => None,
         .                   }
         .               }
         .           
         .               /// Converts from `Option<T>` (or `&mut Option<T>`) to `Option<&mut T::Target>`.
         .               ///
         .               /// Leaves the original `Option` in-place, creating a new one containing a mutable reference to
-- line 1096 ----------------------------------------
-- line 1213 ----------------------------------------
         .               /// assert_eq!(Some(2).and_then(sq).and_then(sq), Some(16));
         .               /// assert_eq!(Some(2).and_then(sq).and_then(nope), None);
         .               /// assert_eq!(Some(2).and_then(nope).and_then(sq), None);
         .               /// assert_eq!(None.and_then(sq).and_then(sq), None);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
     1,389 ( 0.00%)      pub const fn and_then<U, F>(self, f: F) -> Option<U>
         .               where
         .                   F: ~const FnOnce(T) -> Option<U>,
         .                   F: ~const Drop,
         .               {
   193,113 ( 0.00%)          match self {
    13,185 ( 0.00%)              Some(x) => f(x),
         .                       None => None,
         .                   }
    27,269 ( 0.00%)      }
         .           
         .               /// Returns [`None`] if the option is [`None`], otherwise calls `predicate`
         .               /// with the wrapped value and returns:
         .               ///
         .               /// - [`Some(t)`] if `predicate` returns `true` (where `t` is the wrapped
         .               ///   value), and
         .               /// - [`None`] if `predicate` returns `false`.
         .               ///
-- line 1238 ----------------------------------------
-- line 1257 ----------------------------------------
         .               #[stable(feature = "option_filter", since = "1.27.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn filter<P>(self, predicate: P) -> Self
         .               where
         .                   T: ~const Drop,
         .                   P: ~const FnOnce(&T) -> bool,
         .                   P: ~const Drop,
         .               {
     4,314 ( 0.00%)          if let Some(x) = self {
     3,319 ( 0.00%)              if predicate(&x) {
       910 ( 0.00%)                  return Some(x);
         .                       }
         .                   }
         .                   None
       120 ( 0.00%)      }
         .           
         .               /// Returns the option if it contains a value, otherwise returns `optb`.
         .               ///
         .               /// Arguments passed to `or` are eagerly evaluated; if you are passing the
         .               /// result of a function call, it is recommended to use [`or_else`], which is
         .               /// lazily evaluated.
         .               ///
         .               /// [`or_else`]: Option::or_else
-- line 1279 ----------------------------------------
-- line 1299 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn or(self, optb: Option<T>) -> Option<T>
         .               where
         .                   T: ~const Drop,
         .               {
     7,121 ( 0.00%)          match self {
       637 ( 0.00%)              Some(x) => Some(x),
         .                       None => optb,
         .                   }
         .               }
         .           
         .               /// Returns the option if it contains a value, otherwise calls `f` and
         .               /// returns the result.
         .               ///
         .               /// # Examples
-- line 1316 ----------------------------------------
-- line 1326 ----------------------------------------
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn or_else<F>(self, f: F) -> Option<T>
         .               where
         .                   F: ~const FnOnce() -> Option<T>,
         .                   F: ~const Drop,
         .               {
    30,060 ( 0.00%)          match self {
    15,250 ( 0.00%)              Some(x) => Some(x),
         .                       None => f(),
         .                   }
         .               }
         .           
         .               /// Returns [`Some`] if exactly one of `self`, `optb` is [`Some`], otherwise returns [`None`].
         .               ///
         .               /// # Examples
         .               ///
-- line 1343 ----------------------------------------
-- line 1431 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "option_entry", since = "1.20.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn get_or_insert(&mut self, value: T) -> &mut T
         .               where
         .                   T: ~const Drop,
         .               {
    41,751 ( 0.00%)          if let None = *self {
    97,415 ( 0.00%)              *self = Some(value);
         .                   }
         .           
         .                   // SAFETY: a `None` variant for `self` would have been replaced by a `Some`
         .                   // variant in the code above.
         .                   unsafe { self.as_mut().unwrap_unchecked() }
         .               }
         .           
         .               /// Inserts the default value into the option if it is [`None`], then
-- line 1448 ----------------------------------------
-- line 1499 ----------------------------------------
         .               #[inline]
         .               #[stable(feature = "option_entry", since = "1.20.0")]
         .               #[rustc_const_unstable(feature = "const_option_ext", issue = "91930")]
         .               pub const fn get_or_insert_with<F>(&mut self, f: F) -> &mut T
         .               where
         .                   F: ~const FnOnce() -> T,
         .                   F: ~const Drop,
         .               {
   248,936 ( 0.00%)          if let None = *self {
         .                       // the compiler isn't smart enough to know that we are not dropping a `T`
         .                       // here and wants us to ensure `T` can be dropped at compile time.
        18 ( 0.00%)              mem::forget(mem::replace(self, Some(f())))
         .                   }
         .           
         .                   // SAFETY: a `None` variant for `self` would have been replaced by a `Some`
         .                   // variant in the code above.
         .                   unsafe { self.as_mut().unwrap_unchecked() }
         .               }
         .           
         .               /////////////////////////////////////////////////////////////////////////
-- line 1518 ----------------------------------------
-- line 1558 ----------------------------------------
         .               /// let old = x.replace(3);
         .               /// assert_eq!(x, Some(3));
         .               /// assert_eq!(old, None);
         .               /// ```
         .               #[inline]
         .               #[rustc_const_unstable(feature = "const_option", issue = "67441")]
         .               #[stable(feature = "option_replace", since = "1.31.0")]
         .               pub const fn replace(&mut self, value: T) -> Option<T> {
     2,804 ( 0.00%)          mem::replace(self, Some(value))
         .               }
         .           
         .               /// Returns `true` if the option is a [`Some`] value containing the given value.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// #![feature(option_result_contains)]
-- line 1574 ----------------------------------------
-- line 1712 ----------------------------------------
         .               #[stable(feature = "copied", since = "1.35.0")]
         .               #[rustc_const_unstable(feature = "const_option", issue = "67441")]
         .               pub const fn copied(self) -> Option<T>
         .               where
         .                   T: Copy,
         .               {
         .                   // FIXME: this implementation, which sidesteps using `Option::map` since it's not const
         .                   // ready yet, should be reverted when possible to avoid code repetition
    39,412 ( 0.00%)          match self {
   497,396 ( 0.01%)              Some(&v) => Some(v),
     3,741 ( 0.00%)              None => None,
         .                   }
        32 ( 0.00%)      }
         .           
         .               /// Maps an `Option<&T>` to an `Option<T>` by cloning the contents of the
         .               /// option.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// let x = 12;
-- line 1732 ----------------------------------------
-- line 1733 ----------------------------------------
         .               /// let opt_x = Some(&x);
         .               /// assert_eq!(opt_x, Some(&12));
         .               /// let cloned = opt_x.cloned();
         .               /// assert_eq!(cloned, Some(12));
         .               /// ```
         .               #[must_use = "`self` will be dropped if the result is not used"]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[rustc_const_unstable(feature = "const_option_cloned", issue = "91582")]
    15,547 ( 0.00%)      pub const fn cloned(self) -> Option<T>
         .               where
         .                   T: ~const Clone,
         .               {
   118,296 ( 0.00%)          match self {
   281,454 ( 0.00%)              Some(t) => Some(t.clone()),
    10,077 ( 0.00%)              None => None,
         .                   }
    42,475 ( 0.00%)      }
         .           }
         .           
         .           impl<T> Option<&mut T> {
         .               /// Maps an `Option<&mut T>` to an `Option<T>` by copying the contents of the
         .               /// option.
         .               ///
         .               /// # Examples
         .               ///
-- line 1757 ----------------------------------------
-- line 1843 ----------------------------------------
         .           /////////////////////////////////////////////////////////////////////////////
         .           // Trait implementations
         .           /////////////////////////////////////////////////////////////////////////////
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T: Clone> Clone for Option<T> {
         .               #[inline]
         .               fn clone(&self) -> Self {
 1,887,822 ( 0.02%)          match self {
    41,519 ( 0.00%)              Some(x) => Some(x.clone()),
     1,603 ( 0.00%)              None => None,
         .                   }
   596,476 ( 0.01%)      }
         .           
         .               #[inline]
         .               fn clone_from(&mut self, source: &Self) {
         .                   match (self, source) {
         .                       (Some(to), Some(from)) => to.clone_from(from),
         .                       (to, from) => *to = from.clone(),
         .                   }
         .               }
-- line 1863 ----------------------------------------
-- line 2006 ----------------------------------------
         .           
         .               #[inline]
         .               fn next(&mut self) -> Option<A> {
         .                   self.opt.take()
         .               }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
    30,480 ( 0.00%)          match self.opt {
         .                       Some(_) => (1, Some(1)),
         .                       None => (0, Some(0)),
         .                   }
         .               }
         .           }
         .           
         .           impl<A> DoubleEndedIterator for Item<A> {
         .               #[inline]
-- line 2022 ----------------------------------------
-- line 2136 ----------------------------------------
         .               type Item = A;
         .           
         .               #[inline]
         .               fn next(&mut self) -> Option<A> {
         .                   self.inner.next()
         .               }
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
        18 ( 0.00%)          self.inner.size_hint()
         .               }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<A> DoubleEndedIterator for IntoIter<A> {
         .               #[inline]
         .               fn next_back(&mut self) -> Option<A> {
         .                   self.inner.next_back()
-- line 2152 ----------------------------------------
-- line 2241 ----------------------------------------
         .           #[rustc_const_unstable(feature = "const_convert", issue = "88674")]
         .           impl<T> const ops::Try for Option<T> {
         .               type Output = T;
         .               type Residual = Option<convert::Infallible>;
         .           
         .               #[inline]
         .               fn from_output(output: Self::Output) -> Self {
         .                   Some(output)
     3,505 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn branch(self) -> ControlFlow<Self::Residual, Self::Output> {
   562,872 ( 0.01%)          match self {
    62,407 ( 0.00%)              Some(v) => ControlFlow::Continue(v),
         .                       None => ControlFlow::Break(None),
         .                   }
         .               }
         .           }
         .           
         .           #[unstable(feature = "try_trait_v2", issue = "84277")]
         .           #[rustc_const_unstable(feature = "const_convert", issue = "88674")]
         .           impl<T> const ops::FromResidual for Option<T> {
         .               #[inline]
         .               fn from_residual(residual: Option<convert::Infallible>) -> Self {
         .                   match residual {
    67,186 ( 0.00%)              None => None,
         .                   }
         .               }
         .           }
         .           
         .           #[unstable(feature = "try_trait_v2_residual", issue = "91285")]
         .           impl<T> ops::Residual<T> for Option<convert::Infallible> {
         .               type TryType = Option<T>;
         .           }
-- line 2274 ----------------------------------------
-- line 2297 ----------------------------------------
         .               /// let x: Option<Option<Option<u32>>> = Some(Some(Some(6)));
         .               /// assert_eq!(Some(Some(6)), x.flatten());
         .               /// assert_eq!(Some(6), x.flatten().flatten());
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "option_flattening", since = "1.40.0")]
         .               #[rustc_const_unstable(feature = "const_option", issue = "67441")]
         .               pub const fn flatten(self) -> Option<T> {
        32 ( 0.00%)          match self {
       176 ( 0.00%)              Some(inner) => inner,
         .                       None => None,
         .                   }
         .               }
         .           }

 4,218,816 ( 0.05%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/library/core/src/option.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/library/core/src/ascii.rs
--------------------------------------------------------------------------------
Ir                 

-- line 84 ----------------------------------------
        .           /// let mut escaped = ascii::escape_default(b'\x9d');
        .           ///
        .           /// assert_eq!(b'\\', escaped.next().unwrap());
        .           /// assert_eq!(b'x', escaped.next().unwrap());
        .           /// assert_eq!(b'9', escaped.next().unwrap());
        .           /// assert_eq!(b'd', escaped.next().unwrap());
        .           /// ```
        .           #[stable(feature = "rust1", since = "1.0.0")]
  454,933 ( 0.01%)  pub fn escape_default(c: u8) -> EscapeDefault {
2,199,983 ( 0.03%)      let (data, len) = match c {
        .                   b'\t' => ([b'\\', b't', 0, 0], 2),
        .                   b'\r' => ([b'\\', b'r', 0, 0], 2),
        .                   b'\n' => ([b'\\', b'n', 0, 0], 2),
        .                   b'\\' => ([b'\\', b'\\', 0, 0], 2),
        .                   b'\'' => ([b'\\', b'\'', 0, 0], 2),
        .                   b'"' => ([b'\\', b'"', 0, 0], 2),
1,524,264 ( 0.02%)          b'\x20'..=b'\x7e' => ([c, 0, 0, 0], 1),
3,521,340 ( 0.04%)          _ => ([b'\\', b'x', hexify(c >> 4), hexify(c & 0xf)], 4),
        .               };
        .           
        .               return EscapeDefault { range: 0..len, data };
        .           
        .               fn hexify(b: u8) -> u8 {
        .                   match b {
4,695,120 ( 0.05%)              0..=9 => b'0' + b,
        .                       _ => b'a' + b - 10,
        .                   }
        .               }
2,274,665 ( 0.03%)  }
        .           
        .           #[stable(feature = "rust1", since = "1.0.0")]
        .           impl Iterator for EscapeDefault {
        .               type Item = u8;
4,177,810 ( 0.05%)      fn next(&mut self) -> Option<u8> {
4,901,916 ( 0.06%)          self.range.next().map(|i| self.data[i as usize])
4,177,810 ( 0.05%)      }
        .               fn size_hint(&self) -> (usize, Option<usize>) {
        .                   self.range.size_hint()
        .               }
        .               fn last(mut self) -> Option<u8> {
        .                   self.next_back()
        .               }
        .           }
        .           #[stable(feature = "rust1", since = "1.0.0")]
-- line 127 ----------------------------------------

  230,972 ( 0.00%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/library/core/src/ascii.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/library/alloc/src/vec/mod.rs
--------------------------------------------------------------------------------
Ir                  

-- line 417 ----------------------------------------
         .               /// # #![allow(unused_mut)]
         .               /// let mut vec: Vec<i32> = Vec::new();
         .               /// ```
         .               #[inline]
         .               #[rustc_const_stable(feature = "const_vec_new", since = "1.39.0")]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[must_use]
         .               pub const fn new() -> Self {
 3,408,642 ( 0.04%)          Vec { buf: RawVec::NEW, len: 0 }
       180 ( 0.00%)      }
         .           
         .               /// Constructs a new, empty `Vec<T>` with the specified capacity.
         .               ///
         .               /// The vector will be able to hold exactly `capacity` elements without
         .               /// reallocating. If `capacity` is 0, the vector will not allocate.
         .               ///
         .               /// It is important to note that although the returned vector has the
         .               /// *capacity* specified, the vector will have a zero *length*. For an
-- line 434 ----------------------------------------
-- line 601 ----------------------------------------
         .               /// vec.push(11);
         .               /// assert_eq!(vec.len(), 11);
         .               /// assert!(vec.capacity() >= 11);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[inline]
         .               #[unstable(feature = "allocator_api", issue = "32838")]
         .               pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {
 1,109,628 ( 0.01%)          Vec { buf: RawVec::with_capacity_in(capacity, alloc), len: 0 }
         .               }
         .           
         .               /// Creates a `Vec<T, A>` directly from the raw components of another vector.
         .               ///
         .               /// # Safety
         .               ///
         .               /// This is highly unsafe, due to the number of invariants that aren't
         .               /// checked:
-- line 617 ----------------------------------------
-- line 677 ----------------------------------------
         .               ///     // Put everything back together into a Vec
         .               ///     let rebuilt = Vec::from_raw_parts_in(p, len, cap, alloc.clone());
         .               ///     assert_eq!(rebuilt, [4, 5, 6]);
         .               /// }
         .               /// ```
         .               #[inline]
         .               #[unstable(feature = "allocator_api", issue = "32838")]
         .               pub unsafe fn from_raw_parts_in(ptr: *mut T, length: usize, capacity: usize, alloc: A) -> Self {
    75,359 ( 0.00%)          unsafe { Vec { buf: RawVec::from_raw_parts_in(ptr, capacity, alloc), len: length } }
         .               }
         .           
         .               /// Decomposes a `Vec<T>` into its raw components.
         .               ///
         .               /// Returns the raw pointer to the underlying data, the length of
         .               /// the vector (in elements), and the allocated capacity of the
         .               /// data (in elements). These are the same arguments in the same
         .               /// order as the arguments to [`from_raw_parts`].
-- line 693 ----------------------------------------
-- line 778 ----------------------------------------
         .               ///
         .               /// ```
         .               /// let vec: Vec<i32> = Vec::with_capacity(10);
         .               /// assert_eq!(vec.capacity(), 10);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn capacity(&self) -> usize {
   395,115 ( 0.00%)          self.buf.capacity()
         .               }
         .           
         .               /// Reserves capacity for at least `additional` more elements to be inserted
         .               /// in the given `Vec<T>`. The collection may reserve more space to avoid
         .               /// frequent reallocations. After calling `reserve`, capacity will be
         .               /// greater than or equal to `self.len() + additional`. Does nothing if
         .               /// capacity is already sufficient.
         .               ///
-- line 794 ----------------------------------------
-- line 801 ----------------------------------------
         .               /// ```
         .               /// let mut vec = vec![1];
         .               /// vec.reserve(10);
         .               /// assert!(vec.capacity() >= 11);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn reserve(&mut self, additional: usize) {
   346,946 ( 0.00%)          self.buf.reserve(self.len, additional);
         .               }
         .           
         .               /// Reserves the minimum capacity for exactly `additional` more elements to
         .               /// be inserted in the given `Vec<T>`. After calling `reserve_exact`,
         .               /// capacity will be greater than or equal to `self.len() + additional`.
         .               /// Does nothing if the capacity is already sufficient.
         .               ///
         .               /// Note that the allocator may give the collection more space than it
-- line 817 ----------------------------------------
-- line 829 ----------------------------------------
         .               /// ```
         .               /// let mut vec = vec![1];
         .               /// vec.reserve_exact(10);
         .               /// assert!(vec.capacity() >= 11);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn reserve_exact(&mut self, additional: usize) {
    12,687 ( 0.00%)          self.buf.reserve_exact(self.len, additional);
         .               }
         .           
         .               /// Tries to reserve capacity for at least `additional` more elements to be inserted
         .               /// in the given `Vec<T>`. The collection may reserve more space to avoid
         .               /// frequent reallocations. After calling `try_reserve`, capacity will be
         .               /// greater than or equal to `self.len() + additional`. Does nothing if
         .               /// capacity is already sufficient.
         .               ///
-- line 845 ----------------------------------------
-- line 930 ----------------------------------------
         .               /// assert!(vec.capacity() >= 3);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn shrink_to_fit(&mut self) {
         .                   // The capacity is never less than the length, and there's nothing to do when
         .                   // they are equal, so we can avoid the panic case in `RawVec::shrink_to_fit`
         .                   // by only calling it with a greater capacity.
    25,748 ( 0.00%)          if self.capacity() > self.len {
    20,162 ( 0.00%)              self.buf.shrink_to_fit(self.len);
         .                   }
         .               }
         .           
         .               /// Shrinks the capacity of the vector with a lower bound.
         .               ///
         .               /// The capacity will remain at least as large as both the length
         .               /// and the supplied value.
         .               ///
-- line 947 ----------------------------------------
-- line 990 ----------------------------------------
         .               /// let slice = vec.into_boxed_slice();
         .               /// assert_eq!(slice.into_vec().capacity(), 3);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn into_boxed_slice(mut self) -> Box<[T], A> {
         .                   unsafe {
         .                       self.shrink_to_fit();
     7,812 ( 0.00%)              let me = ManuallyDrop::new(self);
         .                       let buf = ptr::read(&me.buf);
         .                       let len = me.len();
         .                       buf.into_box(len).assume_init()
         .                   }
         .               }
         .           
         .               /// Shortens the vector, keeping the first `len` elements and dropping
         .               /// the rest.
-- line 1006 ----------------------------------------
-- line 1040 ----------------------------------------
         .               /// let mut vec = vec![1, 2, 3];
         .               /// vec.truncate(0);
         .               /// assert_eq!(vec, []);
         .               /// ```
         .               ///
         .               /// [`clear`]: Vec::clear
         .               /// [`drain`]: Vec::drain
         .               #[stable(feature = "rust1", since = "1.0.0")]
   264,467 ( 0.00%)      pub fn truncate(&mut self, len: usize) {
         .                   // This is safe because:
         .                   //
         .                   // * the slice passed to `drop_in_place` is valid; the `len > self.len`
         .                   //   case avoids creating an invalid slice, and
         .                   // * the `len` of the vector is shrunk before calling `drop_in_place`,
         .                   //   such that no value will be dropped twice in case `drop_in_place`
         .                   //   were to panic once (if it panics twice, the program aborts).
         .                   unsafe {
         .                       // Note: It's intentional that this is `>` and not `>=`.
         .                       //       Changing it to `>=` has negative performance
         .                       //       implications in some cases. See #78884 for more.
   213,155 ( 0.00%)              if len > self.len {
         .                           return;
         .                       }
         .                       let remaining_len = self.len - len;
         .                       let s = ptr::slice_from_raw_parts_mut(self.as_mut_ptr().add(len), remaining_len);
   215,251 ( 0.00%)              self.len = len;
     5,815 ( 0.00%)              ptr::drop_in_place(s);
         .                   }
   317,328 ( 0.00%)      }
         .           
         .               /// Extracts a slice containing the entire vector.
         .               ///
         .               /// Equivalent to `&s[..]`.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
-- line 1076 ----------------------------------------
-- line 1126 ----------------------------------------
         .               /// ```
         .               ///
         .               /// [`as_mut_ptr`]: Vec::as_mut_ptr
         .               #[stable(feature = "vec_as_ptr", since = "1.37.0")]
         .               #[inline]
         .               pub fn as_ptr(&self) -> *const T {
         .                   // We shadow the slice method of the same name to avoid going through
         .                   // `deref`, which creates an intermediate reference.
 4,212,731 ( 0.05%)          let ptr = self.buf.ptr();
         .                   unsafe {
         .                       assume(!ptr.is_null());
         .                   }
         .                   ptr
         .               }
         .           
         .               /// Returns an unsafe mutable pointer to the vector's buffer.
         .               ///
-- line 1142 ----------------------------------------
-- line 1162 ----------------------------------------
         .               /// }
         .               /// assert_eq!(&*x, &[0, 1, 2, 3]);
         .               /// ```
         .               #[stable(feature = "vec_as_ptr", since = "1.37.0")]
         .               #[inline]
         .               pub fn as_mut_ptr(&mut self) -> *mut T {
         .                   // We shadow the slice method of the same name to avoid going through
         .                   // `deref_mut`, which creates an intermediate reference.
 5,465,737 ( 0.06%)          let ptr = self.buf.ptr();
         .                   unsafe {
         .                       assume(!ptr.is_null());
         .                   }
         .                   ptr
         .               }
         .           
         .               /// Returns a reference to the underlying allocator.
         .               #[unstable(feature = "allocator_api", issue = "32838")]
-- line 1178 ----------------------------------------
-- line 1259 ----------------------------------------
         .               ///
         .               /// Normally, here, one would use [`clear`] instead to correctly drop
         .               /// the contents and thus not leak memory.
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub unsafe fn set_len(&mut self, new_len: usize) {
         .                   debug_assert!(new_len <= self.capacity());
         .           
   729,589 ( 0.01%)          self.len = new_len;
    14,370 ( 0.00%)      }
         .           
         .               /// Removes an element from the vector and returns it.
         .               ///
         .               /// The removed element is replaced by the last element of the vector.
         .               ///
         .               /// This does not preserve ordering, but is *O*(1).
         .               /// If you need to preserve the element order, use [`remove`] instead.
         .               ///
-- line 1276 ----------------------------------------
-- line 1305 ----------------------------------------
         .                       assert_failed(index, len);
         .                   }
         .                   unsafe {
         .                       // We replace self[index] with the last element. Note that if the
         .                       // bounds check above succeeds there must be a last element (which
         .                       // can be self[index] itself).
         .                       let value = ptr::read(self.as_ptr().add(index));
         .                       let base_ptr = self.as_mut_ptr();
        27 ( 0.00%)              ptr::copy(base_ptr.add(len - 1), base_ptr.add(index), 1);
         .                       self.set_len(len - 1);
         .                       value
         .                   }
         .               }
         .           
         .               /// Inserts an element at position `index` within the vector, shifting all
         .               /// elements after it to the right.
         .               ///
-- line 1321 ----------------------------------------
-- line 1329 ----------------------------------------
         .               /// let mut vec = vec![1, 2, 3];
         .               /// vec.insert(1, 4);
         .               /// assert_eq!(vec, [1, 4, 2, 3]);
         .               /// vec.insert(4, 5);
         .               /// assert_eq!(vec, [1, 4, 2, 3, 5]);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "rust1", since = "1.0.0")]
     8,589 ( 0.00%)      pub fn insert(&mut self, index: usize, element: T) {
         .                   #[cold]
         .                   #[inline(never)]
         .                   fn assert_failed(index: usize, len: usize) -> ! {
         .                       panic!("insertion index (is {}) should be <= len (is {})", index, len);
         .                   }
         .           
     1,335 ( 0.00%)          let len = self.len();
     2,906 ( 0.00%)          if index > len {
         .                       assert_failed(index, len);
         .                   }
         .           
         .                   // space for the new element
     4,774 ( 0.00%)          if len == self.buf.capacity() {
         .                       self.reserve(1);
         .                   }
         .           
         .                   unsafe {
         .                       // infallible
         .                       // The spot to put the new value
         .                       {
         .                           let p = self.as_mut_ptr().add(index);
         .                           // Shift everything over to make space. (Duplicating the
         .                           // `index`th element into two consecutive places.)
     6,717 ( 0.00%)                  ptr::copy(p, p.offset(1), len - index);
         .                           // Write it in, overwriting the first copy of the `index`th
         .                           // element.
         .                           ptr::write(p, element);
         .                       }
     4,694 ( 0.00%)              self.set_len(len + 1);
         .                   }
     7,362 ( 0.00%)      }
         .           
         .               /// Removes and returns the element at position `index` within the vector,
         .               /// shifting all elements after it to the left.
         .               ///
         .               /// Note: Because this shifts over the remaining elements, it has a
         .               /// worst-case performance of *O*(*n*). If you don't need the order of elements
         .               /// to be preserved, use [`swap_remove`] instead. If you'd like to remove
         .               /// elements from the beginning of the `Vec`, consider using
-- line 1376 ----------------------------------------
-- line 1395 ----------------------------------------
         .               pub fn remove(&mut self, index: usize) -> T {
         .                   #[cold]
         .                   #[inline(never)]
         .                   #[track_caller]
         .                   fn assert_failed(index: usize, len: usize) -> ! {
         .                       panic!("removal index (is {}) should be < len (is {})", index, len);
         .                   }
         .           
       420 ( 0.00%)          let len = self.len();
     1,522 ( 0.00%)          if index >= len {
         .                       assert_failed(index, len);
         .                   }
         .                   unsafe {
         .                       // infallible
         .                       let ret;
         .                       {
         .                           // the place we are taking from.
         .                           let ptr = self.as_mut_ptr().add(index);
         .                           // copy it out, unsafely having a copy of the value on
         .                           // the stack and in the vector at the same time.
     2,528 ( 0.00%)                  ret = ptr::read(ptr);
         .           
         .                           // Shift everything down to fill in that spot.
     1,018 ( 0.00%)                  ptr::copy(ptr.offset(1), ptr, len - index - 1);
         .                       }
       420 ( 0.00%)              self.set_len(len - 1);
         .                       ret
         .                   }
         .               }
         .           
         .               /// Retains only the elements specified by the predicate.
         .               ///
         .               /// In other words, remove all elements `e` such that `f(&e)` returns `false`.
         .               /// This method operates in place, visiting each element exactly once in the
-- line 1428 ----------------------------------------
-- line 1442 ----------------------------------------
         .               /// ```
         .               /// let mut vec = vec![1, 2, 3, 4, 5];
         .               /// let keep = [false, true, true, false, true];
         .               /// let mut iter = keep.iter();
         .               /// vec.retain(|_| *iter.next().unwrap());
         .               /// assert_eq!(vec, [2, 3, 5]);
         .               /// ```
         .               #[stable(feature = "rust1", since = "1.0.0")]
   323,822 ( 0.00%)      pub fn retain<F>(&mut self, mut f: F)
         .               where
         .                   F: FnMut(&T) -> bool,
         .               {
    15,524 ( 0.00%)          self.retain_mut(|elem| f(elem));
   313,960 ( 0.00%)      }
         .           
         .               /// Retains only the elements specified by the predicate, passing a mutable reference to it.
         .               ///
         .               /// In other words, remove all elements `e` such that `f(&mut e)` returns `false`.
         .               /// This method operates in place, visiting each element exactly once in the
         .               /// original order, and preserves the order of the retained elements.
         .               ///
         .               /// # Examples
-- line 1463 ----------------------------------------
-- line 1474 ----------------------------------------
         .               /// });
         .               /// assert_eq!(vec, [2, 3, 4]);
         .               /// ```
         .               #[unstable(feature = "vec_retain_mut", issue = "90829")]
         .               pub fn retain_mut<F>(&mut self, mut f: F)
         .               where
         .                   F: FnMut(&mut T) -> bool,
         .               {
    40,759 ( 0.00%)          let original_len = self.len();
         .                   // Avoid double drop if the drop guard is not executed,
         .                   // since we may make some holes during the process.
         .                   unsafe { self.set_len(0) };
         .           
         .                   // Vec: [Kept, Kept, Hole, Hole, Hole, Hole, Unchecked, Unchecked]
         .                   //      |<-              processed len   ->| ^- next to check
         .                   //                  |<-  deleted cnt     ->|
         .                   //      |<-              original_len                          ->|
-- line 1490 ----------------------------------------
-- line 1499 ----------------------------------------
         .                       v: &'a mut Vec<T, A>,
         .                       processed_len: usize,
         .                       deleted_cnt: usize,
         .                       original_len: usize,
         .                   }
         .           
         .                   impl<T, A: Allocator> Drop for BackshiftOnDrop<'_, T, A> {
         .                       fn drop(&mut self) {
    28,366 ( 0.00%)                  if self.deleted_cnt > 0 {
         .                               // SAFETY: Trailing unchecked items must be valid since we never touch them.
         .                               unsafe {
         .                                   ptr::copy(
         .                                       self.v.as_ptr().add(self.processed_len),
    20,638 ( 0.00%)                              self.v.as_mut_ptr().add(self.processed_len - self.deleted_cnt),
         .                                       self.original_len - self.processed_len,
         .                                   );
         .                               }
         .                           }
         .                           // SAFETY: After filling holes, all items are in contiguous memory.
         .                           unsafe {
         2 ( 0.00%)                      self.v.set_len(self.original_len - self.deleted_cnt);
         .                           }
         .                       }
         .                   }
         .           
         .                   let mut g = BackshiftOnDrop { v: self, processed_len: 0, deleted_cnt: 0, original_len };
         .           
         .                   fn process_loop<F, T, A: Allocator, const DELETED: bool>(
         .                       original_len: usize,
         .                       f: &mut F,
         .                       g: &mut BackshiftOnDrop<'_, T, A>,
         .                   ) where
         .                       F: FnMut(&mut T) -> bool,
         .                   {
   571,106 ( 0.01%)              while g.processed_len != original_len {
         .                           // SAFETY: Unchecked element must be valid.
         .                           let cur = unsafe { &mut *g.v.as_mut_ptr().add(g.processed_len) };
   132,978 ( 0.00%)                  if !f(cur) {
         .                               // Advance early to avoid double drop if `drop_in_place` panicked.
     4,566 ( 0.00%)                      g.processed_len += 1;
     1,530 ( 0.00%)                      g.deleted_cnt += 1;
         .                               // SAFETY: We never touch this element again after dropped.
       208 ( 0.00%)                      unsafe { ptr::drop_in_place(cur) };
         .                               // We already advanced the counter.
         .                               if DELETED {
         .                                   continue;
         .                               } else {
         .                                   break;
         .                               }
         .                           }
         .                           if DELETED {
         .                               // SAFETY: `deleted_cnt` > 0, so the hole slot must not overlap with current element.
         .                               // We use copy for move, and never touch this element again.
         .                               unsafe {
    18,084 ( 0.00%)                          let hole_slot = g.v.as_mut_ptr().add(g.processed_len - g.deleted_cnt);
         .                                   ptr::copy_nonoverlapping(cur, hole_slot, 1);
         .                               }
         .                           }
    15,976 ( 0.00%)                  g.processed_len += 1;
         .                       }
         .                   }
         .           
         .                   // Stage 1: Nothing was deleted.
         .                   process_loop::<F, T, A, false>(original_len, &mut f, &mut g);
         .           
         .                   // Stage 2: Some elements were deleted.
         .                   process_loop::<F, T, A, true>(original_len, &mut f, &mut g);
-- line 1565 ----------------------------------------
-- line 1606 ----------------------------------------
         .               /// ```
         .               /// let mut vec = vec!["foo", "bar", "Bar", "baz", "bar"];
         .               ///
         .               /// vec.dedup_by(|a, b| a.eq_ignore_ascii_case(b));
         .               ///
         .               /// assert_eq!(vec, ["foo", "bar", "baz", "bar"]);
         .               /// ```
         .               #[stable(feature = "dedup_by", since = "1.16.0")]
     4,249 ( 0.00%)      pub fn dedup_by<F>(&mut self, mut same_bucket: F)
         .               where
         .                   F: FnMut(&mut T, &mut T) -> bool,
         .               {
     1,982 ( 0.00%)          let len = self.len();
     6,218 ( 0.00%)          if len <= 1 {
         .                       return;
         .                   }
         .           
         .                   /* INVARIANT: vec.len() > read >= write > write-1 >= 0 */
         .                   struct FillGapOnDrop<'a, T, A: core::alloc::Allocator> {
         .                       /* Offset of the element we want to check if it is duplicate */
         .                       read: usize,
         .           
-- line 1627 ----------------------------------------
-- line 1670 ----------------------------------------
         .                   let ptr = gap.vec.as_mut_ptr();
         .           
         .                   /* Drop items while going through Vec, it should be more efficient than
         .                    * doing slice partition_dedup + truncate */
         .           
         .                   /* SAFETY: Because of the invariant, read_ptr, prev_ptr and write_ptr
         .                    * are always in-bounds and read_ptr never aliases prev_ptr */
         .                   unsafe {
    10,650 ( 0.00%)              while gap.read < len {
         .                           let read_ptr = ptr.add(gap.read);
         .                           let prev_ptr = ptr.add(gap.write.wrapping_sub(1));
         .           
     1,136 ( 0.00%)                  if same_bucket(&mut *read_ptr, &mut *prev_ptr) {
         .                               // Increase `gap.read` now since the drop may panic.
         .                               gap.read += 1;
         .                               /* We have found duplicate, drop it in-place */
         .                               ptr::drop_in_place(read_ptr);
         .                           } else {
         .                               let write_ptr = ptr.add(gap.write);
         .           
         .                               /* Because `read_ptr` can be equal to `write_ptr`, we either
         .                                * have to use `copy` or conditional `copy_nonoverlapping`.
         .                                * Looks like the first option is faster. */
         .                               ptr::copy(read_ptr, write_ptr, 1);
         .           
         .                               /* We have filled that place, so go further */
     6,108 ( 0.00%)                      gap.write += 1;
         .                               gap.read += 1;
         .                           }
         .                       }
         .           
         .                       /* Technically we could let `gap` clean up with its Drop, but
         .                        * when `same_bucket` is guaranteed to not panic, this bloats a little
         .                        * the codegen, so we just do it manually */
         .                       gap.vec.set_len(gap.write);
         .                       mem::forget(gap);
         .                   }
     4,856 ( 0.00%)      }
         .           
         .               /// Appends an element to the back of a collection.
         .               ///
         .               /// # Panics
         .               ///
         .               /// Panics if the new capacity exceeds `isize::MAX` bytes.
         .               ///
         .               /// # Examples
-- line 1715 ----------------------------------------
-- line 1717 ----------------------------------------
         .               /// ```
         .               /// let mut vec = vec![1, 2];
         .               /// vec.push(3);
         .               /// assert_eq!(vec, [1, 2, 3]);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
       715 ( 0.00%)      pub fn push(&mut self, value: T) {
         .                   // This will panic or abort if we would allocate > isize::MAX bytes
         .                   // or if the length increment would overflow for zero-sized types.
10,762,907 ( 0.12%)          if self.len == self.buf.capacity() {
   468,094 ( 0.01%)              self.buf.reserve_for_push(self.len);
         .                   }
         .                   unsafe {
   209,537 ( 0.00%)              let end = self.as_mut_ptr().add(self.len);
         .                       ptr::write(end, value);
13,521,490 ( 0.16%)              self.len += 1;
         .                   }
       572 ( 0.00%)      }
         .           
         .               /// Removes the last element from a vector and returns it, or [`None`] if it
         .               /// is empty.
         .               ///
         .               /// If you'd like to pop the first element, consider using
         .               /// [`VecDeque::pop_front`] instead.
         .               ///
         .               /// [`VecDeque::pop_front`]: crate::collections::VecDeque::pop_front
-- line 1744 ----------------------------------------
-- line 1748 ----------------------------------------
         .               /// ```
         .               /// let mut vec = vec![1, 2, 3];
         .               /// assert_eq!(vec.pop(), Some(3));
         .               /// assert_eq!(vec, [1, 2]);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn pop(&mut self) -> Option<T> {
 1,270,920 ( 0.01%)          if self.len == 0 {
        59 ( 0.00%)              None
         .                   } else {
         .                       unsafe {
   944,189 ( 0.01%)                  self.len -= 1;
   189,086 ( 0.00%)                  Some(ptr::read(self.as_ptr().add(self.len())))
         .                       }
         .                   }
         .               }
         .           
         .               /// Moves all the elements of `other` into `Self`, leaving `other` empty.
         .               ///
         .               /// # Panics
         .               ///
-- line 1769 ----------------------------------------
-- line 1776 ----------------------------------------
         .               /// let mut vec2 = vec![4, 5, 6];
         .               /// vec.append(&mut vec2);
         .               /// assert_eq!(vec, [1, 2, 3, 4, 5, 6]);
         .               /// assert_eq!(vec2, []);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[inline]
         .               #[stable(feature = "append", since = "1.4.0")]
     1,722 ( 0.00%)      pub fn append(&mut self, other: &mut Self) {
         .                   unsafe {
         .                       self.append_elements(other.as_slice() as _);
         .                       other.set_len(0);
         .                   }
     1,476 ( 0.00%)      }
         .           
         .               /// Appends elements to `Self` from other buffer.
         .               #[cfg(not(no_global_oom_handling))]
         .               #[inline]
         .               unsafe fn append_elements(&mut self, other: *const [T]) {
         .                   let count = unsafe { (*other).len() };
         .                   self.reserve(count);
    57,661 ( 0.00%)          let len = self.len();
       188 ( 0.00%)          unsafe { ptr::copy_nonoverlapping(other as *const T, self.as_mut_ptr().add(len), count) };
   448,187 ( 0.01%)          self.len += count;
         .               }
         .           
         .               /// Creates a draining iterator that removes the specified range in the vector
         .               /// and yields the removed items.
         .               ///
         .               /// When the iterator **is** dropped, all elements in the range are removed
         .               /// from the vector, even if the iterator was not fully consumed. If the
         .               /// iterator **is not** dropped (with [`mem::forget`] for example), it is
-- line 1807 ----------------------------------------
-- line 1834 ----------------------------------------
         .                   // When the Drain is first created, it shortens the length of
         .                   // the source vector to make sure no uninitialized or moved-from elements
         .                   // are accessible at all if the Drain's destructor never gets to run.
         .                   //
         .                   // Drain will ptr::read out the values to remove.
         .                   // When finished, remaining tail of the vec is copied back to cover
         .                   // the hole, and the vector length is restored to the new length.
         .                   //
    22,317 ( 0.00%)          let len = self.len();
         .                   let Range { start, end } = slice::range(range, ..len);
         .           
         .                   unsafe {
         .                       // set self.vec length's to start, to be safe in case Drain is leaked
         .                       self.set_len(start);
         .                       // Use the borrow in the IterMut to indicate borrowing behavior of the
         .                       // whole Drain iterator (like &mut T).
       689 ( 0.00%)              let range_slice = slice::from_raw_parts_mut(self.as_mut_ptr().add(start), end - start);
     2,477 ( 0.00%)              Drain {
         .                           tail_start: end,
       512 ( 0.00%)                  tail_len: len - end,
         .                           iter: range_slice.iter(),
         .                           vec: NonNull::from(self),
         .                       }
         .                   }
         .               }
         .           
         .               /// Clears the vector, removing all values.
         .               ///
-- line 1861 ----------------------------------------
-- line 1869 ----------------------------------------
         .               ///
         .               /// v.clear();
         .               ///
         .               /// assert!(v.is_empty());
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn clear(&mut self) {
   471,239 ( 0.01%)          self.truncate(0)
         .               }
         .           
         .               /// Returns the number of elements in the vector, also referred to
         .               /// as its 'length'.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
-- line 1885 ----------------------------------------
-- line 1900 ----------------------------------------
         .               /// let mut v = Vec::new();
         .               /// assert!(v.is_empty());
         .               ///
         .               /// v.push(1);
         .               /// assert!(!v.is_empty());
         .               /// ```
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               pub fn is_empty(&self) -> bool {
   475,399 ( 0.01%)          self.len() == 0
         .               }
         .           
         .               /// Splits the collection into two at the given index.
         .               ///
         .               /// Returns a newly allocated vector containing the elements in the range
         .               /// `[at, len)`. After the call, the original vector will be left containing
         .               /// the elements `[0, at)` with its previous capacity unchanged.
         .               ///
-- line 1916 ----------------------------------------
-- line 1935 ----------------------------------------
         .                   A: Clone,
         .               {
         .                   #[cold]
         .                   #[inline(never)]
         .                   fn assert_failed(at: usize, len: usize) -> ! {
         .                       panic!("`at` split index (is {}) should be <= len (is {})", at, len);
         .                   }
         .           
     2,524 ( 0.00%)          if at > self.len() {
         .                       assert_failed(at, self.len());
         .                   }
         .           
     1,976 ( 0.00%)          if at == 0 {
         .                       // the new vector can take over the original buffer and avoid the copy
         .                       return mem::replace(
         .                           self,
         .                           Vec::with_capacity_in(self.capacity(), self.allocator().clone()),
         .                       );
         .                   }
         .           
         .                   let other_len = self.len - at;
-- line 1955 ----------------------------------------
-- line 1988 ----------------------------------------
         .               ///
         .               /// let mut vec = vec![];
         .               /// let mut p = 1;
         .               /// vec.resize_with(4, || { p *= 2; p });
         .               /// assert_eq!(vec, [2, 4, 8, 16]);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "vec_resize_with", since = "1.33.0")]
    26,425 ( 0.00%)      pub fn resize_with<F>(&mut self, new_len: usize, f: F)
         .               where
         .                   F: FnMut() -> T,
         .               {
     3,593 ( 0.00%)          let len = self.len();
     7,186 ( 0.00%)          if new_len > len {
    28,483 ( 0.00%)              self.extend_with(new_len - len, ExtendFunc(f));
         .                   } else {
         .                       self.truncate(new_len);
         .                   }
    22,832 ( 0.00%)      }
         .           
         .               /// Consumes and leaks the `Vec`, returning a mutable reference to the contents,
         .               /// `&'a mut [T]`. Note that the type `T` must outlive the chosen lifetime
         .               /// `'a`. If the type has only static references, or none at all, then this
         .               /// may be chosen to be `'static`.
         .               ///
         .               /// As of Rust 1.57, this method does not reallocate or shrink the `Vec`,
         .               /// so the leaked allocation may include unused capacity that is not part
-- line 2014 ----------------------------------------
-- line 2070 ----------------------------------------
         .               #[stable(feature = "vec_spare_capacity", since = "1.60.0")]
         .               #[inline]
         .               pub fn spare_capacity_mut(&mut self) -> &mut [MaybeUninit<T>] {
         .                   // Note:
         .                   // This method is not implemented in terms of `split_at_spare_mut`,
         .                   // to prevent invalidation of pointers to the buffer.
         .                   unsafe {
         .                       slice::from_raw_parts_mut(
         2 ( 0.00%)                  self.as_mut_ptr().add(self.len) as *mut MaybeUninit<T>,
       129 ( 0.00%)                  self.buf.capacity() - self.len,
         .                       )
         .                   }
         .               }
         .           
         .               /// Returns vector content as a slice of `T`, along with the remaining spare
         .               /// capacity of the vector as a slice of `MaybeUninit<T>`.
         .               ///
         .               /// The returned spare capacity slice can be used to fill the vector with data
-- line 2087 ----------------------------------------
-- line 2189 ----------------------------------------
         .               /// assert_eq!(vec, ["hello", "world", "world"]);
         .               ///
         .               /// let mut vec = vec![1, 2, 3, 4];
         .               /// vec.resize(2, 0);
         .               /// assert_eq!(vec, [1, 2]);
         .               /// ```
         .               #[cfg(not(no_global_oom_handling))]
         .               #[stable(feature = "vec_resize", since = "1.5.0")]
    30,810 ( 0.00%)      pub fn resize(&mut self, new_len: usize, value: T) {
     3,081 ( 0.00%)          let len = self.len();
         .           
     9,243 ( 0.00%)          if new_len > len {
     6,309 ( 0.00%)              self.extend_with(new_len - len, ExtendElement(value))
         .                   } else {
         .                       self.truncate(new_len);
         .                   }
     4,297 ( 0.00%)      }
         .           
         .               /// Clones and appends all elements in a slice to the `Vec`.
         .               ///
         .               /// Iterates over the slice `other`, clones each element, and then appends
         .               /// it to this `Vec`. The `other` slice is traversed in-order.
         .               ///
         .               /// Note that this function is same as [`extend`] except that it is
         .               /// specialized to work with slices instead. If and when Rust gets
-- line 2213 ----------------------------------------
-- line 2271 ----------------------------------------
         .           trait ExtendWith<T> {
         .               fn next(&mut self) -> T;
         .               fn last(self) -> T;
         .           }
         .           
         .           struct ExtendElement<T>(T);
         .           impl<T: Clone> ExtendWith<T> for ExtendElement<T> {
         .               fn next(&mut self) -> T {
       394 ( 0.00%)          self.0.clone()
         .               }
         .               fn last(self) -> T {
         .                   self.0
         .               }
         .           }
         .           
         .           struct ExtendFunc<F>(F);
         .           impl<T, F: FnMut() -> T> ExtendWith<T> for ExtendFunc<F> {
-- line 2287 ----------------------------------------
-- line 2291 ----------------------------------------
         .               fn last(mut self) -> T {
         .                   (self.0)()
         .               }
         .           }
         .           
         .           impl<T, A: Allocator> Vec<T, A> {
         .               #[cfg(not(no_global_oom_handling))]
         .               /// Extend the vector by `n` values, using the given generator.
   257,375 ( 0.00%)      fn extend_with<E: ExtendWith<T>>(&mut self, n: usize, mut value: E) {
         .                   self.reserve(n);
         .           
         .                   unsafe {
     7,427 ( 0.00%)              let mut ptr = self.as_mut_ptr().add(self.len());
         .                       // Use SetLenOnDrop to work around bug where compiler
         .                       // might not realize the store through `ptr` through self.set_len()
         .                       // don't alias.
         .                       let mut local_len = SetLenOnDrop::new(&mut self.len);
         .           
         .                       // Write all elements except the last one
         .                       for _ in 1..n {
         .                           ptr::write(ptr, value.next());
         .                           ptr = ptr.offset(1);
         .                           // Increment the length in every step in case next() panics
         .                           local_len.increment_len(1);
         .                       }
         .           
   293,823 ( 0.00%)              if n > 0 {
         .                           // We can write the last element directly without cloning needlessly
         .                           ptr::write(ptr, value.last());
         .                           local_len.increment_len(1);
         .                       }
         .           
         .                       // len set by scope guard
         .                   }
   204,715 ( 0.00%)      }
         .           }
         .           
         .           impl<T: PartialEq, A: Allocator> Vec<T, A> {
         .               /// Removes consecutive repeated elements in the vector according to the
         .               /// [`PartialEq`] trait implementation.
         .               ///
         .               /// If the vector is sorted, this removes all duplicates.
         .               ///
-- line 2333 ----------------------------------------
-- line 2338 ----------------------------------------
         .               ///
         .               /// vec.dedup();
         .               ///
         .               /// assert_eq!(vec, [1, 2, 3, 2]);
         .               /// ```
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[inline]
         .               pub fn dedup(&mut self) {
       608 ( 0.00%)          self.dedup_by(|a, b| a == b)
         .               }
         .           }
         .           
         .           ////////////////////////////////////////////////////////////////////////////////
         .           // Internal methods and functions
         .           ////////////////////////////////////////////////////////////////////////////////
         .           
         .           #[doc(hidden)]
         .           #[cfg(not(no_global_oom_handling))]
         .           #[stable(feature = "rust1", since = "1.0.0")]
    68,738 ( 0.00%)  pub fn from_elem<T: Clone>(elem: T, n: usize) -> Vec<T> {
   349,323 ( 0.00%)      <T as SpecFromElem>::from_elem(elem, n, Global)
    77,408 ( 0.00%)  }
         .           
         .           #[doc(hidden)]
         .           #[cfg(not(no_global_oom_handling))]
         .           #[unstable(feature = "allocator_api", issue = "32838")]
         .           pub fn from_elem_in<T: Clone, A: Allocator>(elem: T, n: usize, alloc: A) -> Vec<T, A> {
         .               <T as SpecFromElem>::from_elem(elem, n, alloc)
         .           }
         .           
-- line 2367 ----------------------------------------
-- line 2424 ----------------------------------------
         .           // Common trait implementations for Vec
         .           ////////////////////////////////////////////////////////////////////////////////
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T, A: Allocator> ops::Deref for Vec<T, A> {
         .               type Target = [T];
         .           
         .               fn deref(&self) -> &[T] {
 6,483,129 ( 0.07%)          unsafe { slice::from_raw_parts(self.as_ptr(), self.len) }
       162 ( 0.00%)      }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T, A: Allocator> ops::DerefMut for Vec<T, A> {
         .               fn deref_mut(&mut self) -> &mut [T] {
 1,530,361 ( 0.02%)          unsafe { slice::from_raw_parts_mut(self.as_mut_ptr(), self.len) }
         .               }
         .           }
         .           
         .           #[cfg(not(no_global_oom_handling))]
         .           trait SpecCloneFrom {
         .               fn clone_from(this: &mut Self, other: &Self);
         .           }
         .           
-- line 2447 ----------------------------------------
-- line 2468 ----------------------------------------
         .                   this.extend_from_slice(other);
         .               }
         .           }
         .           
         .           #[cfg(not(no_global_oom_handling))]
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T: Clone, A: Allocator + Clone> Clone for Vec<T, A> {
         .               #[cfg(not(test))]
   231,194 ( 0.00%)      fn clone(&self) -> Self {
         .                   let alloc = self.allocator().clone();
         2 ( 0.00%)          <[T]>::to_vec_in(&**self, alloc)
   288,949 ( 0.00%)      }
         .           
         .               // HACK(japaric): with cfg(test) the inherent `[T]::to_vec` method, which is
         .               // required for this method definition, is not available. Instead use the
         .               // `slice::to_vec`  function which is only available with cfg(test)
         .               // NB see the slice::hack module in slice.rs for more information
         .               #[cfg(test)]
         .               fn clone(&self) -> Self {
         .                   let alloc = self.allocator().clone();
-- line 2487 ----------------------------------------
-- line 2518 ----------------------------------------
         .               message = "vector indices are of type `usize` or ranges of `usize`",
         .               label = "vector indices are of type `usize` or ranges of `usize`"
         .           )]
         .           impl<T, I: SliceIndex<[T]>, A: Allocator> Index<I> for Vec<T, A> {
         .               type Output = I::Output;
         .           
         .               #[inline]
         .               fn index(&self, index: I) -> &Self::Output {
   176,757 ( 0.00%)          Index::index(&**self, index)
         .               }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           #[rustc_on_unimplemented(
         .               message = "vector indices are of type `usize` or ranges of `usize`",
         .               label = "vector indices are of type `usize` or ranges of `usize`"
         .           )]
         .           impl<T, I: SliceIndex<[T]>, A: Allocator> IndexMut<I> for Vec<T, A> {
         .               #[inline]
         .               fn index_mut(&mut self, index: I) -> &mut Self::Output {
       984 ( 0.00%)          IndexMut::index_mut(&mut **self, index)
         .               }
         .           }
         .           
         .           #[cfg(not(no_global_oom_handling))]
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T> FromIterator<T> for Vec<T> {
         .               #[inline]
         .               fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Vec<T> {
 1,647,020 ( 0.02%)          <Self as SpecFromIter<T, I::IntoIter>>::from_iter(iter.into_iter())
         .               }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T, A: Allocator> IntoIterator for Vec<T, A> {
         .               type Item = T;
         .               type IntoIter = IntoIter<T, A>;
         .           
-- line 2555 ----------------------------------------
-- line 2564 ----------------------------------------
         .               /// for s in v.into_iter() {
         .               ///     // s has type String, not &String
         .               ///     println!("{}", s);
         .               /// }
         .               /// ```
         .               #[inline]
         .               fn into_iter(self) -> IntoIter<T, A> {
         .                   unsafe {
   684,392 ( 0.01%)              let mut me = ManuallyDrop::new(self);
         .                       let alloc = ptr::read(me.allocator());
         .                       let begin = me.as_mut_ptr();
         .                       let end = if mem::size_of::<T>() == 0 {
         .                           arith_offset(begin as *const i8, me.len() as isize) as *const T
         .                       } else {
         .                           begin.add(me.len()) as *const T
         .                       };
         .                       let cap = me.buf.capacity();
   224,518 ( 0.00%)              IntoIter {
         .                           buf: NonNull::new_unchecked(begin),
         .                           phantom: PhantomData,
         .                           cap,
         .                           alloc,
         .                           ptr: begin,
         .                           end,
         .                       }
         .                   }
-- line 2589 ----------------------------------------
-- line 2591 ----------------------------------------
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<'a, T, A: Allocator> IntoIterator for &'a Vec<T, A> {
         .               type Item = &'a T;
         .               type IntoIter = slice::Iter<'a, T>;
         .           
         .               fn into_iter(self) -> slice::Iter<'a, T> {
        57 ( 0.00%)          self.iter()
         .               }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<'a, T, A: Allocator> IntoIterator for &'a mut Vec<T, A> {
         .               type Item = &'a mut T;
         .               type IntoIter = slice::IterMut<'a, T>;
         .           
         .               fn into_iter(self) -> slice::IterMut<'a, T> {
     1,194 ( 0.00%)          self.iter_mut()
         .               }
         .           }
         .           
         .           #[cfg(not(no_global_oom_handling))]
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<T, A: Allocator> Extend<T> for Vec<T, A> {
         .               #[inline]
     2,344 ( 0.00%)      fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {
   677,373 ( 0.01%)          <Self as SpecExtend<T, I::IntoIter>>::spec_extend(self, iter.into_iter())
     2,344 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn extend_one(&mut self, item: T) {
         .                   self.push(item);
         .               }
         .           
         .               #[inline]
         .               fn extend_reserve(&mut self, additional: usize) {
-- line 2627 ----------------------------------------
-- line 2636 ----------------------------------------
         .               fn extend_desugared<I: Iterator<Item = T>>(&mut self, mut iterator: I) {
         .                   // This is the case for a general iterator.
         .                   //
         .                   // This function should be the moral equivalent of:
         .                   //
         .                   //      for item in iterator {
         .                   //          self.push(item);
         .                   //      }
   113,144 ( 0.00%)          while let Some(element) = iterator.next() {
    27,133 ( 0.00%)              let len = self.len();
   314,008 ( 0.00%)              if len == self.capacity() {
     1,449 ( 0.00%)                  let (lower, _) = iterator.size_hint();
         .                           self.reserve(lower.saturating_add(1));
         .                       }
         .                       unsafe {
         .                           ptr::write(self.as_mut_ptr().add(len), element);
         .                           // Since next() executes user code which can panic we have to bump the length
         .                           // after each step.
         .                           // NB can't overflow since we would have had to alloc the address space
   240,920 ( 0.00%)                  self.set_len(len + 1);
         .                       }
         .                   }
     2,758 ( 0.00%)      }
         .           
         .               /// Creates a splicing iterator that replaces the specified range in the vector
         .               /// with the given `replace_with` iterator and yields the removed items.
         .               /// `replace_with` does not need to be the same length as `range`.
         .               ///
         .               /// `range` is removed even if the iterator is not consumed until the end.
         .               ///
         .               /// It is unspecified how many elements are removed from the vector
-- line 2666 ----------------------------------------
-- line 2693 ----------------------------------------
         .               #[cfg(not(no_global_oom_handling))]
         .               #[inline]
         .               #[stable(feature = "vec_splice", since = "1.21.0")]
         .               pub fn splice<R, I>(&mut self, range: R, replace_with: I) -> Splice<'_, I::IntoIter, A>
         .               where
         .                   R: RangeBounds<usize>,
         .                   I: IntoIterator<Item = T>,
         .               {
     1,980 ( 0.00%)          Splice { drain: self.drain(range), replace_with: replace_with.into_iter() }
         .               }
         .           
         .               /// Creates an iterator which uses a closure to determine if an element should be removed.
         .               ///
         .               /// If the closure returns true, then the element is removed and yielded.
         .               /// If the closure returns false, the element will remain in the vector and will not be yielded
         .               /// by the iterator.
         .               ///
-- line 2709 ----------------------------------------
-- line 2745 ----------------------------------------
         .               /// assert_eq!(evens, vec![2, 4, 6, 8, 14]);
         .               /// assert_eq!(odds, vec![1, 3, 5, 9, 11, 13, 15]);
         .               /// ```
         .               #[unstable(feature = "drain_filter", reason = "recently added", issue = "43244")]
         .               pub fn drain_filter<F>(&mut self, filter: F) -> DrainFilter<'_, T, F, A>
         .               where
         .                   F: FnMut(&mut T) -> bool,
         .               {
     3,306 ( 0.00%)          let old_len = self.len();
         .           
         .                   // Guard against us getting leaked (leak amplification)
         .                   unsafe {
         .                       self.set_len(0);
         .                   }
         .           
     6,936 ( 0.00%)          DrainFilter { vec: self, idx: 0, del: 0, old_len, pred: filter, panic_flag: false }
         .               }
         .           }
         .           
         .           /// Extend implementation that copies elements out of references before pushing them onto the Vec.
         .           ///
         .           /// This implementation is specialized for slice iterators, where it uses [`copy_from_slice`] to
         .           /// append the entire slice at once.
         .           ///
         .           /// [`copy_from_slice`]: slice::copy_from_slice
         .           #[cfg(not(no_global_oom_handling))]
         .           #[stable(feature = "extend_ref", since = "1.2.0")]
         .           impl<'a, T: Copy + 'a, A: Allocator + 'a> Extend<&'a T> for Vec<T, A> {
    12,840 ( 0.00%)      fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {
         .                   self.spec_extend(iter.into_iter())
     9,630 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn extend_one(&mut self, &item: &'a T) {
         .                   self.push(item);
         .               }
         .           
         .               #[inline]
         .               fn extend_reserve(&mut self, additional: usize) {
-- line 2783 ----------------------------------------
-- line 2803 ----------------------------------------
         .               #[inline]
         .               fn cmp(&self, other: &Self) -> Ordering {
         .                   Ord::cmp(&**self, &**other)
         .               }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           unsafe impl<#[may_dangle] T, A: Allocator> Drop for Vec<T, A> {
   897,706 ( 0.01%)      fn drop(&mut self) {
         .                   unsafe {
         .                       // use drop for [T]
         .                       // use a raw slice to refer to the elements of the vector as weakest necessary type;
         .                       // could avoid questions of validity in certain cases
   380,249 ( 0.00%)              ptr::drop_in_place(ptr::slice_from_raw_parts_mut(self.as_mut_ptr(), self.len))
         .                   }
         .                   // RawVec handles deallocation
 1,057,216 ( 0.01%)      }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           #[rustc_const_unstable(feature = "const_default_impls", issue = "87864")]
         .           impl<T> const Default for Vec<T> {
         .               /// Creates an empty `Vec<T>`.
         .               fn default() -> Vec<T> {
         .                   Vec::new()
-- line 2827 ----------------------------------------
-- line 2976 ----------------------------------------
         .               /// newly-allocated buffer with exactly the right capacity.
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// assert_eq!(Box::from(vec![1, 2, 3]), vec![1, 2, 3].into_boxed_slice());
         .               /// ```
         .               fn from(v: Vec<T, A>) -> Self {
         4 ( 0.00%)          v.into_boxed_slice()
         .               }
         .           }
         .           
         .           #[cfg(not(no_global_oom_handling))]
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl From<&str> for Vec<u8> {
         .               /// Allocate a `Vec<u8>` and fill it with a UTF-8 string.
         .               ///
-- line 2992 ----------------------------------------

 2,204,400 ( 0.03%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/library/alloc/src/vec/mod.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/library/core/src/iter/traits/iterator.rs
--------------------------------------------------------------------------------
Ir                  

-- line 193 ----------------------------------------
         .               /// assert_eq!(a.iter().count(), 5);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn count(self) -> usize
         .               where
         .                   Self: Sized,
         .               {
    17,629 ( 0.00%)          self.fold(
         .                       0,
         .                       #[rustc_inherit_overflow_checks]
    10,412 ( 0.00%)              |count, _| count + 1,
         .                   )
         .               }
         .           
         .               /// Consumes the iterator, returning the last element.
         .               ///
         .               /// This method will evaluate the iterator until it returns [`None`]. While
         .               /// doing so, it keeps track of the current element. After [`None`] is
         .               /// returned, `last()` will then return the last element it saw.
-- line 212 ----------------------------------------
-- line 267 ----------------------------------------
         .               /// assert_eq!(iter.next(), Some(&3));
         .               /// assert_eq!(iter.advance_by(0), Ok(()));
         .               /// assert_eq!(iter.advance_by(100), Err(1)); // only `&4` was skipped
         .               /// ```
         .               #[inline]
         .               #[unstable(feature = "iter_advance_by", reason = "recently added", issue = "77404")]
         .               fn advance_by(&mut self, n: usize) -> Result<(), usize> {
         .                   for i in 0..n {
     1,771 ( 0.00%)              self.next().ok_or(i)?;
         .                   }
         .                   Ok(())
         .               }
         .           
         .               /// Returns the `n`th element of the iterator.
         .               ///
         .               /// Like most indexing operations, the count starts from zero, so `nth(0)`
         .               /// returns the first value, `nth(1)` the second, and so on.
-- line 283 ----------------------------------------
-- line 313 ----------------------------------------
         .               /// Returning `None` if there are less than `n + 1` elements:
         .               ///
         .               /// ```
         .               /// let a = [1, 2, 3];
         .               /// assert_eq!(a.iter().nth(10), None);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
       112 ( 0.00%)      fn nth(&mut self, n: usize) -> Option<Self::Item> {
         .                   self.advance_by(n).ok()?;
     4,191 ( 0.00%)          self.next()
         .               }
         .           
         .               /// Creates an iterator starting at the same point, but stepping by
         .               /// the given amount at each iteration.
         .               ///
         .               /// Note 1: The first element of the iterator will always be returned,
         .               /// regardless of the step given.
         .               ///
-- line 331 ----------------------------------------
-- line 441 ----------------------------------------
         .               /// [`OsStr`]: ../../std/ffi/struct.OsStr.html
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn chain<U>(self, other: U) -> Chain<Self, U::IntoIter>
         .               where
         .                   Self: Sized,
         .                   U: IntoIterator<Item = Self::Item>,
         .               {
    33,040 ( 0.00%)          Chain::new(self, other.into_iter())
         .               }
         .           
         .               /// 'Zips up' two iterators into a single iterator of pairs.
         .               ///
         .               /// `zip()` returns a new iterator that will iterate over two other
         .               /// iterators, returning a tuple where the first element comes from the
         .               /// first iterator, and the second element comes from the second iterator.
         .               ///
-- line 457 ----------------------------------------
-- line 555 ----------------------------------------
         .               /// [`zip`]: crate::iter::zip
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn zip<U>(self, other: U) -> Zip<Self, U::IntoIter>
         .               where
         .                   Self: Sized,
         .                   U: IntoIterator,
         .               {
       106 ( 0.00%)          Zip::new(self, other.into_iter())
         .               }
         .           
         .               /// Creates a new iterator which places a copy of `separator` between adjacent
         .               /// items of the original iterator.
         .               ///
         .               /// In case `separator` does not implement [`Clone`] or needs to be
         .               /// computed every time, use [`intersperse_with`].
         .               ///
-- line 571 ----------------------------------------
-- line 714 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn map<B, F>(self, f: F) -> Map<Self, F>
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item) -> B,
         .               {
   116,937 ( 0.00%)          Map::new(self, f)
         .               }
         .           
         .               /// Calls a closure on each element of an iterator.
         .               ///
         .               /// This is equivalent to using a [`for`] loop on the iterator, although
         .               /// `break` and `continue` are not possible from a closure. It's generally
         .               /// more idiomatic to use a `for` loop, but `for_each` may be more legible
         .               /// when processing items at the end of longer iterator chains. In some
-- line 730 ----------------------------------------
-- line 761 ----------------------------------------
         .               #[stable(feature = "iterator_for_each", since = "1.21.0")]
         .               fn for_each<F>(self, f: F)
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item),
         .               {
         .                   #[inline]
         .                   fn call<T>(mut f: impl FnMut(T)) -> impl FnMut((), T) {
     1,465 ( 0.00%)              move |(), item| f(item)
         .                   }
         .           
 1,282,198 ( 0.01%)          self.fold((), call(f));
         .               }
         .           
         .               /// Creates an iterator which uses a closure to determine if an element
         .               /// should be yielded.
         .               ///
         .               /// Given an element the closure must return `true` or `false`. The returned
         .               /// iterator will yield only the elements for which the closure returns
         .               /// true.
-- line 780 ----------------------------------------
-- line 834 ----------------------------------------
         .               /// Note that `iter.filter(f).next()` is equivalent to `iter.find(f)`.
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn filter<P>(self, predicate: P) -> Filter<Self, P>
         .               where
         .                   Self: Sized,
         .                   P: FnMut(&Self::Item) -> bool,
         .               {
    22,740 ( 0.00%)          Filter::new(self, predicate)
         .               }
         .           
         .               /// Creates an iterator that both filters and maps.
         .               ///
         .               /// The returned iterator yields only the `value`s for which the supplied
         .               /// closure returns `Some(value)`.
         .               ///
         .               /// `filter_map` can be used to make chains of [`filter`] and [`map`] more
-- line 850 ----------------------------------------
-- line 879 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn filter_map<B, F>(self, f: F) -> FilterMap<Self, F>
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item) -> Option<B>,
         .               {
     7,307 ( 0.00%)          FilterMap::new(self, f)
         .               }
         .           
         .               /// Creates an iterator which gives the current iteration count as well as
         .               /// the next value.
         .               ///
         .               /// The iterator returned yields pairs `(i, val)`, where `i` is the
         .               /// current index of iteration and `val` is the value returned by the
         .               /// iterator.
-- line 895 ----------------------------------------
-- line 924 ----------------------------------------
         .               /// assert_eq!(iter.next(), None);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn enumerate(self) -> Enumerate<Self>
         .               where
         .                   Self: Sized,
         .               {
        16 ( 0.00%)          Enumerate::new(self)
         .               }
         .           
         .               /// Creates an iterator which can use the [`peek`] and [`peek_mut`] methods
         .               /// to look at the next element of the iterator without consuming it. See
         .               /// their documentation for more information.
         .               ///
         .               /// Note that the underlying iterator is still advanced when [`peek`] or
         .               /// [`peek_mut`] are called for the first time: In order to retrieve the
-- line 940 ----------------------------------------
-- line 995 ----------------------------------------
         .               /// [`peek_mut`]: Peekable::peek_mut
         .               /// [`next`]: Iterator::next
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn peekable(self) -> Peekable<Self>
         .               where
         .                   Self: Sized,
         .               {
        13 ( 0.00%)          Peekable::new(self)
         .               }
         .           
         .               /// Creates an iterator that [`skip`]s elements based on a predicate.
         .               ///
         .               /// [`skip`]: Iterator::skip
         .               ///
         .               /// `skip_while()` takes a closure as an argument. It will call this
         .               /// closure on each element of the iterator, and ignore elements
-- line 1011 ----------------------------------------
-- line 1537 ----------------------------------------
         .               /// assert_eq!(iter.next(), None);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn fuse(self) -> Fuse<Self>
         .               where
         .                   Self: Sized,
         .               {
     3,300 ( 0.00%)          Fuse::new(self)
         .               }
         .           
         .               /// Does something with each element of an iterator, passing the value on.
         .               ///
         .               /// When using iterators, you'll often chain several of them together.
         .               /// While working on such code, you might want to check out what's
         .               /// happening at various parts in the pipeline. To do that, insert
         .               /// a call to `inspect()`.
-- line 1553 ----------------------------------------
-- line 1769 ----------------------------------------
         .               /// [`char`]: type@char
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               #[must_use = "if you really need to exhaust the iterator, consider `.for_each(drop)` instead"]
         .               fn collect<B: FromIterator<Self::Item>>(self) -> B
         .               where
         .                   Self: Sized,
         .               {
    20,315 ( 0.00%)          FromIterator::from_iter(self)
         .               }
         .           
         .               /// Consumes an iterator, creating two collections from it.
         .               ///
         .               /// The predicate passed to `partition()` can return `true`, or `false`.
         .               /// `partition()` returns a pair, all of the elements for which it returned
         .               /// `true`, and all of the elements for which it returned `false`.
         .               ///
-- line 1785 ----------------------------------------
-- line 1798 ----------------------------------------
         .               /// let (even, odd): (Vec<i32>, Vec<i32>) = a
         .               ///     .iter()
         .               ///     .partition(|&n| n % 2 == 0);
         .               ///
         .               /// assert_eq!(even, vec![2]);
         .               /// assert_eq!(odd, vec![1, 3]);
         .               /// ```
         .               #[stable(feature = "rust1", since = "1.0.0")]
       696 ( 0.00%)      fn partition<B, F>(self, f: F) -> (B, B)
         .               where
         .                   Self: Sized,
         .                   B: Default + Extend<Self::Item>,
         .                   F: FnMut(&Self::Item) -> bool,
         .               {
         .                   #[inline]
         .                   fn extend<'a, T, B: Extend<T>>(
         .                       mut f: impl FnMut(&T) -> bool + 'a,
         .                       left: &'a mut B,
         .                       right: &'a mut B,
         .                   ) -> impl FnMut((), T) + 'a {
         .                       move |(), x| {
        65 ( 0.00%)                  if f(&x) {
         .                               left.extend_one(x);
         .                           } else {
         .                               right.extend_one(x);
         .                           }
         .                       }
         .                   }
         .           
         .                   let mut left: B = Default::default();
         .                   let mut right: B = Default::default();
         .           
         4 ( 0.00%)          self.fold((), extend(f, &mut left, &mut right));
         .           
     1,040 ( 0.00%)          (left, right)
       783 ( 0.00%)      }
         .           
         .               /// Reorders the elements of this iterator *in-place* according to the given predicate,
         .               /// such that all those that return `true` precede all those that return `false`.
         .               /// Returns the number of `true` elements found.
         .               ///
         .               /// The relative order of partitioned items is not maintained.
         .               ///
         .               /// # Current implementation
-- line 1841 ----------------------------------------
-- line 2011 ----------------------------------------
         .               ///     } else {
         .               ///         ControlFlow::Break(prev)
         .               ///     }
         .               /// });
         .               /// assert_eq!(triangular, ControlFlow::Continue(435));
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "iterator_try_fold", since = "1.27.0")]
     5,476 ( 0.00%)      fn try_fold<B, F, R>(&mut self, init: B, mut f: F) -> R
         .               where
         .                   Self: Sized,
         .                   F: FnMut(B, Self::Item) -> R,
         .                   R: Try<Output = B>,
         .               {
     8,221 ( 0.00%)          let mut accum = init;
 1,747,509 ( 0.02%)          while let Some(x) = self.next() {
 2,598,229 ( 0.03%)              accum = f(accum, x)?;
         .                   }
    14,629 ( 0.00%)          try { accum }
     5,240 ( 0.00%)      }
         .           
         .               /// An iterator method that applies a fallible function to each item in the
         .               /// iterator, stopping at the first error and returning that error.
         .               ///
         .               /// This can also be thought of as the fallible form of [`for_each()`]
         .               /// or as the stateless version of [`try_fold()`].
         .               ///
         .               /// [`for_each()`]: Iterator::for_each
-- line 2038 ----------------------------------------
-- line 2077 ----------------------------------------
         .               fn try_for_each<F, R>(&mut self, f: F) -> R
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item) -> R,
         .                   R: Try<Output = ()>,
         .               {
         .                   #[inline]
         .                   fn call<T, R>(mut f: impl FnMut(T) -> R) -> impl FnMut((), T) -> R {
     1,536 ( 0.00%)              move |(), x| f(x)
         .                   }
         .           
       238 ( 0.00%)          self.try_fold((), call(f))
         .               }
         .           
         .               /// Folds every element into an accumulator by applying an operation,
         .               /// returning the final result.
         .               ///
         .               /// `fold()` takes two arguments: an initial value, and a closure with two
         .               /// arguments: an 'accumulator', and an element. The closure returns the value that
         .               /// the accumulator should have for the next iteration.
-- line 2096 ----------------------------------------
-- line 2188 ----------------------------------------
         .               /// // they're the same
         .               /// assert_eq!(result, result2);
         .               /// ```
         .               ///
         .               /// [`reduce()`]: Iterator::reduce
         .               #[doc(alias = "inject", alias = "foldl")]
         .               #[inline]
         .               #[stable(feature = "rust1", since = "1.0.0")]
     4,753 ( 0.00%)      fn fold<B, F>(mut self, init: B, mut f: F) -> B
         .               where
         .                   Self: Sized,
         .                   F: FnMut(B, Self::Item) -> B,
         .               {
     4,434 ( 0.00%)          let mut accum = init;
10,399,677 ( 0.12%)          while let Some(x) = self.next() {
   203,399 ( 0.00%)              accum = f(accum, x);
         .                   }
         .                   accum
     5,484 ( 0.00%)      }
         .           
         .               /// Reduces the elements to a single one, by repeatedly applying a reducing
         .               /// operation.
         .               ///
         .               /// If the iterator is empty, returns [`None`]; otherwise, returns the
         .               /// result of the reduction.
         .               ///
         .               /// The reducing function is a closure with two arguments: an 'accumulator', and an element.
-- line 2214 ----------------------------------------
-- line 2240 ----------------------------------------
         .               #[inline]
         .               #[stable(feature = "iterator_fold_self", since = "1.51.0")]
         .               fn reduce<F>(mut self, f: F) -> Option<Self::Item>
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item, Self::Item) -> Self::Item,
         .               {
         .                   let first = self.next()?;
    12,155 ( 0.00%)          Some(self.fold(first, f))
         .               }
         .           
         .               /// Reduces the elements to a single one by repeatedly applying a reducing operation. If the
         .               /// closure returns a failure, the failure is propagated back to the caller immediately.
         .               ///
         .               /// The return type of this method depends on the return type of the closure. If the closure
         .               /// returns `Result<Self::Item, E>`, then this function will return `Result<Option<Self::Item>,
         .               /// E>`. If the closure returns `Option<Self::Item>`, then this function will return
-- line 2256 ----------------------------------------
-- line 2370 ----------------------------------------
         .               fn all<F>(&mut self, f: F) -> bool
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item) -> bool,
         .               {
         .                   #[inline]
         .                   fn check<T>(mut f: impl FnMut(T) -> bool) -> impl FnMut((), T) -> ControlFlow<()> {
         .                       move |(), x| {
     2,976 ( 0.00%)                  if f(x) { ControlFlow::CONTINUE } else { ControlFlow::BREAK }
         .                       }
         .                   }
     7,451 ( 0.00%)          self.try_fold((), check(f)) == ControlFlow::CONTINUE
         .               }
         .           
         .               /// Tests if any element of the iterator matches a predicate.
         .               ///
         .               /// `any()` takes a closure that returns `true` or `false`. It applies
         .               /// this closure to each element of the iterator, and if any of them return
         .               /// `true`, then so does `any()`. If they all return `false`, it
         .               /// returns `false`.
-- line 2389 ----------------------------------------
-- line 2423 ----------------------------------------
         .               fn any<F>(&mut self, f: F) -> bool
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item) -> bool,
         .               {
         .                   #[inline]
         .                   fn check<T>(mut f: impl FnMut(T) -> bool) -> impl FnMut((), T) -> ControlFlow<()> {
         .                       move |(), x| {
        48 ( 0.00%)                  if f(x) { ControlFlow::BREAK } else { ControlFlow::CONTINUE }
         .                       }
         .                   }
         .           
         .                   self.try_fold((), check(f)) == ControlFlow::BREAK
         .               }
         .           
         .               /// Searches for an element of an iterator that satisfies a predicate.
         .               ///
-- line 2439 ----------------------------------------
-- line 2483 ----------------------------------------
         .               fn find<P>(&mut self, predicate: P) -> Option<Self::Item>
         .               where
         .                   Self: Sized,
         .                   P: FnMut(&Self::Item) -> bool,
         .               {
         .                   #[inline]
         .                   fn check<T>(mut predicate: impl FnMut(&T) -> bool) -> impl FnMut((), T) -> ControlFlow<T> {
         .                       move |(), x| {
    31,105 ( 0.00%)                  if predicate(&x) { ControlFlow::Break(x) } else { ControlFlow::CONTINUE }
         .                       }
         .                   }
         .           
    45,791 ( 0.00%)          self.try_fold((), check(predicate)).break_value()
         .               }
         .           
         .               /// Applies function to the elements of iterator and returns
         .               /// the first non-none result.
         .               ///
         .               /// `iter.find_map(f)` is equivalent to `iter.filter_map(f).next()`.
         .               ///
         .               /// # Examples
-- line 2503 ----------------------------------------
-- line 2513 ----------------------------------------
         .               #[stable(feature = "iterator_find_map", since = "1.30.0")]
         .               fn find_map<B, F>(&mut self, f: F) -> Option<B>
         .               where
         .                   Self: Sized,
         .                   F: FnMut(Self::Item) -> Option<B>,
         .               {
         .                   #[inline]
         .                   fn check<T, B>(mut f: impl FnMut(T) -> Option<B>) -> impl FnMut((), T) -> ControlFlow<B> {
    66,530 ( 0.00%)              move |(), x| match f(x) {
    59,630 ( 0.00%)                  Some(x) => ControlFlow::Break(x),
         .                           None => ControlFlow::CONTINUE,
         .                       }
         .                   }
         .           
     5,519 ( 0.00%)          self.try_fold((), check(f)).break_value()
         .               }
         .           
         .               /// Applies function to the elements of iterator and returns
         .               /// the first true result or the first error.
         .               ///
         .               /// The return type of this method depends on the return type of the closure.
         .               /// If you return `Result<bool, E>` from the closure, you'll get a `Result<Option<Self::Item>; E>`.
         .               /// If you return `Option<bool>` from the closure, you'll get an `Option<Option<Self::Item>>`.
-- line 2535 ----------------------------------------
-- line 2713 ----------------------------------------
         .               {
         .                   // No need for an overflow check here, because `ExactSizeIterator`
         .                   // implies that the number of elements fits into a `usize`.
         .                   #[inline]
         .                   fn check<T>(
         .                       mut predicate: impl FnMut(T) -> bool,
         .                   ) -> impl FnMut(usize, T) -> ControlFlow<usize, usize> {
         .                       move |i, x| {
         9 ( 0.00%)                  let i = i - 1;
         .                           if predicate(x) { ControlFlow::Break(i) } else { ControlFlow::Continue(i) }
         .                       }
         .                   }
         .           
         .                   let n = self.len();
         .                   self.try_rfold(n, check(predicate)).break_value()
         .               }
         .           
-- line 2729 ----------------------------------------
-- line 2812 ----------------------------------------
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// let a = [-3_i32, 0, 1, 5, -10];
         .               /// assert_eq!(*a.iter().max_by_key(|x| x.abs()).unwrap(), -10);
         .               /// ```
         .               #[inline]
         .               #[stable(feature = "iter_cmp_by_key", since = "1.6.0")]
       511 ( 0.00%)      fn max_by_key<B: Ord, F>(self, f: F) -> Option<Self::Item>
         .               where
         .                   Self: Sized,
         .                   F: FnMut(&Self::Item) -> B,
         .               {
         .                   #[inline]
         .                   fn key<T, B>(mut f: impl FnMut(&T) -> B) -> impl FnMut(T) -> (B, T) {
       380 ( 0.00%)              move |x| (f(&x), x)
         .                   }
         .           
         .                   #[inline]
         .                   fn compare<T, B: Ord>((x_p, _): &(B, T), (y_p, _): &(B, T)) -> Ordering {
         .                       x_p.cmp(y_p)
         .                   }
         .           
     1,042 ( 0.00%)          let (_, x) = self.map(key(f)).max_by(compare)?;
         .                   Some(x)
       584 ( 0.00%)      }
         .           
         .               /// Returns the element that gives the maximum value with respect to the
         .               /// specified comparison function.
         .               ///
         .               /// If several elements are equally maximum, the last element is
         .               /// returned. If the iterator is empty, [`None`] is returned.
         .               ///
         .               /// # Examples
-- line 2845 ----------------------------------------
-- line 2852 ----------------------------------------
         .               #[stable(feature = "iter_max_by", since = "1.15.0")]
         .               fn max_by<F>(self, compare: F) -> Option<Self::Item>
         .               where
         .                   Self: Sized,
         .                   F: FnMut(&Self::Item, &Self::Item) -> Ordering,
         .               {
         .                   #[inline]
         .                   fn fold<T>(mut compare: impl FnMut(&T, &T) -> Ordering) -> impl FnMut(T, T) -> T {
       252 ( 0.00%)              move |x, y| cmp::max_by(x, y, &mut compare)
         .                   }
         .           
     9,696 ( 0.00%)          self.reduce(fold(compare))
         .               }
         .           
         .               /// Returns the element that gives the minimum value from the
         .               /// specified function.
         .               ///
         .               /// If several elements are equally minimum, the first element is
         .               /// returned. If the iterator is empty, [`None`] is returned.
         .               ///
-- line 2871 ----------------------------------------
-- line 2946 ----------------------------------------
         .               /// ```
         .               #[inline]
         .               #[doc(alias = "reverse")]
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn rev(self) -> Rev<Self>
         .               where
         .                   Self: Sized + DoubleEndedIterator,
         .               {
        13 ( 0.00%)          Rev::new(self)
         .               }
         .           
         .               /// Converts an iterator of pairs into a pair of containers.
         .               ///
         .               /// `unzip()` consumes an entire iterator of pairs, producing two
         .               /// collections: one from the left elements of the pairs, and one
         .               /// from the right elements.
         .               ///
-- line 2962 ----------------------------------------
-- line 2987 ----------------------------------------
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn unzip<A, B, FromA, FromB>(self) -> (FromA, FromB)
         .               where
         .                   FromA: Default + Extend<A>,
         .                   FromB: Default + Extend<B>,
         .                   Self: Sized + Iterator<Item = (A, B)>,
         .               {
         .                   let mut unzipped: (FromA, FromB) = Default::default();
     1,605 ( 0.00%)          unzipped.extend(self);
         .                   unzipped
         .               }
         .           
         .               /// Creates an iterator which copies all of its elements.
         .               ///
         .               /// This is useful when you have an iterator over `&T`, but you need an
         .               /// iterator over `T`.
         .               ///
-- line 3003 ----------------------------------------
-- line 3017 ----------------------------------------
         .               /// assert_eq!(v_map, vec![1, 2, 3]);
         .               /// ```
         .               #[stable(feature = "iter_copied", since = "1.36.0")]
         .               fn copied<'a, T: 'a>(self) -> Copied<Self>
         .               where
         .                   Self: Sized + Iterator<Item = &'a T>,
         .                   T: Copy,
         .               {
    17,572 ( 0.00%)          Copied::new(self)
         .               }
         .           
         .               /// Creates an iterator which [`clone`]s all of its elements.
         .               ///
         .               /// This is useful when you have an iterator over `&T`, but you need an
         .               /// iterator over `T`.
         .               ///
         .               /// [`clone`]: Clone::clone
-- line 3033 ----------------------------------------
-- line 3048 ----------------------------------------
         .               /// assert_eq!(v_map, vec![1, 2, 3]);
         .               /// ```
         .               #[stable(feature = "rust1", since = "1.0.0")]
         .               fn cloned<'a, T: 'a>(self) -> Cloned<Self>
         .               where
         .                   Self: Sized + Iterator<Item = &'a T>,
         .                   T: Clone,
         .               {
    80,279 ( 0.00%)          Cloned::new(self)
         .               }
         .           
         .               /// Repeats an iterator endlessly.
         .               ///
         .               /// Instead of stopping at [`None`], the iterator will instead start again,
         .               /// from the beginning. After iterating again, it will start at the
         .               /// beginning again. And again. And again. Forever. Note that in case the
         .               /// original iterator is empty, the resulting iterator will also be empty.
-- line 3064 ----------------------------------------
-- line 3313 ----------------------------------------
         .               ///
         .               /// # Examples
         .               ///
         .               /// ```
         .               /// assert_eq!([1].iter().eq([1].iter()), true);
         .               /// assert_eq!([1].iter().eq([1, 2].iter()), false);
         .               /// ```
         .               #[stable(feature = "iter_order", since = "1.5.0")]
       483 ( 0.00%)      fn eq<I>(self, other: I) -> bool
         .               where
         .                   I: IntoIterator,
         .                   Self::Item: PartialEq<I::Item>,
         .                   Self: Sized,
         .               {
       552 ( 0.00%)          self.eq_by(other, |x, y| x == y)
       552 ( 0.00%)      }
         .           
         .               /// Determines if the elements of this [`Iterator`] are equal to those of
         .               /// another with respect to the specified equality function.
         .               ///
         .               /// # Examples
         .               ///
         .               /// Basic usage:
         .               ///
-- line 3336 ----------------------------------------
-- line 3344 ----------------------------------------
         .               /// ```
         .               #[unstable(feature = "iter_order_by", issue = "64295")]
         .               fn eq_by<I, F>(mut self, other: I, mut eq: F) -> bool
         .               where
         .                   Self: Sized,
         .                   I: IntoIterator,
         .                   F: FnMut(Self::Item, I::Item) -> bool,
         .               {
       690 ( 0.00%)          let mut other = other.into_iter();
         .           
         .                   loop {
       210 ( 0.00%)              let x = match self.next() {
         .                           None => return other.next().is_none(),
       770 ( 0.00%)                  Some(val) => val,
         .                       };
         .           
       210 ( 0.00%)              let y = match other.next() {
         .                           None => return false,
         .                           Some(val) => val,
         .                       };
         .           
         7 ( 0.00%)              if !eq(x, y) {
         .                           return false;
         .                       }
         .                   }
         .               }
         .           
         .               /// Determines if the elements of this [`Iterator`] are unequal to those of
         .               /// another.
         .               ///
-- line 3373 ----------------------------------------
-- line 3589 ----------------------------------------
         .                   unreachable!("Always specialized");
         .               }
         .           }
         .           
         .           #[stable(feature = "rust1", since = "1.0.0")]
         .           impl<I: Iterator + ?Sized> Iterator for &mut I {
         .               type Item = I::Item;
         .               #[inline]
       100 ( 0.00%)      fn next(&mut self) -> Option<I::Item> {
    81,487 ( 0.00%)          (**self).next()
       150 ( 0.00%)      }
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         6 ( 0.00%)          (**self).size_hint()
         .               }
         .               fn advance_by(&mut self, n: usize) -> Result<(), usize> {
         .                   (**self).advance_by(n)
         .               }
         .               fn nth(&mut self, n: usize) -> Option<Self::Item> {
         .                   (**self).nth(n)
         .               }
         .           }
-- line 3609 ----------------------------------------

 1,516,304 ( 0.02%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/library/core/src/iter/traits/iterator.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs
--------------------------------------------------------------------------------
Ir                  

-- line 111 ----------------------------------------
         .           const EMPTY: u8 = 0b1111_1111;
         .           
         .           /// Control byte value for a deleted bucket.
         .           const DELETED: u8 = 0b1000_0000;
         .           
         .           /// Checks whether a control byte represents a full bucket (top bit is clear).
         .           #[inline]
         .           fn is_full(ctrl: u8) -> bool {
 2,083,658 ( 0.02%)      ctrl & 0x80 == 0
         .           }
         .           
         .           /// Checks whether a control byte represents a special value (top bit is set).
         .           #[inline]
         .           fn is_special(ctrl: u8) -> bool {
         .               ctrl & 0x80 != 0
         .           }
         .           
         .           /// Checks whether a special control value is EMPTY (just check 1 bit).
         .           #[inline]
         .           fn special_is_empty(ctrl: u8) -> bool {
         .               debug_assert!(is_special(ctrl));
   162,224 ( 0.00%)      ctrl & 0x01 != 0
         .           }
         .           
         .           /// Primary hash function, used to select the initial bucket to probe from.
         .           #[inline]
         .           #[allow(clippy::cast_possible_truncation)]
         .           fn h1(hash: u64) -> usize {
         .               // On 32-bit platforms we simply ignore the higher hash bits.
         .               hash as usize
-- line 140 ----------------------------------------
-- line 143 ----------------------------------------
         .           /// Secondary hash function, saved in the low 7 bits of the control byte.
         .           #[inline]
         .           #[allow(clippy::cast_possible_truncation)]
         .           fn h2(hash: u64) -> u8 {
         .               // Grab the top 7 bits of the hash. While the hash is normally a full 64-bit
         .               // value, some hash functions (such as FxHash) produce a usize result
         .               // instead, which means that the top 32 bits are 0 on 32-bit platforms.
         .               let hash_len = usize::min(mem::size_of::<usize>(), mem::size_of::<u64>());
33,939,885 ( 0.39%)      let top7 = hash >> (hash_len * 8 - 7);
         .               (top7 & 0x7f) as u8 // truncation
         .           }
         .           
         .           /// Probe sequence based on triangular numbers, which is guaranteed (since our
         .           /// table size is a power of two) to visit every group of elements exactly once.
         .           ///
         .           /// A triangular probe has us jump by 1 more group every time. So first we
         .           /// jump by 1 group (meaning we just continue our linear scan), then 2 groups
-- line 159 ----------------------------------------
-- line 170 ----------------------------------------
         .               #[inline]
         .               fn move_next(&mut self, bucket_mask: usize) {
         .                   // We should have found an empty bucket by now and ended the probe.
         .                   debug_assert!(
         .                       self.stride <= bucket_mask,
         .                       "Went past end of probe sequence"
         .                   );
         .           
   251,504 ( 0.00%)          self.stride += Group::WIDTH;
   251,504 ( 0.00%)          self.pos += self.stride;
   210,779 ( 0.00%)          self.pos &= bucket_mask;
         .               }
         .           }
         .           
         .           /// Returns the number of buckets needed to hold the given number of items,
         .           /// taking the maximum load factor into account.
         .           ///
         .           /// Returns `None` if an overflow occurs.
         .           // Workaround for emscripten bug emscripten-core/emscripten-fastcomp#258
         .           #[cfg_attr(target_os = "emscripten", inline(never))]
         .           #[cfg_attr(not(target_os = "emscripten"), inline)]
         .           fn capacity_to_buckets(cap: usize) -> Option<usize> {
         .               debug_assert_ne!(cap, 0);
         .           
         .               // For small tables we require at least 1 empty bucket so that lookups are
         .               // guaranteed to terminate if an element doesn't exist in the table.
   156,550 ( 0.00%)      if cap < 8 {
         .                   // We don't bother with a table size of 2 buckets since that can only
         .                   // hold a single element. Instead we skip directly to a 4 bucket table
         .                   // which can hold 3 elements.
   333,145 ( 0.00%)          return Some(if cap < 4 { 4 } else { 8 });
         .               }
         .           
         .               // Otherwise require 1/8 buckets to be empty (87.5% load)
         .               //
         .               // Be careful when modifying this, calculate_layout relies on the
         .               // overflow check here.
    69,876 ( 0.00%)      let adjusted_cap = cap.checked_mul(8)? / 7;
         .           
         .               // Any overflows will have been caught by the checked_mul. Also, any
         .               // rounding errors from the division above will be cleaned up by
         .               // next_power_of_two (which can't overflow because of the previous division).
         .               Some(adjusted_cap.next_power_of_two())
         .           }
         .           
         .           /// Returns the maximum effective capacity for the given bucket mask, taking
         .           /// the maximum load factor into account.
         .           #[inline]
         .           fn bucket_mask_to_capacity(bucket_mask: usize) -> usize {
   413,636 ( 0.00%)      if bucket_mask < 8 {
         .                   // For tables with 1/2/4/8 buckets, we always reserve one empty slot.
         .                   // Keep in mind that the bucket mask is one less than the bucket count.
         .                   bucket_mask
         .               } else {
         .                   // For larger tables we reserve 12.5% of the slots as empty.
    78,172 ( 0.00%)          ((bucket_mask + 1) / 8) * 7
         .               }
         .           }
         .           
         .           /// Helper which allows the max calculation for ctrl_align to be statically computed for each T
         .           /// while keeping the rest of `calculate_layout_for` independent of `T`
         .           #[derive(Copy, Clone)]
         .           struct TableLayout {
         .               size: usize,
-- line 233 ----------------------------------------
-- line 246 ----------------------------------------
         .           
         .               #[inline]
         .               fn calculate_layout_for(self, buckets: usize) -> Option<(Layout, usize)> {
         .                   debug_assert!(buckets.is_power_of_two());
         .           
         .                   let TableLayout { size, ctrl_align } = self;
         .                   // Manual layout calculation since Layout methods are not yet stable.
         .                   let ctrl_offset =
   317,039 ( 0.00%)              size.checked_mul(buckets)?.checked_add(ctrl_align - 1)? & !(ctrl_align - 1);
   425,458 ( 0.00%)          let len = ctrl_offset.checked_add(buckets + Group::WIDTH)?;
         .           
         .                   Some((
         .                       unsafe { Layout::from_size_align_unchecked(len, ctrl_align) },
         .                       ctrl_offset,
         .                   ))
         .               }
         .           }
         .           
-- line 263 ----------------------------------------
-- line 337 ----------------------------------------
         .                   }
         .               }
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub unsafe fn drop(&self) {
         .                   self.as_ptr().drop_in_place();
         .               }
         .               #[inline]
         .               pub unsafe fn read(&self) -> T {
     1,106 ( 0.00%)          self.as_ptr().read()
         .               }
         .               #[inline]
         .               pub unsafe fn write(&self, val: T) {
         .                   self.as_ptr().write(val);
         .               }
         .               #[inline]
         .               pub unsafe fn as_ref<'a>(&self) -> &'a T {
         .                   &*self.as_ptr()
-- line 353 ----------------------------------------
-- line 422 ----------------------------------------
         .               /// Creates a new empty hash table without allocating any memory, using the
         .               /// given allocator.
         .               ///
         .               /// In effect this returns a table with exactly 1 bucket. However we can
         .               /// leave the data pointer dangling since that bucket is never written to
         .               /// due to our load factor forcing us to always have at least 1 free bucket.
         .               #[inline]
         .               pub fn new_in(alloc: A) -> Self {
     1,416 ( 0.00%)          Self {
         .                       table: RawTableInner::new_in(alloc),
         .                       marker: PhantomData,
         .                   }
         .               }
         .           
         .               /// Allocates a new hash table with the given number of buckets.
         .               ///
         .               /// The control bytes are left uninitialized.
-- line 438 ----------------------------------------
-- line 440 ----------------------------------------
         .               unsafe fn new_uninitialized(
         .                   alloc: A,
         .                   buckets: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
         .                   debug_assert!(buckets.is_power_of_two());
         .           
         .                   Ok(Self {
       340 ( 0.00%)              table: RawTableInner::new_uninitialized(
         .                           alloc,
         .                           TableLayout::new::<T>(),
         .                           buckets,
         .                           fallibility,
         .                       )?,
         .                       marker: PhantomData,
         .                   })
         .               }
-- line 456 ----------------------------------------
-- line 458 ----------------------------------------
         .               /// Attempts to allocate a new hash table with at least enough capacity
         .               /// for inserting the given number of elements without reallocating.
         .               fn fallible_with_capacity(
         .                   alloc: A,
         .                   capacity: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
         .                   Ok(Self {
    27,545 ( 0.00%)              table: RawTableInner::fallible_with_capacity(
         .                           alloc,
         .                           TableLayout::new::<T>(),
         .                           capacity,
         .                           fallibility,
         .                       )?,
         .                       marker: PhantomData,
         .                   })
         .               }
-- line 474 ----------------------------------------
-- line 527 ----------------------------------------
         .                   debug_assert_ne!(self.table.bucket_mask, 0);
         .                   debug_assert!(index < self.buckets());
         .                   Bucket::from_base_index(self.data_end(), index)
         .               }
         .           
         .               /// Erases an element from the table without dropping it.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[deprecated(since = "0.8.1", note = "use erase or remove instead")]
    23,602 ( 0.00%)      pub unsafe fn erase_no_drop(&mut self, item: &Bucket<T>) {
    23,602 ( 0.00%)          let index = self.bucket_index(item);
         .                   self.table.erase(index);
    47,204 ( 0.00%)      }
         .           
         .               /// Erases an element from the table, dropping it in place.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[allow(clippy::needless_pass_by_value)]
         .               #[allow(deprecated)]
         .               pub unsafe fn erase(&mut self, item: Bucket<T>) {
         .                   // Erase the element from the table first since drop might panic.
    10,046 ( 0.00%)          self.erase_no_drop(&item);
         .                   item.drop();
         .               }
         .           
         .               /// Finds and erases an element from the table, dropping it in place.
         .               /// Returns true if an element was found.
         .               #[cfg(feature = "raw")]
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn erase_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> bool {
-- line 554 ----------------------------------------
-- line 563 ----------------------------------------
         .                   }
         .               }
         .           
         .               /// Removes an element from the table, returning it.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[allow(clippy::needless_pass_by_value)]
         .               #[allow(deprecated)]
         .               pub unsafe fn remove(&mut self, item: Bucket<T>) -> T {
    37,158 ( 0.00%)          self.erase_no_drop(&item);
       207 ( 0.00%)          item.read()
         .               }
         .           
         .               /// Finds and removes an element from the table, returning it.
         .               #[cfg_attr(feature = "inline-more", inline)]
   792,773 ( 0.01%)      pub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T> {
         .                   // Avoid `Option::map` because it bloats LLVM IR.
     2,406 ( 0.00%)          match self.find(hash, eq) {
     9,826 ( 0.00%)              Some(bucket) => Some(unsafe { self.remove(bucket) }),
   153,851 ( 0.00%)              None => None,
         .                   }
 1,125,694 ( 0.01%)      }
         .           
         .               /// Marks all table buckets as empty without dropping their contents.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn clear_no_drop(&mut self) {
         .                   self.table.clear_no_drop();
         .               }
         .           
         .               /// Removes all elements from the table without freeing the backing memory.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn clear(&mut self) {
         .                   // Ensure that the table is reset even if one of the drops panic
         .                   let mut self_ = guard(self, |self_| self_.clear_no_drop());
         .                   unsafe {
         1 ( 0.00%)              self_.drop_elements();
         .                   }
         .               }
         .           
         7 ( 0.00%)      unsafe fn drop_elements(&mut self) {
    16,978 ( 0.00%)          if mem::needs_drop::<T>() && !self.is_empty() {
         .                       for item in self.iter() {
         .                           item.drop();
         .                       }
         .                   }
         8 ( 0.00%)      }
         .           
         .               /// Shrinks the table to fit `max(self.len(), min_size)` elements.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64) {
         .                   // Calculate the minimal number of elements that we need to reserve
         .                   // space for.
         .                   let min_size = usize::max(self.table.items, min_size);
         .                   if min_size == 0 {
-- line 615 ----------------------------------------
-- line 642 ----------------------------------------
         .                       }
         .                   }
         .               }
         .           
         .               /// Ensures that at least `additional` items can be inserted into the table
         .               /// without reallocation.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64) {
   420,162 ( 0.00%)          if additional > self.table.growth_left {
         .                       // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.
   260,393 ( 0.00%)              if self
         .                           .reserve_rehash(additional, hasher, Fallibility::Infallible)
         .                           .is_err()
         .                       {
         .                           unsafe { hint::unreachable_unchecked() }
         .                       }
         .                   }
         .               }
         .           
-- line 660 ----------------------------------------
-- line 671 ----------------------------------------
         .                   } else {
         .                       Ok(())
         .                   }
         .               }
         .           
         .               /// Out-of-line slow path for `reserve` and `try_reserve`.
         .               #[cold]
         .               #[inline(never)]
   607,769 ( 0.01%)      fn reserve_rehash(
         .                   &mut self,
         .                   additional: usize,
         .                   hasher: impl Fn(&T) -> u64,
         .                   fallibility: Fallibility,
         .               ) -> Result<(), TryReserveError> {
         .                   unsafe {
         .                       self.table.reserve_rehash_inner(
         .                           additional,
-- line 687 ----------------------------------------
-- line 690 ----------------------------------------
         .                           TableLayout::new::<T>(),
         .                           if mem::needs_drop::<T>() {
         .                               Some(mem::transmute(ptr::drop_in_place::<T> as unsafe fn(*mut T)))
         .                           } else {
         .                               None
         .                           },
         .                       )
         .                   }
   426,152 ( 0.00%)      }
         .           
         .               /// Allocates a new table of a different size and moves the contents of the
         .               /// current table into it.
         .               fn resize(
         .                   &mut self,
         .                   capacity: usize,
         .                   hasher: impl Fn(&T) -> u64,
         .                   fallibility: Fallibility,
-- line 706 ----------------------------------------
-- line 714 ----------------------------------------
         .                       )
         .                   }
         .               }
         .           
         .               /// Inserts a new element into the table, and returns its raw bucket.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg_attr(feature = "inline-more", inline)]
 2,998,710 ( 0.03%)      pub fn insert(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> Bucket<T> {
         .                   unsafe {
         .                       let mut index = self.table.find_insert_slot(hash);
         .           
         .                       // We can avoid growing the table once we have reached our load
         .                       // factor if we are replacing a tombstone. This works since the
         .                       // number of EMPTY slots does not change in this case.
     7,961 ( 0.00%)              let old_ctrl = *self.table.ctrl(index);
 1,978,611 ( 0.02%)              if unlikely(self.table.growth_left == 0 && special_is_empty(old_ctrl)) {
         .                           self.reserve(1, hasher);
         .                           index = self.table.find_insert_slot(hash);
         .                       }
         .           
         .                       self.table.record_item_insert_at(index, old_ctrl, hash);
         .           
         .                       let bucket = self.bucket(index);
         4 ( 0.00%)              bucket.write(value);
         .                       bucket
         .                   }
 2,201,484 ( 0.03%)      }
         .           
         .               /// Attempts to insert a new element without growing the table and return its raw bucket.
         .               ///
         .               /// Returns an `Err` containing the given element if inserting it would require growing the
         .               /// table.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg(feature = "raw")]
-- line 749 ----------------------------------------
-- line 760 ----------------------------------------
         .                       }
         .                   }
         .               }
         .           
         .               /// Inserts a new element into the table, and returns a mutable reference to it.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg_attr(feature = "inline-more", inline)]
   639,304 ( 0.01%)      pub fn insert_entry(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> &mut T {
       276 ( 0.00%)          unsafe { self.insert(hash, value, hasher).as_mut() }
   479,478 ( 0.01%)      }
         .           
         .               /// Inserts a new element into the table, without growing the table.
         .               ///
         .               /// There must be enough space in the table to insert the new element.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[cfg(any(feature = "raw", feature = "rustc-internal-api"))]
     1,505 ( 0.00%)      pub unsafe fn insert_no_grow(&mut self, hash: u64, value: T) -> Bucket<T> {
   464,974 ( 0.01%)          let (index, old_ctrl) = self.table.prepare_insert_slot(hash);
    10,691 ( 0.00%)          let bucket = self.table.bucket(index);
         .           
         .                   // If we are replacing a DELETED entry then we don't need to update
         .                   // the load counter.
   961,763 ( 0.01%)          self.table.growth_left -= special_is_empty(old_ctrl) as usize;
         .           
         .                   bucket.write(value);
   762,947 ( 0.01%)          self.table.items += 1;
         .                   bucket
     3,005 ( 0.00%)      }
         .           
         .               /// Temporary removes a bucket, applying the given function to the removed
         .               /// element and optionally put back the returned value in the same bucket.
         .               ///
         .               /// Returns `true` if the bucket still contains an element
         .               ///
         .               /// This does not check if the given bucket is actually occupied.
         .               #[cfg_attr(feature = "inline-more", inline)]
-- line 798 ----------------------------------------
-- line 813 ----------------------------------------
         .                       true
         .                   } else {
         .                       false
         .                   }
         .               }
         .           
         .               /// Searches for an element in the table.
         .               #[inline]
    51,219 ( 0.00%)      pub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>> {
    11,157 ( 0.00%)          let result = self.table.find_inner(hash, &mut |index| unsafe {
    26,572 ( 0.00%)              eq(self.bucket(index).as_ref())
     3,934 ( 0.00%)          });
         .           
         .                   // Avoid `Option::map` because it bloats LLVM IR.
         .                   match result {
     1,209 ( 0.00%)              Some(index) => Some(unsafe { self.bucket(index) }),
         .                       None => None,
         .                   }
    57,584 ( 0.00%)      }
         .           
         .               /// Gets a reference to an element in the table.
         .               #[inline]
         .               pub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T> {
         .                   // Avoid `Option::map` because it bloats LLVM IR.
    24,309 ( 0.00%)          match self.find(hash, eq) {
         .                       Some(bucket) => Some(unsafe { bucket.as_ref() }),
         .                       None => None,
         .                   }
         .               }
         .           
         .               /// Gets a mutable reference to an element in the table.
         .               #[inline]
     2,814 ( 0.00%)      pub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T> {
         .                   // Avoid `Option::map` because it bloats LLVM IR.
    23,347 ( 0.00%)          match self.find(hash, eq) {
         .                       Some(bucket) => Some(unsafe { bucket.as_mut() }),
         .                       None => None,
         .                   }
     3,216 ( 0.00%)      }
         .           
         .               /// Attempts to get mutable references to `N` entries in the table at once.
         .               ///
         .               /// Returns an array of length `N` with the results of each query.
         .               ///
         .               /// At most one mutable reference will be returned to any entry. `None` will be returned if any
         .               /// of the hashes are duplicates. `None` will be returned if the hash is not found.
         .               ///
-- line 859 ----------------------------------------
-- line 920 ----------------------------------------
         .               #[inline]
         .               pub fn len(&self) -> usize {
         .                   self.table.items
         .               }
         .           
         .               /// Returns `true` if the table contains no elements.
         .               #[inline]
         .               pub fn is_empty(&self) -> bool {
   914,694 ( 0.01%)          self.len() == 0
         .               }
         .           
         .               /// Returns the number of buckets in the table.
         .               #[inline]
         .               pub fn buckets(&self) -> usize {
         .                   self.table.bucket_mask + 1
         .               }
         .           
         .               /// Returns an iterator over every element in the table. It is up to
         .               /// the caller to ensure that the `RawTable` outlives the `RawIter`.
         .               /// Because we cannot make the `next` method unsafe on the `RawIter`
         .               /// struct, we have to make the `iter` method unsafe.
         .               #[inline]
         .               pub unsafe fn iter(&self) -> RawIter<T> {
         2 ( 0.00%)          let data = Bucket::from_base_index(self.data_end(), 0);
         .                   RawIter {
         .                       iter: RawIterRange::new(self.table.ctrl.as_ptr(), data, self.table.buckets()),
   127,651 ( 0.00%)              items: self.table.items,
         .                   }
         .               }
         .           
         .               /// Returns an iterator over occupied buckets that could match a given hash.
         .               ///
         .               /// `RawTable` only stores 7 bits of the hash value, so this iterator may
         .               /// return items that have a hash value different than the one provided. You
         .               /// should always validate the returned values before using them.
-- line 954 ----------------------------------------
-- line 995 ----------------------------------------
         .               /// Iteration starts at the provided iterator's current location.
         .               ///
         .               /// It is up to the caller to ensure that the iterator is valid for this
         .               /// `RawTable` and covers all items that remain in the table.
         .               pub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T, A> {
         .                   debug_assert_eq!(iter.len(), self.len());
         .           
         .                   let alloc = self.table.alloc.clone();
     9,960 ( 0.00%)          let allocation = self.into_allocation();
     7,470 ( 0.00%)          RawIntoIter {
    12,450 ( 0.00%)              iter,
         .                       allocation,
         .                       marker: PhantomData,
         .                       alloc,
         .                   }
         .               }
         .           
         .               /// Converts the table into a raw allocation. The contents of the table
         .               /// should be dropped using a `RawIter` before freeing the allocation.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub(crate) fn into_allocation(self) -> Option<(NonNull<u8>, Layout)> {
     4,616 ( 0.00%)          let alloc = if self.table.is_empty_singleton() {
         .                       None
         .                   } else {
         .                       // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.
         .                       let (layout, ctrl_offset) = match calculate_layout::<T>(self.table.buckets()) {
         .                           Some(lco) => lco,
         .                           None => unsafe { hint::unreachable_unchecked() },
         .                       };
         .                       Some((
       829 ( 0.00%)                  unsafe { NonNull::new_unchecked(self.table.ctrl.as_ptr().sub(ctrl_offset)) },
         .                           layout,
         .                       ))
         .                   };
         .                   mem::forget(self);
         .                   alloc
         .               }
         .           }
         .           
-- line 1033 ----------------------------------------
-- line 1042 ----------------------------------------
         .               T: Sync,
         .               A: Sync,
         .           {
         .           }
         .           
         .           impl<A> RawTableInner<A> {
         .               #[inline]
         .               const fn new_in(alloc: A) -> Self {
   836,926 ( 0.01%)          Self {
         .                       // Be careful to cast the entire slice to a raw pointer.
         .                       ctrl: unsafe { NonNull::new_unchecked(Group::static_empty() as *const _ as *mut u8) },
         .                       bucket_mask: 0,
         .                       items: 0,
         .                       growth_left: 0,
         .                       alloc,
         .                   }
         .               }
         .           }
         .           
         .           impl<A: Allocator + Clone> RawTableInner<A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
   546,414 ( 0.01%)      unsafe fn new_uninitialized(
         .                   alloc: A,
         .                   table_layout: TableLayout,
         .                   buckets: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
         .                   debug_assert!(buckets.is_power_of_two());
         .           
         .                   // Avoid `Option::ok_or_else` because it bloats LLVM IR.
-- line 1071 ----------------------------------------
-- line 1078 ----------------------------------------
         .                   // exceed `isize::MAX`. We can skip this check on 64-bit systems since
         .                   // such allocations will never succeed anyways.
         .                   //
         .                   // This mirrors what Vec does in the standard library.
         .                   if mem::size_of::<usize>() < 8 && layout.size() > isize::MAX as usize {
         .                       return Err(fallibility.capacity_overflow());
         .                   }
         .           
   131,834 ( 0.00%)          let ptr: NonNull<u8> = match do_alloc(&alloc, layout) {
         .                       Ok(block) => block.cast(),
         .                       Err(_) => return Err(fallibility.alloc_err(layout)),
         .                   };
         .           
         .                   let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));
   301,338 ( 0.00%)          Ok(Self {
         .                       ctrl,
   128,566 ( 0.00%)              bucket_mask: buckets - 1,
         .                       items: 0,
         .                       growth_left: bucket_mask_to_capacity(buckets - 1),
         .                       alloc,
         .                   })
   397,758 ( 0.00%)      }
         .           
         .               #[inline]
    65,023 ( 0.00%)      fn fallible_with_capacity(
         .                   alloc: A,
         .                   table_layout: TableLayout,
         .                   capacity: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
    16,648 ( 0.00%)          if capacity == 0 {
    16,311 ( 0.00%)              Ok(Self::new_in(alloc))
         .                   } else {
         .                       unsafe {
         .                           let buckets =
         .                               capacity_to_buckets(capacity).ok_or_else(|| fallibility.capacity_overflow())?;
         .           
   248,085 ( 0.00%)                  let result = Self::new_uninitialized(alloc, table_layout, buckets, fallibility)?;
         .                           result.ctrl(0).write_bytes(EMPTY, result.num_ctrl_bytes());
         .           
    29,745 ( 0.00%)                  Ok(result)
         .                       }
         .                   }
    65,023 ( 0.00%)      }
         .           
         .               /// Searches for an empty or deleted bucket which is suitable for inserting
         .               /// a new element and sets the hash for that slot.
         .               ///
         .               /// There must be at least 1 empty bucket in the table.
         .               #[inline]
   160,724 ( 0.00%)      unsafe fn prepare_insert_slot(&self, hash: u64) -> (usize, u8) {
         .                   let index = self.find_insert_slot(hash);
   160,724 ( 0.00%)          let old_ctrl = *self.ctrl(index);
         .                   self.set_ctrl_h2(index, hash);
         .                   (index, old_ctrl)
   321,448 ( 0.00%)      }
         .           
         .               /// Searches for an empty or deleted bucket which is suitable for inserting
         .               /// a new element.
         .               ///
         .               /// There must be at least 1 empty bucket in the table.
         .               #[inline]
         .               fn find_insert_slot(&self, hash: u64) -> usize {
         .                   let mut probe_seq = self.probe_seq(hash);
         .                   loop {
         .                       unsafe {
         .                           let group = Group::load(self.ctrl(probe_seq.pos));
 1,358,092 ( 0.02%)                  if let Some(bit) = group.match_empty_or_deleted().lowest_set_bit() {
 3,972,159 ( 0.05%)                      let result = (probe_seq.pos + bit) & self.bucket_mask;
         .           
         .                               // In tables smaller than the group width, trailing control
         .                               // bytes outside the range of the table are filled with
         .                               // EMPTY entries. These will unfortunately trigger a
         .                               // match, but once masked may point to a full bucket that
         .                               // is already occupied. We detect this situation here and
         .                               // perform a second scan starting at the beginning of the
         .                               // table. This second scan is guaranteed to find an empty
         .                               // slot (due to the load factor) before hitting the trailing
         .                               // control bytes (containing EMPTY).
 1,817,949 ( 0.02%)                      if unlikely(is_full(*self.ctrl(result))) {
         .                                   debug_assert!(self.bucket_mask < Group::WIDTH);
         .                                   debug_assert_ne!(probe_seq.pos, 0);
         .                                   return Group::load_aligned(self.ctrl(0))
         .                                       .match_empty_or_deleted()
         .                                       .lowest_set_bit_nonzero();
         .                               }
         .           
         .                               return result;
-- line 1165 ----------------------------------------
-- line 1171 ----------------------------------------
         .           
         .               /// Searches for an element in the table. This uses dynamic dispatch to reduce the amount of
         .               /// code generated, but it is eliminated by LLVM optimizations.
         .               #[inline]
         .               fn find_inner(&self, hash: u64, eq: &mut dyn FnMut(usize) -> bool) -> Option<usize> {
         .                   let h2_hash = h2(hash);
         .                   let mut probe_seq = self.probe_seq(hash);
         .           
   101,556 ( 0.00%)          loop {
         .                       let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };
         .           
 3,882,529 ( 0.04%)              for bit in group.match_byte(h2_hash) {
 7,369,696 ( 0.08%)                  let index = (probe_seq.pos + bit) & self.bucket_mask;
         .           
 5,086,434 ( 0.06%)                  if likely(eq(index)) {
         .                               return Some(index);
         .                           }
         .                       }
         .           
 1,238,888 ( 0.01%)              if likely(group.match_empty().any_bit_set()) {
         .                           return None;
         .                       }
         .           
         .                       probe_seq.move_next(self.bucket_mask);
         .                   }
         .               }
         .           
         .               #[allow(clippy::mut_mut)]
-- line 1198 ----------------------------------------
-- line 1225 ----------------------------------------
         .                   Bucket::from_base_index(self.data_end(), index)
         .               }
         .           
         .               #[inline]
         .               unsafe fn bucket_ptr(&self, index: usize, size_of: usize) -> *mut u8 {
         .                   debug_assert_ne!(self.bucket_mask, 0);
         .                   debug_assert!(index < self.buckets());
         .                   let base: *mut u8 = self.data_end().as_ptr();
 4,908,328 ( 0.06%)          base.sub((index + 1) * size_of)
         .               }
         .           
         .               #[inline]
         .               unsafe fn data_end<T>(&self) -> NonNull<T> {
         .                   NonNull::new_unchecked(self.ctrl.as_ptr().cast())
         .               }
         .           
         .               /// Returns an iterator-like object for a probe sequence on the table.
         .               ///
         .               /// This iterator never terminates, but is guaranteed to visit each bucket
         .               /// group exactly once. The loop using `probe_seq` must terminate upon
         .               /// reaching a group containing an empty bucket.
         .               #[inline]
         .               fn probe_seq(&self, hash: u64) -> ProbeSeq {
         .                   ProbeSeq {
22,791,074 ( 0.26%)              pos: h1(hash) & self.bucket_mask,
         .                       stride: 0,
         .                   }
         .               }
         .           
         .               /// Returns the index of a bucket for which a value must be inserted if there is enough rooom
         .               /// in the table, otherwise returns error
         .               #[cfg(feature = "raw")]
         .               #[inline]
-- line 1257 ----------------------------------------
-- line 1263 ----------------------------------------
         .                   } else {
         .                       self.record_item_insert_at(index, old_ctrl, hash);
         .                       Ok(index)
         .                   }
         .               }
         .           
         .               #[inline]
         .               unsafe fn record_item_insert_at(&mut self, index: usize, old_ctrl: u8, hash: u64) {
 2,474,448 ( 0.03%)          self.growth_left -= special_is_empty(old_ctrl) as usize;
         .                   self.set_ctrl_h2(index, hash);
 1,977,988 ( 0.02%)          self.items += 1;
         .               }
         .           
         .               #[inline]
         .               fn is_in_same_group(&self, i: usize, new_i: usize, hash: u64) -> bool {
         .                   let probe_seq_pos = self.probe_seq(hash).pos;
         .                   let probe_index =
         .                       |pos: usize| (pos.wrapping_sub(probe_seq_pos) & self.bucket_mask) / Group::WIDTH;
         .                   probe_index(i) == probe_index(new_i)
-- line 1281 ----------------------------------------
-- line 1312 ----------------------------------------
         .                   // replicate the buckets at the end of the trailing group. For example
         .                   // with 2 buckets and a group size of 4, the control bytes will look
         .                   // like this:
         .                   //
         .                   //     Real    |             Replicated
         .                   // ---------------------------------------------
         .                   // | [A] | [B] | [EMPTY] | [EMPTY] | [A] | [B] |
         .                   // ---------------------------------------------
 3,812,542 ( 0.04%)          let index2 = ((index.wrapping_sub(Group::WIDTH)) & self.bucket_mask) + Group::WIDTH;
         .           
 1,270,262 ( 0.01%)          *self.ctrl(index) = ctrl;
 1,270,346 ( 0.01%)          *self.ctrl(index2) = ctrl;
         .               }
         .           
         .               /// Returns a pointer to a control byte.
         .               #[inline]
         .               unsafe fn ctrl(&self, index: usize) -> *mut u8 {
         .                   debug_assert!(index < self.num_ctrl_bytes());
         .                   self.ctrl.as_ptr().add(index)
         .               }
         .           
         .               #[inline]
         .               fn buckets(&self) -> usize {
   384,184 ( 0.00%)          self.bucket_mask + 1
         .               }
         .           
         .               #[inline]
         .               fn num_ctrl_bytes(&self) -> usize {
   307,416 ( 0.00%)          self.bucket_mask + 1 + Group::WIDTH
         .               }
         .           
         .               #[inline]
         .               fn is_empty_singleton(&self) -> bool {
 1,566,276 ( 0.02%)          self.bucket_mask == 0
         .               }
         .           
         .               #[allow(clippy::mut_mut)]
         .               #[inline]
         .               unsafe fn prepare_resize(
         .                   &self,
         .                   table_layout: TableLayout,
         .                   capacity: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<crate::scopeguard::ScopeGuard<Self, impl FnMut(&mut Self)>, TryReserveError> {
         .                   debug_assert!(self.items <= capacity);
         .           
         .                   // Allocate and initialize the new table.
     3,921 ( 0.00%)          let mut new_table = RawTableInner::fallible_with_capacity(
         .                       self.alloc.clone(),
         .                       table_layout,
         .                       capacity,
         .                       fallibility,
         .                   )?;
   162,467 ( 0.00%)          new_table.growth_left -= self.items;
         .                   new_table.items = self.items;
         .           
         .                   // The hash function may panic, in which case we simply free the new
         .                   // table without dropping any elements that may have been copied into
         .                   // it.
         .                   //
         .                   // This guard is also used to free the old table on success, see
         .                   // the comment at the bottom of this function.
         .                   Ok(guard(new_table, move |self_| {
    74,623 ( 0.00%)              if !self_.is_empty_singleton() {
         .                           self_.free_buckets(table_layout);
         .                       }
         .                   }))
         .               }
         .           
         .               /// Reserves or rehashes to make room for `additional` more elements.
         .               ///
         .               /// This uses dynamic dispatch to reduce the amount of
-- line 1383 ----------------------------------------
-- line 1388 ----------------------------------------
         .                   &mut self,
         .                   additional: usize,
         .                   hasher: &dyn Fn(&mut Self, usize) -> u64,
         .                   fallibility: Fallibility,
         .                   layout: TableLayout,
         .                   drop: Option<fn(*mut u8)>,
         .               ) -> Result<(), TryReserveError> {
         .                   // Avoid `Option::ok_or_else` because it bloats LLVM IR.
   149,246 ( 0.00%)          let new_items = match self.items.checked_add(additional) {
         .                       Some(new_items) => new_items,
         .                       None => return Err(fallibility.capacity_overflow()),
         .                   };
   149,246 ( 0.00%)          let full_capacity = bucket_mask_to_capacity(self.bucket_mask);
   313,260 ( 0.00%)          if new_items <= full_capacity / 2 {
         .                       // Rehash in-place without re-allocating if we have plenty of spare
         .                       // capacity that is locked up due to DELETED entries.
         .                       self.rehash_in_place(hasher, layout.size, drop);
         .                       Ok(())
         .                   } else {
         .                       // Otherwise, conservatively resize to at least the next size up
         .                       // to avoid churning deletes into frequent rehashes.
         .                       self.resize_inner(
    74,623 ( 0.00%)                  usize::max(new_items, full_capacity + 1),
         .                           hasher,
         .                           fallibility,
         .                           layout,
         .                       )
         .                   }
         .               }
         .           
         .               /// Allocates a new table of a different size and moves the contents of the
-- line 1418 ----------------------------------------
-- line 1424 ----------------------------------------
         .               #[inline(always)]
         .               unsafe fn resize_inner(
         .                   &mut self,
         .                   capacity: usize,
         .                   hasher: &dyn Fn(&mut Self, usize) -> u64,
         .                   fallibility: Fallibility,
         .                   layout: TableLayout,
         .               ) -> Result<(), TryReserveError> {
     9,924 ( 0.00%)          let mut new_table = self.prepare_resize(layout, capacity, fallibility)?;
         .           
         .                   // Copy all elements to the new table.
         .                   for i in 0..self.buckets() {
   760,206 ( 0.01%)              if !is_full(*self.ctrl(i)) {
         .                           continue;
         .                       }
         .           
         .                       // This may panic.
         .                       let hash = hasher(self, i);
         .           
         .                       // We can use a simpler version of insert() here since:
         .                       // - there are no DELETED entries.
-- line 1444 ----------------------------------------
-- line 1454 ----------------------------------------
         .                   }
         .           
         .                   // We successfully copied all elements without panicking. Now replace
         .                   // self with the new table. The old table will have its memory freed but
         .                   // the items will not be dropped (since they have been moved into the
         .                   // new table).
         .                   mem::swap(self, &mut new_table);
         .           
    74,623 ( 0.00%)          Ok(())
         .               }
         .           
         .               /// Rehashes the contents of the table in place (i.e. without changing the
         .               /// allocation).
         .               ///
         .               /// If `hasher` panics then some the table's contents may be lost.
         .               ///
         .               /// This uses dynamic dispatch to reduce the amount of
-- line 1470 ----------------------------------------
-- line 1554 ----------------------------------------
         .               #[inline]
         .               unsafe fn free_buckets(&mut self, table_layout: TableLayout) {
         .                   // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.
         .                   let (layout, ctrl_offset) = match table_layout.calculate_layout_for(self.buckets()) {
         .                       Some(lco) => lco,
         .                       None => hint::unreachable_unchecked(),
         .                   };
         .                   self.alloc.deallocate(
    51,748 ( 0.00%)              NonNull::new_unchecked(self.ctrl.as_ptr().sub(ctrl_offset)),
         .                       layout,
         .                   );
         .               }
         .           
         .               /// Marks all table buckets as empty without dropping their contents.
         .               #[inline]
         .               fn clear_no_drop(&mut self) {
    12,224 ( 0.00%)          if !self.is_empty_singleton() {
         .                       unsafe {
         .                           self.ctrl(0).write_bytes(EMPTY, self.num_ctrl_bytes());
         .                       }
         .                   }
    15,896 ( 0.00%)          self.items = 0;
    12,295 ( 0.00%)          self.growth_left = bucket_mask_to_capacity(self.bucket_mask);
         .               }
         .           
         .               #[inline]
         .               unsafe fn erase(&mut self, index: usize) {
         .                   debug_assert!(is_full(*self.ctrl(index)));
   142,773 ( 0.00%)          let index_before = index.wrapping_sub(Group::WIDTH) & self.bucket_mask;
         .                   let empty_before = Group::load(self.ctrl(index_before)).match_empty();
         .                   let empty_after = Group::load(self.ctrl(index)).match_empty();
         .           
         .                   // If we are inside a continuous block of Group::WIDTH full or deleted
         .                   // cells then a probe window may have seen a full block when trying to
         .                   // insert. We therefore need to keep that block non-empty so that
         .                   // lookups will continue searching to the next probe window.
         .                   //
         .                   // Note that in this context `leading_zeros` refers to the bytes at the
         .                   // end of a group, while `trailing_zeros` refers to the bytes at the
         .                   // beginning of a group.
   571,092 ( 0.01%)          let ctrl = if empty_before.leading_zeros() + empty_after.trailing_zeros() >= Group::WIDTH {
         .                       DELETED
         .                   } else {
   711,785 ( 0.01%)              self.growth_left += 1;
         .                       EMPTY
         .                   };
         .                   self.set_ctrl(index, ctrl);
   571,092 ( 0.01%)          self.items -= 1;
         .               }
         .           }
         .           
         .           impl<T: Clone, A: Allocator + Clone> Clone for RawTable<T, A> {
     3,792 ( 0.00%)      fn clone(&self) -> Self {
       547 ( 0.00%)          if self.table.is_empty_singleton() {
         .                       Self::new_in(self.table.alloc.clone())
         .                   } else {
         .                       unsafe {
         .                           let mut new_table = ManuallyDrop::new(
         .                               // Avoid `Result::ok_or_else` because it bloats LLVM IR.
         .                               match Self::new_uninitialized(
         .                                   self.table.alloc.clone(),
         .                                   self.table.buckets(),
-- line 1615 ----------------------------------------
-- line 1624 ----------------------------------------
         .                               // We need to free the memory allocated for the new table.
         .                               new_table.free_buckets();
         .                           });
         .           
         .                           // Return the newly created table.
         .                           ManuallyDrop::into_inner(new_table)
         .                       }
         .                   }
     4,266 ( 0.00%)      }
         .           
         .               fn clone_from(&mut self, source: &Self) {
         .                   if source.table.is_empty_singleton() {
         .                       *self = Self::new_in(self.table.alloc.clone());
         .                   } else {
         .                       unsafe {
         .                           // First, drop all our elements without clearing the control bytes.
         .                           self.drop_elements();
-- line 1640 ----------------------------------------
-- line 1687 ----------------------------------------
         .                       .table
         .                       .ctrl(0)
         .                       .copy_to_nonoverlapping(self.table.ctrl(0), self.table.num_ctrl_bytes());
         .                   source
         .                       .data_start()
         .                       .copy_to_nonoverlapping(self.data_start(), self.table.buckets());
         .           
         .                   self.table.items = source.table.items;
       136 ( 0.00%)          self.table.growth_left = source.table.growth_left;
         .               }
         .           }
         .           
         .           impl<T: Clone, A: Allocator + Clone> RawTable<T, A> {
         .               /// Common code for clone and clone_from. Assumes `self.buckets() == source.buckets()`.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               unsafe fn clone_from_impl(&mut self, source: &Self, mut on_panic: impl FnMut(&mut Self)) {
         .                   // Copy the control bytes unchanged. We do this in a single pass
-- line 1703 ----------------------------------------
-- line 1790 ----------------------------------------
         .               fn default() -> Self {
         .                   Self::new_in(Default::default())
         .               }
         .           }
         .           
         .           #[cfg(feature = "nightly")]
         .           unsafe impl<#[may_dangle] T, A: Allocator + Clone> Drop for RawTable<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
   812,230 ( 0.01%)      fn drop(&mut self) {
   677,550 ( 0.01%)          if !self.table.is_empty_singleton() {
         .                       unsafe {
         .                           self.drop_elements();
         .                           self.free_buckets();
         .                       }
         .                   }
   871,666 ( 0.01%)      }
         .           }
         .           #[cfg(not(feature = "nightly"))]
         .           impl<T, A: Allocator + Clone> Drop for RawTable<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn drop(&mut self) {
         .                   if !self.table.is_empty_singleton() {
         .                       unsafe {
         .                           self.drop_elements();
-- line 1813 ----------------------------------------
-- line 1817 ----------------------------------------
         .               }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> IntoIterator for RawTable<T, A> {
         .               type Item = T;
         .               type IntoIter = RawIntoIter<T, A>;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
     9,960 ( 0.00%)      fn into_iter(self) -> RawIntoIter<T, A> {
         .                   unsafe {
         .                       let iter = self.iter();
         .                       self.into_iter_from(iter)
         .                   }
    12,450 ( 0.00%)      }
         .           }
         .           
         .           /// Iterator over a sub-range of a table. Unlike `RawIter` this iterator does
         .           /// not track an item count.
         .           pub(crate) struct RawIterRange<T> {
         .               // Mask of full buckets in the current group. Bits are cleared from this
         .               // mask as each element is processed.
         .               current_group: BitMask,
-- line 1838 ----------------------------------------
-- line 1934 ----------------------------------------
         .           
         .           impl<T> Iterator for RawIterRange<T> {
         .               type Item = Bucket<T>;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn next(&mut self) -> Option<Bucket<T>> {
         .                   unsafe {
         .                       loop {
   261,170 ( 0.00%)                  if let Some(index) = self.current_group.lowest_set_bit() {
    40,721 ( 0.00%)                      self.current_group = self.current_group.remove_lowest_bit();
    67,893 ( 0.00%)                      return Some(self.data.next_n(index));
         .                           }
         .           
   237,752 ( 0.00%)                  if self.next_ctrl >= self.end {
         .                               return None;
         .                           }
         .           
         .                           // We might read past self.end up to the next group boundary,
         .                           // but this is fine because it only occurs on tables smaller
         .                           // than the group size where the trailing control bytes are all
         .                           // EMPTY. On larger tables self.end is guaranteed to be aligned
         .                           // to the group size (since tables are power-of-two sized).
     6,119 ( 0.00%)                  self.current_group = Group::load_aligned(self.next_ctrl).match_full();
     5,274 ( 0.00%)                  self.data = self.data.next_n(Group::WIDTH);
    11,863 ( 0.00%)                  self.next_ctrl = self.next_ctrl.add(Group::WIDTH);
         .                       }
         .                   }
         .               }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         .                   // We don't have an item count, so just guess based on the range size.
         .                   (
-- line 1966 ----------------------------------------
-- line 2102 ----------------------------------------
         .                           }
         .                       } else {
         .                           // We must have already iterated past the removed item.
         .                       }
         .                   }
         .               }
         .           
         .               unsafe fn drop_elements(&mut self) {
     2,018 ( 0.00%)          if mem::needs_drop::<T>() && self.len() != 0 {
         .                       for item in self {
         .                           item.drop();
         .                       }
         .                   }
         .               }
         .           }
         .           
         .           impl<T> Clone for RawIter<T> {
-- line 2118 ----------------------------------------
-- line 2124 ----------------------------------------
         .                   }
         .               }
         .           }
         .           
         .           impl<T> Iterator for RawIter<T> {
         .               type Item = Bucket<T>;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
    47,864 ( 0.00%)      fn next(&mut self) -> Option<Bucket<T>> {
   107,654 ( 0.00%)          if let Some(b) = self.iter.next() {
   320,551 ( 0.00%)              self.items -= 1;
         .                       Some(b)
         .                   } else {
         .                       // We don't check against items == 0 here to allow the
         .                       // compiler to optimize away the item count entirely if the
         .                       // iterator length is never queried.
         .                       debug_assert_eq!(self.items, 0);
         .                       None
         .                   }
    95,728 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         .                   (self.items, Some(self.items))
         .               }
         .           }
         .           
         .           impl<T> ExactSizeIterator for RawIter<T> {}
-- line 2151 ----------------------------------------
-- line 2177 ----------------------------------------
         .               T: Sync,
         .               A: Sync,
         .           {
         .           }
         .           
         .           #[cfg(feature = "nightly")]
         .           unsafe impl<#[may_dangle] T, A: Allocator + Clone> Drop for RawIntoIter<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
     4,016 ( 0.00%)      fn drop(&mut self) {
         .                   unsafe {
         .                       // Drop all remaining elements
         .                       self.iter.drop_elements();
         .           
         .                       // Free the table
    21,633 ( 0.00%)              if let Some((ptr, layout)) = self.allocation {
         .                           self.alloc.deallocate(ptr, layout);
         .                       }
         .                   }
       630 ( 0.00%)      }
         .           }
         .           #[cfg(not(feature = "nightly"))]
         .           impl<T, A: Allocator + Clone> Drop for RawIntoIter<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn drop(&mut self) {
         .                   unsafe {
         .                       // Drop all remaining elements
         .                       self.iter.drop_elements();
-- line 2203 ----------------------------------------
-- line 2209 ----------------------------------------
         .                   }
         .               }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> Iterator for RawIntoIter<T, A> {
         .               type Item = T;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
     2,507 ( 0.00%)      fn next(&mut self) -> Option<T> {
       975 ( 0.00%)          unsafe { Some(self.iter.next()?.read()) }
     6,366 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         4 ( 0.00%)          self.iter.size_hint()
         .               }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> ExactSizeIterator for RawIntoIter<T, A> {}
         .           impl<T, A: Allocator + Clone> FusedIterator for RawIntoIter<T, A> {}
         .           
         .           /// Iterator which consumes elements without freeing the table storage.
         .           pub struct RawDrain<'a, T, A: Allocator + Clone = Global> {
-- line 2231 ----------------------------------------
-- line 2259 ----------------------------------------
         .           where
         .               T: Sync,
         .               A: Sync,
         .           {
         .           }
         .           
         .           impl<T, A: Allocator + Clone> Drop for RawDrain<'_, T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
     1,176 ( 0.00%)      fn drop(&mut self) {
         .                   unsafe {
         .                       // Drop all remaining elements. Note that this may panic.
         .                       self.iter.drop_elements();
         .           
         .                       // Reset the contents of the table now that all elements have been
         .                       // dropped.
         .                       self.table.clear_no_drop();
         .           
         .                       // Move the now empty table back to its original location.
       147 ( 0.00%)              self.orig_table
         .                           .as_ptr()
         .                           .copy_from_nonoverlapping(&*self.table, 1);
         .                   }
     1,176 ( 0.00%)      }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> Iterator for RawDrain<'_, T, A> {
         .               type Item = T;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn next(&mut self) -> Option<T> {
         .                   unsafe {
-- line 2289 ----------------------------------------

12,487,960 ( 0.14%)  <counts for unidentified lines in /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/compiler/rustc_const_eval/src/interpret/intern.rs
--------------------------------------------------------------------------------
Ir                 

-- line 49 ----------------------------------------
        .               /// particular allocation. It is primarily used to make as many allocations as possible
        .               /// read-only so LLVM can place them in const memory.
        .               mode: InternMode,
        .               /// This field stores whether we are *currently* inside an `UnsafeCell`. This can affect
        .               /// the intern mode of references we encounter.
        .               inside_unsafe_cell: bool,
        .           }
        .           
    3,024 ( 0.00%)  #[derive(Copy, Clone, Debug, PartialEq, Hash, Eq)]
        .           enum InternMode {
        .               /// A static and its current mutability.  Below shared references inside a `static mut`,
        .               /// this is *immutable*, and below mutable references inside an `UnsafeCell`, this
        .               /// is *mutable*.
        .               Static(hir::Mutability),
        .               /// A `const`.
        .               Const,
        .           }
-- line 65 ----------------------------------------
-- line 69 ----------------------------------------
        .           struct IsStaticOrFn;
        .           
        .           /// Intern an allocation without looking at its children.
        .           /// `mode` is the mode of the environment where we found this pointer.
        .           /// `mutablity` is the mutability of the place to be interned; even if that says
        .           /// `immutable` things might become mutable if `ty` is not frozen.
        .           /// `ty` can be `None` if there is no potential interior mutability
        .           /// to account for (e.g. for vtables).
    5,196 ( 0.00%)  fn intern_shallow<'rt, 'mir, 'tcx, M: CompileTimeMachine<'mir, 'tcx, const_eval::MemoryKind>>(
        .               ecx: &'rt mut InterpCx<'mir, 'tcx, M>,
        .               leftover_allocations: &'rt mut FxHashSet<AllocId>,
        .               alloc_id: AllocId,
        .               mode: InternMode,
        .               ty: Option<Ty<'tcx>>,
        .           ) -> Option<IsStaticOrFn> {
        .               trace!("intern_shallow {:?} with {:?}", alloc_id, mode);
        .               // remove allocation
      433 ( 0.00%)      let tcx = ecx.tcx;
    5,670 ( 0.00%)      let (kind, mut alloc) = match ecx.memory.alloc_map.remove(&alloc_id) {
    3,780 ( 0.00%)          Some(entry) => entry,
        .                   None => {
        .                       // Pointer not found in local memory map. It is either a pointer to the global
        .                       // map, or dangling.
        .                       // If the pointer is dangling (neither in local nor global memory), we leave it
        .                       // to validation to error -- it has the much better error messages, pointing out where
        .                       // in the value the dangling reference lies.
        .                       // The `delay_span_bug` ensures that we don't forget such a check in validation.
      275 ( 0.00%)              if tcx.get_global_alloc(alloc_id).is_none() {
        .                           tcx.sess.delay_span_bug(ecx.tcx.span, "tried to intern dangling pointer");
        .                       }
        .                       // treat dangling pointers like other statics
        .                       // just to stop trying to recurse into them
        .                       return Some(IsStaticOrFn);
        .                   }
        .               };
        .               // This match is just a canary for future changes to `MemoryKind`, which most likely need
-- line 104 ----------------------------------------
-- line 106 ----------------------------------------
        .               match kind {
        .                   MemoryKind::Stack
        .                   | MemoryKind::Machine(const_eval::MemoryKind::Heap)
        .                   | MemoryKind::CallerLocation => {}
        .               }
        .               // Set allocation mutability as appropriate. This is used by LLVM to put things into
        .               // read-only memory, and also by Miri when evaluating other globals that
        .               // access this one.
      756 ( 0.00%)      if let InternMode::Static(mutability) = mode {
        .                   // For this, we need to take into account `UnsafeCell`. When `ty` is `None`, we assume
        .                   // no interior mutability.
      160 ( 0.00%)          let frozen = ty.map_or(true, |ty| ty.is_freeze(ecx.tcx, ecx.param_env));
        .                   // For statics, allocation mutability is the combination of place mutability and
        .                   // type mutability.
        .                   // The entire allocation needs to be mutable if it contains an `UnsafeCell` anywhere.
        .                   let immutable = mutability == Mutability::Not && frozen;
       96 ( 0.00%)          if immutable {
        .                       alloc.mutability = Mutability::Not;
        .                   } else {
        .                       // Just making sure we are not "upgrading" an immutable allocation to mutable.
        8 ( 0.00%)              assert_eq!(alloc.mutability, Mutability::Mut);
        .                   }
        .               } else {
        .                   // No matter what, *constants are never mutable*. Mutating them is UB.
        .                   // See const_eval::machine::MemoryExtra::can_access_statics for why
        .                   // immutability is so important.
        .           
        .                   // Validation will ensure that there is no `UnsafeCell` on an immutable allocation.
        .                   alloc.mutability = Mutability::Not;
        .               };
        .               // link the alloc id to the actual allocation
    8,694 ( 0.00%)      let alloc = tcx.intern_const_alloc(alloc);
        .               leftover_allocations.extend(alloc.relocations().iter().map(|&(_, alloc_id)| alloc_id));
    1,512 ( 0.00%)      tcx.set_alloc_id_memory(alloc_id, alloc);
        .               None
    3,464 ( 0.00%)  }
        .           
        .           impl<'rt, 'mir, 'tcx, M: CompileTimeMachine<'mir, 'tcx, const_eval::MemoryKind>>
        .               InternVisitor<'rt, 'mir, 'tcx, M>
        .           {
        .               fn intern_shallow(
        .                   &mut self,
        .                   alloc_id: AllocId,
        .                   mode: InternMode,
        .                   ty: Option<Ty<'tcx>>,
        .               ) -> Option<IsStaticOrFn> {
      840 ( 0.00%)          intern_shallow(self.ecx, self.leftover_allocations, alloc_id, mode, ty)
        .               }
        .           }
        .           
        .           impl<'rt, 'mir, 'tcx: 'mir, M: CompileTimeMachine<'mir, 'tcx, const_eval::MemoryKind>>
        .               ValueVisitor<'mir, 'tcx, M> for InternVisitor<'rt, 'mir, 'tcx, M>
        .           {
        .               type V = MPlaceTy<'tcx>;
        .           
-- line 160 ----------------------------------------
-- line 164 ----------------------------------------
        .               }
        .           
        .               fn visit_aggregate(
        .                   &mut self,
        .                   mplace: &MPlaceTy<'tcx>,
        .                   fields: impl Iterator<Item = InterpResult<'tcx, Self::V>>,
        .               ) -> InterpResult<'tcx> {
        .                   // ZSTs cannot contain pointers, so we can skip them.
      261 ( 0.00%)          if mplace.layout.is_zst() {
        .                       return Ok(());
        .                   }
        .           
    1,078 ( 0.00%)          if let Some(def) = mplace.layout.ty.ty_adt_def() {
    1,706 ( 0.00%)              if Some(def.did) == self.ecx.tcx.lang_items().unsafe_cell_type() {
        .                           // We are crossing over an `UnsafeCell`, we can mutate again. This means that
        .                           // References we encounter inside here are interned as pointing to mutable
        .                           // allocations.
        .                           // Remember the `old` value to handle nested `UnsafeCell`.
        .                           let old = std::mem::replace(&mut self.inside_unsafe_cell, true);
      175 ( 0.00%)                  let walked = self.walk_aggregate(mplace, fields);
        .                           self.inside_unsafe_cell = old;
        .                           return walked;
        .                       }
        .                   }
        .           
    2,524 ( 0.00%)          self.walk_aggregate(mplace, fields)
        .               }
        .           
4,155,984 ( 0.05%)      fn visit_value(&mut self, mplace: &MPlaceTy<'tcx>) -> InterpResult<'tcx> {
        .                   // Handle Reference types, as these are the only relocations supported by const eval.
        .                   // Raw pointers (and boxes) are handled by the `leftover_relocations` logic.
  461,776 ( 0.01%)          let tcx = self.ecx.tcx;
  461,776 ( 0.01%)          let ty = mplace.layout.ty;
1,385,958 ( 0.02%)          if let ty::Ref(_, referenced_ty, ref_mutability) = *ty.kind() {
    2,100 ( 0.00%)              let value = self.ecx.read_immediate(&(*mplace).into())?;
      630 ( 0.00%)              let mplace = self.ecx.ref_to_mplace(&value)?;
      210 ( 0.00%)              assert_eq!(mplace.layout.ty, referenced_ty);
        .                       // Handle trait object vtables.
      420 ( 0.00%)              if let ty::Dynamic(..) =
      840 ( 0.00%)                  tcx.struct_tail_erasing_lifetimes(referenced_ty, self.ecx.param_env).kind()
        .                       {
        .                           let ptr = self.ecx.scalar_to_ptr(mplace.meta.unwrap_meta());
        .                           if let Some(alloc_id) = ptr.provenance {
        .                               // Explicitly choose const mode here, since vtables are immutable, even
        .                               // if the reference of the fat pointer is mutable.
        .                               self.intern_shallow(alloc_id, InternMode::Const, None);
        .                           } else {
        .                               // Validation will error (with a better message) on an invalid vtable pointer.
        .                               // Let validation show the error message, but make sure it *does* error.
        .                               tcx.sess
        .                                   .delay_span_bug(tcx.span, "vtables pointers cannot be integer pointers");
        .                           }
        .                       }
        .                       // Check if we have encountered this pointer+layout combination before.
        .                       // Only recurse for allocation-backed pointers.
      630 ( 0.00%)              if let Some(alloc_id) = mplace.ptr.provenance {
        .                           // Compute the mode with which we intern this. Our goal here is to make as many
        .                           // statics as we can immutable so they can be placed in read-only memory by LLVM.
      840 ( 0.00%)                  let ref_mode = match self.mode {
        .                               InternMode::Static(mutbl) => {
        .                                   // In statics, merge outer mutability with reference mutability and
        .                                   // take into account whether we are in an `UnsafeCell`.
        .           
        .                                   // The only way a mutable reference actually works as a mutable reference is
        .                                   // by being in a `static mut` directly or behind another mutable reference.
        .                                   // If there's an immutable reference or we are inside a `static`, then our
        .                                   // mutable reference is equivalent to an immutable one. As an example:
        .                                   // `&&mut Foo` is semantically equivalent to `&&Foo`
        8 ( 0.00%)                          match ref_mutability {
       16 ( 0.00%)                              _ if self.inside_unsafe_cell => {
        .                                           // Inside an `UnsafeCell` is like inside a `static mut`, the "outer"
        .                                           // mutability does not matter.
        .                                           InternMode::Static(ref_mutability)
        .                                       }
        .                                       Mutability::Not => {
        .                                           // A shared reference, things become immutable.
        .                                           // We do *not* consider `freeze` here: `intern_shallow` considers
        .                                           // `freeze` for the actual mutability of this allocation; the intern
-- line 241 ----------------------------------------
-- line 254 ----------------------------------------
        .                               }
        .                               InternMode::Const => {
        .                                   // Ignore `UnsafeCell`, everything is immutable.  Validity does some sanity
        .                                   // checking for mutable references that we encounter -- they must all be
        .                                   // ZST.
        .                                   InternMode::Const
        .                               }
        .                           };
      630 ( 0.00%)                  match self.intern_shallow(alloc_id, ref_mode, Some(referenced_ty)) {
        .                               // No need to recurse, these are interned already and statics may have
        .                               // cycles, so we don't want to recurse there
        .                               Some(IsStaticOrFn) => {}
        .                               // intern everything referenced by this value. The mutability is taken from the
        .                               // reference. It is checked above that mutable references only happen in
        .                               // `static mut`
    1,395 ( 0.00%)                      None => self.ref_tracking.track((mplace, ref_mode), || ()),
        .                           }
        .                       }
        .                       Ok(())
        .                   } else {
        .                       // Not a reference -- proceed recursively.
        .                       self.walk_value(mplace)
        .                   }
4,155,984 ( 0.05%)      }
        .           }
        .           
        .           #[derive(Copy, Clone, Debug, PartialEq, Hash, Eq)]
        .           pub enum InternKind {
        .               /// The `mutability` of the static, ignoring the type which may have interior mutability.
        .               Static(hir::Mutability),
        .               Constant,
        .               Promoted,
-- line 285 ----------------------------------------
-- line 286 ----------------------------------------
        .           }
        .           
        .           /// Intern `ret` and everything it references.
        .           ///
        .           /// This *cannot raise an interpreter error*.  Doing so is left to validation, which
        .           /// tracks where in the value we are and thus can show much better error messages.
        .           /// Any errors here would anyway be turned into `const_err` lints, whereas validation failures
        .           /// are hard errors.
    1,784 ( 0.00%)  #[tracing::instrument(level = "debug", skip(ecx))]
    1,784 ( 0.00%)  pub fn intern_const_alloc_recursive<
        .               'mir,
        .               'tcx: 'mir,
        .               M: CompileTimeMachine<'mir, 'tcx, const_eval::MemoryKind>,
        .           >(
        .               ecx: &mut InterpCx<'mir, 'tcx, M>,
        .               intern_kind: InternKind,
        .               ret: &MPlaceTy<'tcx>,
        .           ) -> Result<(), ErrorReported> {
      446 ( 0.00%)      let tcx = ecx.tcx;
    1,561 ( 0.00%)      let base_intern_mode = match intern_kind {
        .                   InternKind::Static(mutbl) => InternMode::Static(mutbl),
        .                   // `Constant` includes array lengths.
        .                   InternKind::Constant | InternKind::Promoted => InternMode::Const,
        .               };
        .           
        .               // Type based interning.
        .               // `ref_tracking` tracks typed references we have already interned and still need to crawl for
        .               // more typed information inside them.
        .               // `leftover_allocations` collects *all* allocations we see, because some might not
        .               // be available in a typed way. They get interned at the end.
        .               let mut ref_tracking = RefTracking::empty();
        .               let leftover_allocations = &mut FxHashSet::default();
        .           
        .               // start with the outermost allocation
      892 ( 0.00%)      intern_shallow(
        .                   ecx,
        .                   leftover_allocations,
        .                   // The outermost allocation must exist, because we allocated it with
        .                   // `Memory::allocate`.
      223 ( 0.00%)          ret.ptr.provenance.unwrap(),
        .                   base_intern_mode,
      223 ( 0.00%)          Some(ret.layout.ty),
        .               );
        .           
        .               ref_tracking.track((*ret, base_intern_mode), || ());
        .           
    3,780 ( 0.00%)      while let Some(((mplace, mode), _)) = ref_tracking.todo.pop() {
    3,780 ( 0.00%)          let res = InternVisitor {
        .                       ref_tracking: &mut ref_tracking,
        .                       ecx,
        .                       mode,
        .                       leftover_allocations,
        .                       inside_unsafe_cell: false,
        .                   }
        .                   .visit_value(&mplace);
        .                   // We deliberately *ignore* interpreter errors here.  When there is a problem, the remaining
        .                   // references are "leftover"-interned, and later validation will show a proper error
        .                   // and point at the right part of the value causing the problem.
      756 ( 0.00%)          match res {
        .                       Ok(()) => {}
        .                       Err(error) => {
        .                           ecx.tcx.sess.delay_span_bug(
        .                               ecx.tcx.span,
        .                               &format!(
        .                                   "error during interning should later cause validation failure: {}",
        .                                   error
        .                               ),
-- line 352 ----------------------------------------
-- line 354 ----------------------------------------
        .                       }
        .                   }
        .               }
        .           
        .               // Intern the rest of the allocations as mutable. These might be inside unions, padding, raw
        .               // pointers, ... So we can't intern them according to their type rules
        .           
        .               let mut todo: Vec<_> = leftover_allocations.iter().cloned().collect();
      630 ( 0.00%)      while let Some(alloc_id) = todo.pop() {
        .                   if let Some((_, mut alloc)) = ecx.memory.alloc_map.remove(&alloc_id) {
        .                       // We can't call the `intern_shallow` method here, as its logic is tailored to safe
        .                       // references and a `leftover_allocations` set (where we only have a todo-list here).
        .                       // So we hand-roll the interning logic here again.
        .                       match intern_kind {
        .                           // Statics may contain mutable allocations even behind relocations.
        .                           // Even for immutable statics it would be ok to have mutable allocations behind
        .                           // raw pointers, e.g. for `static FOO: *const AtomicUsize = &AtomicUsize::new(42)`.
-- line 370 ----------------------------------------
-- line 396 ----------------------------------------
        .                       }
        .                       let alloc = tcx.intern_const_alloc(alloc);
        .                       tcx.set_alloc_id_memory(alloc_id, alloc);
        .                       for &(_, alloc_id) in alloc.relocations().iter() {
        .                           if leftover_allocations.insert(alloc_id) {
        .                               todo.push(alloc_id);
        .                           }
        .                       }
      420 ( 0.00%)          } else if ecx.memory.dead_alloc_map.contains_key(&alloc_id) {
        .                       // Codegen does not like dangling pointers, and generally `tcx` assumes that
        .                       // all allocations referenced anywhere actually exist. So, make sure we error here.
        .                       ecx.tcx.sess.span_err(ecx.tcx.span, "encountered dangling pointer in final constant");
        .                       return Err(ErrorReported);
      840 ( 0.00%)          } else if ecx.tcx.get_global_alloc(alloc_id).is_none() {
        .                       // We have hit an `AllocId` that is neither in local or global memory and isn't
        .                       // marked as dangling by local memory.  That should be impossible.
        .                       span_bug!(ecx.tcx.span, "encountered unknown alloc id {:?}", alloc_id);
        .                   }
        .               }
        .               Ok(())
        .           }
        .           
-- line 417 ----------------------------------------

    3,273 ( 0.00%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/compiler/rustc_const_eval/src/interpret/intern.rs>

--------------------------------------------------------------------------------
The following files chosen for auto-annotation could not be found:
--------------------------------------------------------------------------------
  ./elf/dl-lookup.c
  ./malloc/malloc.c
  ./stdlib/msort.c
  ./string/../sysdeps/x86_64/multiarch/memcmp-avx2-movbe.S
  ./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
  ./string/../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S
  ./string/../sysdeps/x86_64/multiarch/strcmp-avx2.S
  ./string/../sysdeps/x86_64/multiarch/strlen-avx2.S
  /tmp/gcc-build/x86_64-unknown-linux-gnu/libstdc++-v3/libsupc++/../../../../gcc-5.5.0/libstdc++-v3/libsupc++/new_op.cc

--------------------------------------------------------------------------------
Ir                   
--------------------------------------------------------------------------------
286,574,525 ( 3.30%)  events annotated

