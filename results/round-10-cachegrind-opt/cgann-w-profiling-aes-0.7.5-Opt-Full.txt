--------------------------------------------------------------------------------
I1 cache:         65536 B, 64 B, 4-way associative
D1 cache:         32768 B, 64 B, 8-way associative
LL cache:         67108864 B, 64 B, 64-way associative
Command:          /usr/home/liquid/.rustup/toolchains/w-profiling/bin/rustc --crate-name aes --edition=2018 src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts,future-incompat --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -C embed-bitcode=no -C metadata=c43c4c1342e87cc4 -C extra-filename=-c43c4c1342e87cc4 --out-dir /usr/home/liquid/tmp/.tmpG8blMD/target/release/deps -L dependency=/usr/home/liquid/tmp/.tmpG8blMD/target/release/deps --extern cfg_if=/usr/home/liquid/tmp/.tmpG8blMD/target/release/deps/libcfg_if-19e7cc0b6f708960.rmeta --extern cipher=/usr/home/liquid/tmp/.tmpG8blMD/target/release/deps/libcipher-128ca767dd4b8f18.rmeta --extern cpufeatures=/usr/home/liquid/tmp/.tmpG8blMD/target/release/deps/libcpufeatures-f1c02ab183e74a7a.rmeta --extern opaque_debug=/usr/home/liquid/tmp/.tmpG8blMD/target/release/deps/libopaque_debug-aa4da5ec2dfa7d2b.rmeta -Adeprecated -Aunknown-lints -Zincremental-verify-ich
Data file:        results/cgout-w-profiling-aes-0.7.5-Opt-Full
Events recorded:  Ir
Events shown:     Ir
Event sort order: Ir
Thresholds:       0.1
Include dirs:     
User annotated:   
Auto-annotation:  on

--------------------------------------------------------------------------------
Ir                     
--------------------------------------------------------------------------------
5,942,058,460 (100.0%)  PROGRAM TOTALS

--------------------------------------------------------------------------------
Ir                    file:function
--------------------------------------------------------------------------------
302,878,916 ( 5.10%)  ???:computeKnownBits(llvm::Value const*, llvm::APInt const&, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&)
235,118,765 ( 3.96%)  ???:llvm::BasicAAResult::alias(llvm::MemoryLocation const&, llvm::MemoryLocation const&, llvm::AAQueryInfo&)
137,618,239 ( 2.32%)  ???:SimplifyXorInst(llvm::Value*, llvm::Value*, llvm::SimplifyQuery const&, unsigned int) [clone .llvm.1619516508949622737]
131,532,160 ( 2.21%)  ???:llvm::DataLayout::getAlignment(llvm::Type*, bool) const
111,117,146 ( 1.87%)  ???:llvm::DataLayout::getTypeSizeInBits(llvm::Type*) const
108,626,008 ( 1.83%)  ./malloc/malloc.c:_int_free
 99,563,413 ( 1.68%)  ./malloc/malloc.c:_int_malloc
 89,896,777 ( 1.51%)  ???:computeKnownBits(llvm::Value const*, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&) [clone .llvm.15619146473165121143]
 84,151,548 ( 1.42%)  ???:llvm::InstCombinerImpl::SimplifyDemandedUseBits(llvm::Value*, llvm::APInt, llvm::KnownBits&, unsigned int, llvm::Instruction*)
 77,459,007 ( 1.30%)  ???:llvm::getObjectSize(llvm::Value const*, unsigned long&, llvm::DataLayout const&, llvm::TargetLibraryInfo const*, llvm::ObjectSizeOpts)
 69,704,563 ( 1.17%)  ???:computeKnownBitsFromAssume(llvm::Value const*, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&)
 68,755,064 ( 1.16%)  ???:llvm::InstCombinerImpl::run()
 66,484,739 ( 1.12%)  ???:computeKnownBitsFromOperator(llvm::Operator const*, llvm::APInt const&, llvm::KnownBits&, unsigned int, (anonymous namespace)::Query const&)
 65,703,294 ( 1.11%)  ???:llvm::SelectionDAG::computeKnownBits(llvm::SDValue, llvm::APInt const&, unsigned int) const
 65,513,295 ( 1.10%)  ./malloc/malloc.c:malloc
 46,404,212 ( 0.78%)  ???:SimplifyAndInst(llvm::Value*, llvm::Value*, llvm::SimplifyQuery const&, unsigned int) [clone .llvm.1619516508949622737]
 41,776,710 ( 0.70%)  ???:combineInstructionsOverFunction(llvm::Function&, llvm::InstCombineWorklist&, llvm::AAResults*, llvm::AssumptionCache&, llvm::TargetLibraryInfo&, llvm::TargetTransformInfo&, llvm::DominatorTree&, llvm::OptimizationRemarkEmitter&, llvm::BlockFrequencyInfo*, llvm::ProfileSummaryInfo*, unsigned int, llvm::LoopInfo*)
 41,323,854 ( 0.70%)  ???:llvm::AAResults::getModRefInfo(llvm::Instruction const*, llvm::Optional<llvm::MemoryLocation> const&, llvm::AAQueryInfo&)
 34,304,709 ( 0.58%)  ???:llvm::Value::stripAndAccumulateConstantOffsets(llvm::DataLayout const&, llvm::APInt&, bool, llvm::function_ref<bool (llvm::Value&, llvm::APInt&)>) const
 33,528,423 ( 0.56%)  ???:llvm::Type::isSizedDerivedType(llvm::SmallPtrSetImpl<llvm::Type*>*) const
 33,139,269 ( 0.56%)  ./malloc/malloc.c:free
 32,614,708 ( 0.55%)  ./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:__memcpy_avx_unaligned_erms
 30,238,928 ( 0.51%)  ???:llvm::InstCombinerImpl::visitXor(llvm::BinaryOperator&)
 28,526,466 ( 0.48%)  ???:runCVP(llvm::Module&) [clone .llvm.11785992503873176614]
 27,794,175 ( 0.47%)  ???:bool llvm::DenseMapBase<llvm::DenseMap<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*, llvm::DenseMapInfo<(anonymous namespace)::SimpleValue>, llvm::detail::DenseMapPair<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*> >, (anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*, llvm::DenseMapInfo<(anonymous namespace)::SimpleValue>, llvm::detail::DenseMapPair<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*> >::LookupBucketFor<(anonymous namespace)::SimpleValue>((anonymous namespace)::SimpleValue const&, llvm::detail::DenseMapPair<(anonymous namespace)::SimpleValue, llvm::ScopedHashTableVal<(anonymous namespace)::SimpleValue, llvm::Value*>*> const*&) const
 26,151,660 ( 0.44%)  ???:llvm::SelectionDAG::Combine(llvm::CombineLevel, llvm::AAResults*, llvm::CodeGenOpt::Level)
 25,607,623 ( 0.43%)  ???:llvm::FPPassManager::runOnFunction(llvm::Function&)
 24,354,500 ( 0.41%)  ???:llvm::isNonEscapingLocalObject(llvm::Value const*, llvm::SmallDenseMap<llvm::Value const*, bool, 8u, llvm::DenseMapInfo<llvm::Value const*>, llvm::detail::DenseMapPair<llvm::Value const*, bool> >*)
 22,660,372 ( 0.38%)  ???:llvm::ValueHandleBase::AddToUseList()
 22,219,757 ( 0.37%)  ???:llvm::SelectionDAGISel::SelectCodeCommon(llvm::SDNode*, unsigned char const*, unsigned int)
 20,006,622 ( 0.34%)  ./string/../sysdeps/x86_64/multiarch/memcmp-avx2-movbe.S:__memcmp_avx2_movbe
 17,804,658 ( 0.30%)  ???:llvm::TargetLibraryInfoImpl::getLibFunc(llvm::Function const&, llvm::LibFunc&) const
 17,302,267 ( 0.29%)  ???:(anonymous namespace)::MachineCopyPropagation::runOnMachineFunction(llvm::MachineFunction&)
 16,421,265 ( 0.28%)  ???:SimplifyOrInst(llvm::Value*, llvm::Value*, llvm::SimplifyQuery const&, unsigned int) [clone .llvm.1619516508949622737]
 15,875,275 ( 0.27%)  ???:llvm::InstCombinerImpl::visitLoadInst(llvm::LoadInst&)
 15,834,571 ( 0.27%)  ???:llvm::SimplifyInstruction(llvm::Instruction*, llvm::SimplifyQuery const&, llvm::OptimizationRemarkEmitter*)
 15,259,351 ( 0.26%)  ???:(anonymous namespace)::eliminateDeadStores(llvm::Function&, llvm::AAResults&, llvm::MemorySSA&, llvm::DominatorTree&, llvm::PostDominatorTree&, llvm::TargetLibraryInfo const&, llvm::LoopInfo const&) [clone .llvm.5769264623867638418]
 15,130,559 ( 0.25%)  ???:collectBitParts(llvm::Value*, bool, bool, std::map<llvm::Value*, llvm::Optional<(anonymous namespace)::BitPart>, std::less<llvm::Value*>, std::allocator<std::pair<llvm::Value* const, llvm::Optional<(anonymous namespace)::BitPart> > > >&, int, bool&)
 15,099,935 ( 0.25%)  ???:(anonymous namespace)::RAGreedy::tryAssign(llvm::LiveInterval&, llvm::AllocationOrder&, llvm::SmallVectorImpl<llvm::Register>&, llvm::SmallSet<llvm::Register, 16u, std::less<llvm::Register> > const&)
 14,758,434 ( 0.25%)  ???:llvm::AnalysisManager<llvm::Function>::getResultImpl(llvm::AnalysisKey*, llvm::Function&)
 14,524,163 ( 0.24%)  ???:llvm::ScalarEvolution::getAddExpr(llvm::SmallVectorImpl<llvm::SCEV const*>&, llvm::SCEV::NoWrapFlags, unsigned int)
 14,095,683 ( 0.24%)  ???:llvm::TargetLowering::SimplifyDemandedBits(llvm::SDValue, llvm::APInt const&, llvm::APInt const&, llvm::KnownBits&, llvm::TargetLowering::TargetLoweringOpt&, unsigned int, bool) const
 14,048,061 ( 0.24%)  ./malloc/malloc.c:malloc_consolidate
 13,858,125 ( 0.23%)  ???:llvm::AnalysisManager<llvm::Function>::invalidate(llvm::Function&, llvm::PreservedAnalyses const&)
 13,131,936 ( 0.22%)  ???:llvm::InstCombinerImpl::visitCallInst(llvm::CallInst&)
 12,571,214 ( 0.21%)  ???:llvm::Type::getPrimitiveSizeInBits() const
 12,414,755 ( 0.21%)  ???:llvm::AttributeList::addAttributes(llvm::LLVMContext&, unsigned int, llvm::AttrBuilder const&) const
 12,366,813 ( 0.21%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::runSemiNCA(llvm::DominatorTreeBase<llvm::BasicBlock, false>&, unsigned int)
 12,357,221 ( 0.21%)  ???:(anonymous namespace)::LazyValueInfoImpl::solve() [clone .llvm.4316243980339171764]
 12,114,769 ( 0.20%)  ???:llvm::MachineInstr::findRegisterDefOperandIdx(llvm::Register, bool, bool, llvm::TargetRegisterInfo const*) const
 12,070,800 ( 0.20%)  ???:llvm::KnownBits::operator^=(llvm::KnownBits const&)
 11,886,288 ( 0.20%)  /usr/home/liquid/rust/worktree-benchmarking/library/core/src/slice/mod.rs:<rustc_span::source_map::SourceMap>::lookup_source_file_idx
 11,653,160 ( 0.20%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::CalculateFromScratch(llvm::DominatorTreeBase<llvm::BasicBlock, false>&, llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::BatchUpdateInfo*)
 11,558,341 ( 0.19%)  ???:llvm::GVN::processBlock(llvm::BasicBlock*)
 11,493,369 ( 0.19%)  ???:llvm::DemandedBits::isInstructionDead(llvm::Instruction*)
 11,394,848 ( 0.19%)  ???:llvm::ConstantDataSequential::getElementAsConstant(unsigned int) const
 11,260,967 ( 0.19%)  ???:llvm::InstCombinerImpl::SimplifyAssociativeOrCommutative(llvm::BinaryOperator&)
 11,190,326 ( 0.19%)  ???:llvm::KnownBits::computeForAddSub(bool, bool, llvm::KnownBits const&, llvm::KnownBits)
 11,156,155 ( 0.19%)  ./malloc/malloc.c:unlink_chunk.constprop.0
 10,976,620 ( 0.18%)  ???:(anonymous namespace)::DAGCombiner::combine(llvm::SDNode*)
 10,773,455 ( 0.18%)  ./string/../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:__memset_avx2_erms
 10,743,815 ( 0.18%)  ???:llvm::LiveIntervalUnion::Query::collectInterferingVRegs(unsigned int)
 10,309,248 ( 0.17%)  ./elf/dl-lookup.c:_dl_lookup_symbol_x
 10,283,344 ( 0.17%)  ???:llvm::PassRegistry::enumerateWith(llvm::PassRegistrationListener*)
 10,149,831 ( 0.17%)  ???:llvm::BitstreamCursor::readRecord(unsigned int, llvm::SmallVectorImpl<unsigned long>&, llvm::StringRef*)
 10,133,088 ( 0.17%)  ???:llvm::BasicAAResult::getModRefInfo(llvm::CallBase const*, llvm::MemoryLocation const&, llvm::AAQueryInfo&)
 10,086,522 ( 0.17%)  ???:llvm::InlineFunction(llvm::CallBase&, llvm::InlineFunctionInfo&, llvm::AAResults*, bool, llvm::Function*)
 10,071,852 ( 0.17%)  ???:llvm::InstCombinerImpl::visitAnd(llvm::BinaryOperator&)
 10,027,380 ( 0.17%)  /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs:<hashbrown::map::RawEntryBuilderMut<rustc_middle::ty::context::Interned<rustc_middle::ty::TyS>, (), core::hash::BuildHasherDefault<rustc_hash::FxHasher>>>::from_hash::<hashbrown::map::equivalent<rustc_middle::ty::sty::TyKind, rustc_middle::ty::context::Interned<rustc_middle::ty::TyS>>::{closure#0}>
  9,816,733 ( 0.17%)  ???:llvm::PointerMayBeCaptured(llvm::Value const*, llvm::CaptureTracker*, unsigned int)
  9,591,956 ( 0.16%)  ???:(anonymous namespace)::RAGreedy::trySplit(llvm::LiveInterval&, llvm::AllocationOrder&, llvm::SmallVectorImpl<llvm::Register>&, llvm::SmallSet<llvm::Register, 16u, std::less<llvm::Register> > const&)
  9,504,780 ( 0.16%)  ???:llvm::InstCombinerImpl::visitStoreInst(llvm::StoreInst&)
  9,366,691 ( 0.16%)  ???:(anonymous namespace)::LazyValueInfoImpl::getEdgeValue(llvm::Value*, llvm::BasicBlock*, llvm::BasicBlock*, llvm::Instruction*) [clone .llvm.4316243980339171764]
  9,236,778 ( 0.16%)  ???:llvm::slpvectorizer::BoUpSLP::BlockScheduling::calculateDependencies(llvm::slpvectorizer::BoUpSLP::ScheduleData*, bool, llvm::slpvectorizer::BoUpSLP*)
  8,983,223 ( 0.15%)  ???:llvm::Constant::getNullValue(llvm::Type*)
  8,782,468 ( 0.15%)  ???:llvm::SmallPtrSetImplBase::insert_imp_big(void const*)
  8,744,900 ( 0.15%)  ???:llvm::KnownBits::lshr(llvm::KnownBits const&, llvm::KnownBits const&)
  8,739,886 ( 0.15%)  ???:(anonymous namespace)::EarlyCSE::run() [clone .llvm.7062997131228810369]
  8,727,096 ( 0.15%)  ???:llvm::KnownBits::shl(llvm::KnownBits const&, llvm::KnownBits const&)
  8,552,488 ( 0.14%)  ???:llvm::ScalarEvolution::getRangeRef(llvm::SCEV const*, llvm::ScalarEvolution::RangeSignHint)
  8,521,173 ( 0.14%)  ???:(anonymous namespace)::Verifier::visitInstruction(llvm::Instruction&)
  8,477,894 ( 0.14%)  ???:llvm::LivePhysRegs::stepBackward(llvm::MachineInstr const&)
  8,449,989 ( 0.14%)  ???:(anonymous namespace)::ClobberWalker<llvm::BatchAAResults>::findClobber(llvm::MemoryAccess*, (anonymous namespace)::UpwardsMemoryQuery&, unsigned int&)
  8,321,906 ( 0.14%)  ???:ComputeNumSignBitsImpl(llvm::Value const*, llvm::APInt const&, unsigned int, (anonymous namespace)::Query const&) [clone .llvm.15619146473165121143]
  8,147,749 ( 0.14%)  ???:llvm::removeUnreachableBlocks(llvm::Function&, llvm::DomTreeUpdater*, llvm::MemorySSAUpdater*)
  8,127,595 ( 0.14%)  /usr/home/liquid/rust/worktree-benchmarking/compiler/rustc_infer/src/infer/mod.rs:<rustc_infer::infer::InferCtxt>::shallow_resolve_ty
  7,929,022 ( 0.13%)  ???:llvm::SimplifyGEPInst(llvm::Type*, llvm::ArrayRef<llvm::Value*>, llvm::SimplifyQuery const&)
  7,905,403 ( 0.13%)  ???:llvm::MemoryLocation::getOrNone(llvm::Instruction const*)
  7,829,720 ( 0.13%)  ???:llvm::DenseMapBase<llvm::SmallDenseMap<std::pair<llvm::AACacheLoc, llvm::AACacheLoc>, llvm::AAQueryInfo::CacheEntry, 8u, llvm::DenseMapInfo<std::pair<llvm::AACacheLoc, llvm::AACacheLoc> >, llvm::detail::DenseMapPair<std::pair<llvm::AACacheLoc, llvm::AACacheLoc>, llvm::AAQueryInfo::CacheEntry> >, std::pair<llvm::AACacheLoc, llvm::AACacheLoc>, llvm::AAQueryInfo::CacheEntry, llvm::DenseMapInfo<std::pair<llvm::AACacheLoc, llvm::AACacheLoc> >, llvm::detail::DenseMapPair<std::pair<llvm::AACacheLoc, llvm::AACacheLoc>, llvm::AAQueryInfo::CacheEntry> >::moveFromOldBuckets(llvm::detail::DenseMapPair<std::pair<llvm::AACacheLoc, llvm::AACacheLoc>, llvm::AAQueryInfo::CacheEntry>*, llvm::detail::DenseMapPair<std::pair<llvm::AACacheLoc, llvm::AACacheLoc>, llvm::AAQueryInfo::CacheEntry>*)
  7,819,781 ( 0.13%)  ???:EvaluateExpression(llvm::Value*, llvm::Loop const*, llvm::DenseMap<llvm::Instruction*, llvm::Constant*, llvm::DenseMapInfo<llvm::Instruction*>, llvm::detail::DenseMapPair<llvm::Instruction*, llvm::Constant*> >&, llvm::DataLayout const&, llvm::TargetLibraryInfo const*)
  7,704,576 ( 0.13%)  /tmp/gcc-build/x86_64-unknown-linux-gnu/libstdc++-v3/libsupc++/../../../../gcc-5.5.0/libstdc++-v3/libsupc++/new_op.cc:operator new(unsigned long)
  7,670,761 ( 0.13%)  ???:llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::DeleteEdge(llvm::DominatorTreeBase<llvm::BasicBlock, false>&, llvm::DomTreeBuilder::SemiNCAInfo<llvm::DominatorTreeBase<llvm::BasicBlock, false> >::BatchUpdateInfo*, llvm::BasicBlock*, llvm::BasicBlock*)
  7,656,691 ( 0.13%)  ???:(anonymous namespace)::CVPLatticeFunc::ComputeInstructionState(llvm::Instruction&, llvm::DenseMap<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > >, (anonymous namespace)::CVPLatticeVal, llvm::DenseMapInfo<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > > >, llvm::detail::DenseMapPair<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > >, (anonymous namespace)::CVPLatticeVal> >&, llvm::SparseSolver<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > >, (anonymous namespace)::CVPLatticeVal, llvm::LatticeKeyInfo<llvm::PointerIntPair<llvm::Value*, 2u, (anonymous namespace)::IPOGrouping, llvm::PointerLikeTypeTraits<llvm::Value*>, llvm::PointerIntPairInfo<llvm::Value*, 2u, llvm::PointerLikeTypeTraits<llvm::Value*> > > > >&)
  7,647,140 ( 0.13%)  ???:llvm::MemoryLocation::get(llvm::LoadInst const*)
  7,597,893 ( 0.13%)  ???:llvm::ConstantRange::makeExactICmpRegion(llvm::CmpInst::Predicate, llvm::APInt const&)
  7,462,685 ( 0.13%)  ???:llvm::ScalarEvolution::getSCEV(llvm::Value*)
  7,411,558 ( 0.12%)  ???:llvm::TargetTransformInfo::Model<llvm::X86TTIImpl>::getUserCost(llvm::User const*, llvm::ArrayRef<llvm::Value const*>, llvm::TargetTransformInfo::TargetCostKind)
  7,385,621 ( 0.12%)  ???:llvm::MemorySSA::OptimizeUses::optimizeUses()
  7,373,747 ( 0.12%)  ???:LinearizeExprTree(llvm::Instruction*, llvm::SmallVectorImpl<std::pair<llvm::Value*, llvm::APInt> >&)
  7,342,905 ( 0.12%)  ???:llvm::InstCombinerImpl::SimplifyUsingDistributiveLaws(llvm::BinaryOperator&)
  7,339,313 ( 0.12%)  ???:llvm::ScheduleDAGInstrs::addPhysRegDeps(llvm::SUnit*, unsigned int)
  7,235,438 ( 0.12%)  ???:llvm::ConstantInt::get(llvm::LLVMContext&, llvm::APInt const&)
  7,154,947 ( 0.12%)  ???:llvm::SCCPInstVisitor::solve()
  7,137,696 ( 0.12%)  ???:llvm::X86TargetLowering::X86TargetLowering(llvm::X86TargetMachine const&, llvm::X86Subtarget const&)
  7,042,640 ( 0.12%)  ???:llvm::Loop::isLCSSAForm(llvm::DominatorTree const&) const
  6,852,809 ( 0.12%)  ???:llvm::LiveVariables::runOnBlock(llvm::MachineBasicBlock*, unsigned int)
  6,769,049 ( 0.11%)  ???:llvm::SROA::splitAlloca(llvm::AllocaInst&, llvm::sroa::AllocaSlices&)
  6,579,314 ( 0.11%)  ???:(anonymous namespace)::RAGreedy::tryEvict(llvm::LiveInterval&, llvm::AllocationOrder&, llvm::SmallVectorImpl<llvm::Register>&, unsigned char, llvm::SmallSet<llvm::Register, 16u, std::less<llvm::Register> > const&)
  6,453,665 ( 0.11%)  ???:bool llvm::PatternMatch::cstval_pred_ty<llvm::PatternMatch::is_all_ones, llvm::ConstantInt>::match<llvm::Value>(llvm::Value*)
  6,440,762 ( 0.11%)  ???:llvm::ScalarEvolution::getAddRecExpr(llvm::SmallVectorImpl<llvm::SCEV const*>&, llvm::Loop const*, llvm::SCEV::NoWrapFlags)
  6,365,081 ( 0.11%)  ???:llvm::MemorySSA::buildMemorySSA(llvm::BatchAAResults&)
  6,246,327 ( 0.11%)  ???:llvm::Loop::isRecursivelyLCSSAForm(llvm::DominatorTree const&, llvm::LoopInfo const&) const
  6,234,330 ( 0.10%)  ???:llvm::VirtRegAuxInfo::weightCalcHelper(llvm::LiveInterval&, llvm::SlotIndex*, llvm::SlotIndex*)
  6,163,522 ( 0.10%)  ???:llvm::ScalarEvolution::computeExitCountExhaustively(llvm::Loop const*, llvm::Value*, bool)
  6,161,741 ( 0.10%)  ./malloc/malloc.c:realloc
  6,154,874 ( 0.10%)  ???:llvm::MemoryDependenceResults::getNonLocalPointerDepFromBB(llvm::Instruction*, llvm::PHITransAddr const&, llvm::MemoryLocation const&, bool, llvm::BasicBlock*, llvm::SmallVectorImpl<llvm::NonLocalDepResult>&, llvm::DenseMap<llvm::BasicBlock*, llvm::Value*, llvm::DenseMapInfo<llvm::BasicBlock*>, llvm::detail::DenseMapPair<llvm::BasicBlock*, llvm::Value*> >&, bool, bool)
  6,135,609 ( 0.10%)  ???:llvm::SCCPInstVisitor::visitBinaryOperator(llvm::Instruction&)
  6,111,536 ( 0.10%)  /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs:<hashbrown::map::RawEntryBuilder<rustc_span::def_id::LocalDefId, (&rustc_middle::ty::context::TypeckResults, rustc_query_system::dep_graph::graph::DepNodeIndex), core::hash::BuildHasherDefault<rustc_hash::FxHasher>>>::from_key_hashed_nocheck::<rustc_span::def_id::LocalDefId>
  6,105,920 ( 0.10%)  ???:llvm::TargetLoweringBase::computeRegisterProperties(llvm::TargetRegisterInfo const*)
  6,092,197 ( 0.10%)  ???:llvm::AAResults::Model<llvm::BasicAAResult>::pointsToConstantMemory(llvm::MemoryLocation const&, llvm::AAQueryInfo&, bool)
  6,091,596 ( 0.10%)  ???:llvm::TargetLoweringBase::getTypeConversion(llvm::LLVMContext&, llvm::EVT) const
  6,036,606 ( 0.10%)  ???:llvm::ScalarEvolution::getMulExpr(llvm::SmallVectorImpl<llvm::SCEV const*>&, llvm::SCEV::NoWrapFlags, unsigned int)
  6,026,313 ( 0.10%)  ???:llvm::LiveRegMatrix::checkInterference(llvm::LiveInterval&, llvm::MCRegister)
  5,979,777 ( 0.10%)  ???:llvm::MachineInstr::addOperand(llvm::MachineFunction&, llvm::MachineOperand const&)

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/library/core/src/slice/mod.rs
--------------------------------------------------------------------------------
Ir                 

-- line 141 ----------------------------------------
        .               /// ```
        .               /// let a = [1, 2, 3];
        .               /// assert!(!a.is_empty());
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_stable(feature = "const_slice_is_empty", since = "1.39.0")]
        .               #[inline]
        .               pub const fn is_empty(&self) -> bool {
  593,934 ( 0.01%)          self.len() == 0
        .               }
        .           
        .               /// Returns the first element of the slice, or `None` if it is empty.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let v = [10, 40, 30];
-- line 157 ----------------------------------------
-- line 159 ----------------------------------------
        .               ///
        .               /// let w: &[i32] = &[];
        .               /// assert_eq!(None, w.first());
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_stable(feature = "const_slice_first_last_not_mut", since = "1.56.0")]
        .               #[inline]
        .               pub const fn first(&self) -> Option<&T> {
    4,184 ( 0.00%)          if let [first, ..] = self { Some(first) } else { None }
        .               }
        .           
        .               /// Returns a mutable pointer to the first element of the slice, or `None` if it is empty.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let x = &mut [0, 1, 2];
-- line 175 ----------------------------------------
-- line 178 ----------------------------------------
        .               ///     *first = 5;
        .               /// }
        .               /// assert_eq!(x, &[5, 1, 2]);
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_unstable(feature = "const_slice_first_last", issue = "83570")]
        .               #[inline]
        .               pub const fn first_mut(&mut self) -> Option<&mut T> {
      224 ( 0.00%)          if let [first, ..] = self { Some(first) } else { None }
        .               }
        .           
        .               /// Returns the first and all the rest of the elements of the slice, or `None` if it is empty.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let x = &[0, 1, 2];
-- line 194 ----------------------------------------
-- line 237 ----------------------------------------
        .               ///     assert_eq!(last, &2);
        .               ///     assert_eq!(elements, &[0, 1]);
        .               /// }
        .               /// ```
        .               #[stable(feature = "slice_splits", since = "1.5.0")]
        .               #[rustc_const_stable(feature = "const_slice_first_last_not_mut", since = "1.56.0")]
        .               #[inline]
        .               pub const fn split_last(&self) -> Option<(&T, &[T])> {
    8,343 ( 0.00%)          if let [init @ .., last] = self { Some((last, init)) } else { None }
        .               }
        .           
        .               /// Returns the last and all the rest of the elements of the slice, or `None` if it is empty.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let x = &mut [0, 1, 2];
-- line 253 ----------------------------------------
-- line 276 ----------------------------------------
        .               ///
        .               /// let w: &[i32] = &[];
        .               /// assert_eq!(None, w.last());
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_stable(feature = "const_slice_first_last_not_mut", since = "1.56.0")]
        .               #[inline]
        .               pub const fn last(&self) -> Option<&T> {
  364,131 ( 0.01%)          if let [.., last] = self { Some(last) } else { None }
        .               }
        .           
        .               /// Returns a mutable pointer to the last item in the slice.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let x = &mut [0, 1, 2];
-- line 292 ----------------------------------------
-- line 295 ----------------------------------------
        .               ///     *last = 10;
        .               /// }
        .               /// assert_eq!(x, &[0, 1, 10]);
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_unstable(feature = "const_slice_first_last", issue = "83570")]
        .               #[inline]
        .               pub const fn last_mut(&mut self) -> Option<&mut T> {
  395,585 ( 0.01%)          if let [.., last] = self { Some(last) } else { None }
        .               }
        .           
        .               /// Returns a reference to an element or subslice depending on the type of
        .               /// index.
        .               ///
        .               /// - If given a position, returns a reference to the element at that
        .               ///   position or `None` if out of bounds.
        .               /// - If given a range, returns the subslice corresponding to that range,
-- line 311 ----------------------------------------
-- line 448 ----------------------------------------
        .               /// }
        .               /// ```
        .               ///
        .               /// [`as_mut_ptr`]: slice::as_mut_ptr
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_stable(feature = "const_slice_as_ptr", since = "1.32.0")]
        .               #[inline]
        .               pub const fn as_ptr(&self) -> *const T {
  663,060 ( 0.01%)          self as *const [T] as *const T
        .               }
        .           
        .               /// Returns an unsafe mutable pointer to the slice's buffer.
        .               ///
        .               /// The caller must ensure that the slice outlives the pointer this
        .               /// function returns, or else it will end up pointing to garbage.
        .               ///
        .               /// Modifying the container referenced by this slice may cause its buffer
-- line 464 ----------------------------------------
-- line 476 ----------------------------------------
        .               ///     }
        .               /// }
        .               /// assert_eq!(x, &[3, 4, 6]);
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_unstable(feature = "const_ptr_offset", issue = "71499")]
        .               #[inline]
        .               pub const fn as_mut_ptr(&mut self) -> *mut T {
       14 ( 0.00%)          self as *mut [T] as *mut T
        .               }
        .           
        .               /// Returns the two raw pointers spanning the slice.
        .               ///
        .               /// The returned range is half-open, which means that the end pointer
        .               /// points *one past* the last element of the slice. This way, an empty
        .               /// slice is represented by two equal pointers, and the difference between
        .               /// the two pointers represents the size of the slice.
-- line 492 ----------------------------------------
-- line 582 ----------------------------------------
        .               /// v.swap(2, 4);
        .               /// assert!(v == ["a", "b", "e", "d", "c"]);
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[rustc_const_unstable(feature = "const_swap", issue = "83163")]
        .               #[inline]
        .               #[track_caller]
        .               pub const fn swap(&mut self, a: usize, b: usize) {
   32,336 ( 0.00%)          let _ = &self[a];
   94,372 ( 0.00%)          let _ = &self[b];
        .           
        .                   // SAFETY: we just checked that both `a` and `b` are in bounds
        .                   unsafe { self.swap_unchecked(a, b) }
        .               }
        .           
        .               /// Swaps two elements in the slice, without doing bounds checking.
        .               ///
        .               /// For a safe alternative see [`swap`].
-- line 599 ----------------------------------------
-- line 677 ----------------------------------------
        .           
        .                       // Because this function is first compiled in isolation,
        .                       // this check tells LLVM that the indexing below is
        .                       // in-bounds.  Then after inlining -- once the actual
        .                       // lengths of the slices are known -- it's removed.
        .                       let (a, b) = (&mut a[..n], &mut b[..n]);
        .           
        .                       for i in 0..n {
    1,045 ( 0.00%)                  mem::swap(&mut a[i], &mut b[n - 1 - i]);
        .                       }
        .                   }
        .               }
        .           
        .               /// Returns an iterator over the slice.
        .               ///
        .               /// # Examples
        .               ///
-- line 693 ----------------------------------------
-- line 1499 ----------------------------------------
        .               ///     assert_eq!(left, [1, 2, 3, 4, 5, 6]);
        .               ///     assert_eq!(right, []);
        .               /// }
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[inline]
        .               #[track_caller]
        .               pub fn split_at(&self, mid: usize) -> (&[T], &[T]) {
      414 ( 0.00%)          assert!(mid <= self.len());
        .                   // SAFETY: `[ptr; mid]` and `[mid; len]` are inside `self`, which
        .                   // fulfills the requirements of `from_raw_parts_mut`.
        .                   unsafe { self.split_at_unchecked(mid) }
        .               }
        .           
        .               /// Divides one mutable slice into two at an index.
        .               ///
        .               /// The first will contain all indices from `[0, mid)` (excluding
-- line 1515 ----------------------------------------
-- line 1530 ----------------------------------------
        .               /// left[1] = 2;
        .               /// right[1] = 4;
        .               /// assert_eq!(v, [1, 2, 3, 4, 5, 6]);
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[inline]
        .               #[track_caller]
        .               pub fn split_at_mut(&mut self, mid: usize) -> (&mut [T], &mut [T]) {
   26,634 ( 0.00%)          assert!(mid <= self.len());
        .                   // SAFETY: `[ptr; mid]` and `[mid; len]` are inside `self`, which
        .                   // fulfills the requirements of `from_raw_parts_mut`.
        .                   unsafe { self.split_at_mut_unchecked(mid) }
        .               }
        .           
        .               /// Divides one slice into two at an index, without doing bounds checking.
        .               ///
        .               /// The first will contain all indices from `[0, mid)` (excluding
-- line 1546 ----------------------------------------
-- line 1628 ----------------------------------------
        .               pub unsafe fn split_at_mut_unchecked(&mut self, mid: usize) -> (&mut [T], &mut [T]) {
        .                   let len = self.len();
        .                   let ptr = self.as_mut_ptr();
        .           
        .                   // SAFETY: Caller has to check that `0 <= mid <= self.len()`.
        .                   //
        .                   // `[ptr; mid]` and `[mid; len]` are not overlapping, so returning a mutable reference
        .                   // is fine.
    1,844 ( 0.00%)          unsafe { (from_raw_parts_mut(ptr, mid), from_raw_parts_mut(ptr.add(mid), len - mid)) }
        .               }
        .           
        .               /// Divides one slice into an array and a remainder slice at an index.
        .               ///
        .               /// The array will contain all indices from `[0, N)` (excluding
        .               /// the index `N` itself) and the slice will contain all
        .               /// indices from `[N, len)` (excluding the index `len` itself).
        .               ///
-- line 1644 ----------------------------------------
-- line 2113 ----------------------------------------
        .               /// assert!(!v.iter().any(|e| e == "hi"));
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               #[inline]
        .               pub fn contains(&self, x: &T) -> bool
        .               where
        .                   T: PartialEq,
        .               {
      116 ( 0.00%)          cmp::SliceContains::slice_contains(x, self)
        .               }
        .           
        .               /// Returns `true` if `needle` is a prefix of the slice.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let v = [10, 40, 30];
-- line 2129 ----------------------------------------
-- line 2142 ----------------------------------------
        .               /// assert!(v.starts_with(&[]));
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               pub fn starts_with(&self, needle: &[T]) -> bool
        .               where
        .                   T: PartialEq,
        .               {
        .                   let n = needle.len();
   29,395 ( 0.00%)          self.len() >= n && needle == &self[..n]
        .               }
        .           
        .               /// Returns `true` if `needle` is a suffix of the slice.
        .               ///
        .               /// # Examples
        .               ///
        .               /// ```
        .               /// let v = [10, 40, 30];
-- line 2158 ----------------------------------------
-- line 2171 ----------------------------------------
        .               /// assert!(v.ends_with(&[]));
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               pub fn ends_with(&self, needle: &[T]) -> bool
        .               where
        .                   T: PartialEq,
        .               {
        .                   let (m, n) = (self.len(), needle.len());
    1,912 ( 0.00%)          m >= n && needle == &self[m - n..]
        .               }
        .           
        .               /// Returns a subslice with the prefix removed.
        .               ///
        .               /// If the slice starts with `prefix`, returns the subslice after the prefix, wrapped in `Some`.
        .               /// If `prefix` is empty, simply returns the original slice.
        .               ///
        .               /// If the slice does not start with `prefix`, returns `None`.
-- line 2187 ----------------------------------------
-- line 2293 ----------------------------------------
        .               /// s.insert(idx, num);
        .               /// assert_eq!(s, [0, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 42, 55]);
        .               /// ```
        .               #[stable(feature = "rust1", since = "1.0.0")]
        .               pub fn binary_search(&self, x: &T) -> Result<usize, usize>
        .               where
        .                   T: Ord,
        .               {
        3 ( 0.00%)          self.binary_search_by(|p| p.cmp(x))
        .               }
        .           
        .               /// Binary searches this sorted slice with a comparator function.
        .               ///
        .               /// The comparator function should implement an order consistent
        .               /// with the sort order of the underlying slice, returning an
        .               /// order code that indicates whether its argument is `Less`,
        .               /// `Equal` or `Greater` the desired target.
-- line 2309 ----------------------------------------
-- line 2345 ----------------------------------------
        .               #[inline]
        .               pub fn binary_search_by<'a, F>(&'a self, mut f: F) -> Result<usize, usize>
        .               where
        .                   F: FnMut(&'a T) -> Ordering,
        .               {
        .                   let mut size = self.len();
        .                   let mut left = 0;
        .                   let mut right = size;
3,173,186 ( 0.05%)          while left < right {
4,709,486 ( 0.08%)              let mid = left + size / 2;
        .           
        .                       // SAFETY: the call is made safe by the following invariants:
        .                       // - `mid >= 0`
        .                       // - `mid < size`: `mid` is limited by `[left; right)` bound.
1,062,827 ( 0.02%)              let cmp = f(unsafe { self.get_unchecked(mid) });
        .           
        .                       // The reason why we use if/else control flow rather than match
        .                       // is because match reorders comparison operations, which is perf sensitive.
        .                       // This is x86 asm for u8: https://rust.godbolt.org/z/8Y8Pra.
1,290,771 ( 0.02%)              if cmp == Less {
2,580,712 ( 0.04%)                  left = mid + 1;
  594,281 ( 0.01%)              } else if cmp == Greater {
        .                           right = mid;
        .                       } else {
        .                           // SAFETY: same as the `get_unchecked` above
        .                           unsafe { crate::intrinsics::assume(mid < self.len()) };
        .                           return Ok(mid);
        .                       }
        .           
3,916,938 ( 0.07%)              size = right - left;
        .                   }
        .                   Err(left)
        .               }
        .           
        .               /// Binary searches this sorted slice with a key extraction function.
        .               ///
        .               /// Assumes that the slice is sorted by the key, for instance with
        .               /// [`sort_by_key`] using the same key extraction function.
-- line 2382 ----------------------------------------
-- line 3203 ----------------------------------------
        .                   #[track_caller]
        .                   fn len_mismatch_fail(dst_len: usize, src_len: usize) -> ! {
        .                       panic!(
        .                           "source slice length ({}) does not match destination slice length ({})",
        .                           src_len, dst_len,
        .                       );
        .                   }
        .           
   76,760 ( 0.00%)          if self.len() != src.len() {
        .                       len_mismatch_fail(self.len(), src.len());
        .                   }
        .           
        .                   // SAFETY: `self` is valid for `self.len()` elements by definition, and `src` was
        .                   // checked to have the same length. The slices cannot overlap because
        .                   // mutable references are exclusive.
        .                   unsafe {
        .                       ptr::copy_nonoverlapping(src.as_ptr(), self.as_mut_ptr(), self.len());
-- line 3219 ----------------------------------------
-- line 3382 ----------------------------------------
        .                   }
        .                   let gcd: usize = gcd(mem::size_of::<T>(), mem::size_of::<U>());
        .                   let ts: usize = mem::size_of::<U>() / gcd;
        .                   let us: usize = mem::size_of::<T>() / gcd;
        .           
        .                   // Armed with this knowledge, we can find how many `U`s we can fit!
        .                   let us_len = self.len() / ts * us;
        .                   // And how many `T`s will be in the trailing slice!
   15,368 ( 0.00%)          let ts_len = self.len() % ts;
        .                   (us_len, ts_len)
        .               }
        .           
        .               /// Transmute the slice to a slice of another type, ensuring alignment of the types is
        .               /// maintained.
        .               ///
        .               /// This method splits the slice into three distinct slices: prefix, correctly aligned middle
        .               /// slice of a new type, and the suffix slice. The method may make the middle slice the greatest
-- line 3398 ----------------------------------------
-- line 3429 ----------------------------------------
        .                       return (self, &[], &[]);
        .                   }
        .           
        .                   // First, find at what point do we split between the first and 2nd slice. Easy with
        .                   // ptr.align_offset.
        .                   let ptr = self.as_ptr();
        .                   // SAFETY: See the `align_to_mut` method for the detailed safety comment.
        .                   let offset = unsafe { crate::ptr::align_offset(ptr, mem::align_of::<U>()) };
   15,368 ( 0.00%)          if offset > self.len() {
        .                       (self, &[], &[])
        .                   } else {
        .                       let (left, rest) = self.split_at(offset);
        .                       let (us_len, ts_len) = rest.align_to_offsets::<U>();
        .                       // SAFETY: now `rest` is definitely aligned, so `from_raw_parts` below is okay,
        .                       // since the caller guarantees that we can transmute `T` to `U` safely.
        .                       unsafe {
        .                           (
        .                               left,
        .                               from_raw_parts(rest.as_ptr() as *const U, us_len),
   15,368 ( 0.00%)                      from_raw_parts(rest.as_ptr().add(rest.len() - ts_len), ts_len),
        .                           )
        .                       }
        .                   }
        .               }
        .           
        .               /// Transmute the slice to a slice of another type, ensuring alignment of the types is
        .               /// maintained.
        .               ///
-- line 3456 ----------------------------------------

2,809,295 ( 0.05%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/library/core/src/slice/mod.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/rust/worktree-benchmarking/compiler/rustc_infer/src/infer/mod.rs
--------------------------------------------------------------------------------
Ir                 

-- line 108 ----------------------------------------
        .                   suppress_errors: bool,
        .               },
        .           }
        .           
        .           impl RegionckMode {
        .               /// Indicates that the MIR borrowck will repeat these region
        .               /// checks, so we should ignore errors if NLL is (unconditionally)
        .               /// enabled.
      350 ( 0.00%)      pub fn for_item_body(tcx: TyCtxt<'_>) -> Self {
        .                   // FIXME(Centril): Once we actually remove `::Migrate` also make
        .                   // this always `true` and then proceed to eliminate the dead code.
      350 ( 0.00%)          match tcx.borrowck_mode() {
        .                       // If we're on Migrate mode, report AST region errors
        .                       BorrowckMode::Migrate => RegionckMode::Erase { suppress_errors: false },
        .           
        .                       // If we're on MIR, don't report AST region errors as they should be reported by NLL
        .                       BorrowckMode::Mir => RegionckMode::Erase { suppress_errors: true },
        .                   }
      700 ( 0.00%)      }
        .           }
        .           
        .           /// This type contains all the things within `InferCtxt` that sit within a
        .           /// `RefCell` and are involved with taking/rolling back snapshots. Snapshot
        .           /// operations are hot enough that we want only one call to `borrow_mut` per
        .           /// call to `start_snapshot` and `rollback_to`.
        .           pub struct InferCtxtInner<'tcx> {
        .               /// Cache for projections. This cache is snapshotted along with the infcx.
-- line 134 ----------------------------------------
-- line 202 ----------------------------------------
        .               /// type instantiations (`ty::Infer`) to the actual opaque
        .               /// type (`ty::Opaque`). Used during fallback to map unconstrained
        .               /// opaque type inference variables to their corresponding
        .               /// opaque type.
        .               pub opaque_types_vars: FxHashMap<Ty<'tcx>, Ty<'tcx>>,
        .           }
        .           
        .           impl<'tcx> InferCtxtInner<'tcx> {
   38,025 ( 0.00%)      fn new() -> InferCtxtInner<'tcx> {
  258,570 ( 0.00%)          InferCtxtInner {
        .                       projection_cache: Default::default(),
        .                       type_variable_storage: type_variable::TypeVariableStorage::new(),
        .                       undo_log: InferCtxtUndoLogs::default(),
        .                       const_unification_storage: ut::UnificationTableStorage::new(),
        .                       int_unification_storage: ut::UnificationTableStorage::new(),
        .                       float_unification_storage: ut::UnificationTableStorage::new(),
   22,815 ( 0.00%)              region_constraint_storage: Some(RegionConstraintStorage::new()),
        .                       region_obligations: vec![],
        .                       opaque_types: Default::default(),
        .                       opaque_types_vars: Default::default(),
        .                   }
   45,630 ( 0.00%)      }
        .           
        .               #[inline]
        .               pub fn region_obligations(&self) -> &[(hir::HirId, RegionObligation<'tcx>)] {
        .                   &self.region_obligations
        .               }
        .           
        .               #[inline]
        .               pub fn projection_cache(&mut self) -> traits::ProjectionCache<'_, 'tcx> {
   11,468 ( 0.00%)          self.projection_cache.with_log(&mut self.undo_log)
        .               }
        .           
        .               #[inline]
        .               fn type_variables(&mut self) -> type_variable::TypeVariableTable<'_, 'tcx> {
  551,940 ( 0.01%)          self.type_variable_storage.with_log(&mut self.undo_log)
        .               }
        .           
        .               #[inline]
        .               fn int_unification_table(
        .                   &mut self,
        .               ) -> ut::UnificationTable<
        .                   ut::InPlace<
        .                       ty::IntVid,
        .                       &mut ut::UnificationStorage<ty::IntVid>,
        .                       &mut InferCtxtUndoLogs<'tcx>,
        .                   >,
        .               > {
  106,397 ( 0.00%)          self.int_unification_storage.with_log(&mut self.undo_log)
        .               }
        .           
        .               #[inline]
        .               fn float_unification_table(
        .                   &mut self,
        .               ) -> ut::UnificationTable<
        .                   ut::InPlace<
        .                       ty::FloatVid,
-- line 258 ----------------------------------------
-- line 268 ----------------------------------------
        .                   &mut self,
        .               ) -> ut::UnificationTable<
        .                   ut::InPlace<
        .                       ty::ConstVid<'tcx>,
        .                       &mut ut::UnificationStorage<ty::ConstVid<'tcx>>,
        .                       &mut InferCtxtUndoLogs<'tcx>,
        .                   >,
        .               > {
   13,445 ( 0.00%)          self.const_unification_storage.with_log(&mut self.undo_log)
        .               }
        .           
        .               #[inline]
        .               pub fn unwrap_region_constraints(&mut self) -> RegionConstraintCollector<'_, 'tcx> {
   28,718 ( 0.00%)          self.region_constraint_storage
        .                       .as_mut()
        .                       .expect("region constraints already solved")
   31,497 ( 0.00%)              .with_log(&mut self.undo_log)
        .               }
        .           }
        .           
        .           pub struct InferCtxt<'a, 'tcx> {
        .               pub tcx: TyCtxt<'tcx>,
        .           
        .               /// The `DefId` of the item in whose context we are performing inference or typeck.
        .               /// It is used to check whether an opaque type use is a defining use.
-- line 292 ----------------------------------------
-- line 361 ----------------------------------------
        .               /// item we are type-checking, and just consider those names as
        .               /// part of the root universe. So this would only get incremented
        .               /// when we enter into a higher-ranked (`for<..>`) type or trait
        .               /// bound.
        .               universe: Cell<ty::UniverseIndex>,
        .           }
        .           
        .           /// See the `error_reporting` module for more details.
   34,392 ( 0.00%)  #[derive(Clone, Copy, Debug, PartialEq, Eq, TypeFoldable)]
        .           pub enum ValuePairs<'tcx> {
        .               Types(ExpectedFound<Ty<'tcx>>),
        .               Regions(ExpectedFound<ty::Region<'tcx>>),
        .               Consts(ExpectedFound<&'tcx ty::Const<'tcx>>),
        .               TraitRefs(ExpectedFound<ty::TraitRef<'tcx>>),
        .               PolyTraitRefs(ExpectedFound<ty::PolyTraitRef<'tcx>>),
        .           }
        .           
-- line 377 ----------------------------------------
-- line 383 ----------------------------------------
        .           pub struct TypeTrace<'tcx> {
        .               cause: ObligationCause<'tcx>,
        .               values: ValuePairs<'tcx>,
        .           }
        .           
        .           /// The origin of a `r1 <= r2` constraint.
        .           ///
        .           /// See `error_reporting` module for more details
   25,314 ( 0.00%)  #[derive(Clone, Debug)]
        .           pub enum SubregionOrigin<'tcx> {
        .               /// Arose from a subtyping relation
    1,614 ( 0.00%)      Subtype(Box<TypeTrace<'tcx>>),
        .           
        .               /// When casting `&'a T` to an `&'b Trait` object,
        .               /// relating `'a` to `'b`
        .               RelateObjectBound(Span),
        .           
        .               /// Some type parameter was instantiated with the given type,
        .               /// and that type must outlive some region.
       48 ( 0.00%)      RelateParamBound(Span, Ty<'tcx>, Option<Span>),
        .           
        .               /// The given region parameter was instantiated with a region
        .               /// that must outlive some other region.
        .               RelateRegionParamBound(Span),
        .           
        .               /// Creating a pointer `b` to contents of another reference
        .               Reborrow(Span),
        .           
        .               /// Creating a pointer `b` to contents of an upvar
        .               ReborrowUpvar(Span, ty::UpvarId),
        .           
        .               /// Data with type `Ty<'tcx>` was borrowed
       76 ( 0.00%)      DataBorrowed(Ty<'tcx>, Span),
        .           
        .               /// (&'a &'b T) where a >= b
       54 ( 0.00%)      ReferenceOutlivesReferent(Ty<'tcx>, Span),
        .           
        .               /// Comparing the signature and requirements of an impl method against
        .               /// the containing trait.
        .               CompareImplMethodObligation { span: Span, impl_item_def_id: DefId, trait_item_def_id: DefId },
        .           
        .               /// Comparing the signature and requirements of an impl associated type
        .               /// against the containing trait
        .               CompareImplTypeObligation { span: Span, impl_item_def_id: DefId, trait_item_def_id: DefId },
-- line 426 ----------------------------------------
-- line 554 ----------------------------------------
        .               defining_use_anchor: Option<LocalDefId>,
        .           }
        .           
        .           pub trait TyCtxtInferExt<'tcx> {
        .               fn infer_ctxt(self) -> InferCtxtBuilder<'tcx>;
        .           }
        .           
        .           impl<'tcx> TyCtxtInferExt<'tcx> for TyCtxt<'tcx> {
    7,605 ( 0.00%)      fn infer_ctxt(self) -> InferCtxtBuilder<'tcx> {
   22,815 ( 0.00%)          InferCtxtBuilder { tcx: self, defining_use_anchor: None, fresh_typeck_results: None }
    7,605 ( 0.00%)      }
        .           }
        .           
        .           impl<'tcx> InferCtxtBuilder<'tcx> {
        .               /// Used only by `rustc_typeck` during body type-checking/inference,
        .               /// will initialize `in_progress_typeck_results` with fresh `TypeckResults`.
        .               /// Will also change the scope for opaque type defining use checks to the given owner.
    5,364 ( 0.00%)      pub fn with_fresh_in_progress_typeck_results(mut self, table_owner: LocalDefId) -> Self {
    6,556 ( 0.00%)          self.fresh_typeck_results = Some(RefCell::new(ty::TypeckResults::new(table_owner)));
    2,980 ( 0.00%)          self.with_opaque_type_inference(table_owner)
    4,172 ( 0.00%)      }
        .           
        .               /// Whenever the `InferCtxt` should be able to handle defining uses of opaque types,
        .               /// you need to call this function. Otherwise the opaque type will be treated opaquely.
        .               ///
        .               /// It is only meant to be called in two places, for typeck
        .               /// (via `with_fresh_in_progress_typeck_results`) and for the inference context used
        .               /// in mir borrowck.
      700 ( 0.00%)      pub fn with_opaque_type_inference(mut self, defining_use_anchor: LocalDefId) -> Self {
      350 ( 0.00%)          self.defining_use_anchor = Some(defining_use_anchor);
    1,892 ( 0.00%)          self
    1,050 ( 0.00%)      }
        .           
        .               /// Given a canonical value `C` as a starting point, create an
        .               /// inference context that contains each of the bound values
        .               /// within instantiated as a fresh variable. The `f` closure is
        .               /// invoked with the new infcx, along with the instantiated value
        .               /// `V` and a substitution `S`. This substitution `S` maps from
        .               /// the bound values in `C` to their instantiated values in `V`
        .               /// (in other words, `S(C) = V`).
    6,950 ( 0.00%)      pub fn enter_with_canonical<T, R>(
        .                   &mut self,
        .                   span: Span,
        .                   canonical: &Canonical<'tcx, T>,
        .                   f: impl for<'a> FnOnce(InferCtxt<'a, 'tcx>, T, CanonicalVarValues<'tcx>) -> R,
        .               ) -> R
        .               where
        .                   T: TypeFoldable<'tcx>,
        .               {
        .                   self.enter(|infcx| {
    8,250 ( 0.00%)              let (value, subst) =
      327 ( 0.00%)                  infcx.instantiate_canonical_with_fresh_inference_vars(span, canonical);
   12,576 ( 0.00%)              f(infcx, value, subst)
        .                   })
    7,607 ( 0.00%)      }
        .           
   52,914 ( 0.00%)      pub fn enter<R>(&mut self, f: impl for<'a> FnOnce(InferCtxt<'a, 'tcx>) -> R) -> R {
   20,401 ( 0.00%)          let InferCtxtBuilder { tcx, defining_use_anchor, ref fresh_typeck_results } = *self;
        .                   let in_progress_typeck_results = fresh_typeck_results.as_ref();
  337,737 ( 0.01%)          f(InferCtxt {
        .                       tcx,
        .                       defining_use_anchor,
        .                       in_progress_typeck_results,
    7,605 ( 0.00%)              inner: RefCell::new(InferCtxtInner::new()),
        .                       lexical_region_resolutions: RefCell::new(None),
        .                       selection_cache: Default::default(),
        .                       evaluation_cache: Default::default(),
        .                       reported_trait_errors: Default::default(),
        .                       reported_closure_mismatch: Default::default(),
        .                       tainted_by_errors_flag: Cell::new(false),
    7,605 ( 0.00%)              err_count_on_creation: tcx.sess.err_count(),
        .                       in_snapshot: Cell::new(false),
        .                       skip_leak_check: Cell::new(false),
        .                       universe: Cell::new(ty::UniverseIndex::ROOT),
        .                   })
   57,103 ( 0.00%)      }
        .           }
        .           
        .           impl<'tcx, T> InferOk<'tcx, T> {
        .               pub fn unit(self) -> InferOk<'tcx, ()> {
        .                   InferOk { value: (), obligations: self.obligations }
        .               }
        .           
        .               /// Extracts `value`, registering any obligations into `fulfill_cx`.
        .               pub fn into_value_registering_obligations(
        .                   self,
        .                   infcx: &InferCtxt<'_, 'tcx>,
        .                   fulfill_cx: &mut dyn TraitEngine<'tcx>,
        .               ) -> T {
       64 ( 0.00%)          let InferOk { value, obligations } = self;
      270 ( 0.00%)          for obligation in obligations {
        .                       fulfill_cx.register_predicate_obligation(infcx, obligation);
        .                   }
        .                   value
        .               }
        .           }
        .           
        .           impl<'tcx> InferOk<'tcx, ()> {
    4,046 ( 0.00%)      pub fn into_obligations(self) -> PredicateObligations<'tcx> {
   16,184 ( 0.00%)          self.obligations
    4,046 ( 0.00%)      }
        .           }
        .           
        .           #[must_use = "once you start a snapshot, you should always consume it"]
        .           pub struct CombinedSnapshot<'a, 'tcx> {
        .               undo_snapshot: Snapshot<'tcx>,
        .               region_constraints_snapshot: RegionSnapshot,
        .               universe: ty::UniverseIndex,
        .               was_in_snapshot: bool,
-- line 662 ----------------------------------------
-- line 674 ----------------------------------------
        .                   let canonical = self.canonicalize_query((a, b), &mut OriginalQueryValues::default());
        .                   debug!("canonical consts: {:?}", &canonical.value);
        .           
        .                   self.tcx.try_unify_abstract_consts(canonical.value)
        .               }
        .           
        .               pub fn is_in_snapshot(&self) -> bool {
        .                   self.in_snapshot.get()
   24,152 ( 0.00%)      }
        .           
  168,480 ( 0.00%)      pub fn freshen<T: TypeFoldable<'tcx>>(&self, t: T) -> T {
  189,540 ( 0.00%)          t.fold_with(&mut self.freshener())
  189,540 ( 0.00%)      }
        .           
        .               /// Returns the origin of the type variable identified by `vid`, or `None`
        .               /// if this is not a type variable.
        .               ///
        .               /// No attempt is made to resolve `ty`.
    2,378 ( 0.00%)      pub fn type_var_origin(&'a self, ty: Ty<'tcx>) -> Option<TypeVariableOrigin> {
    4,756 ( 0.00%)          match *ty.kind() {
    1,133 ( 0.00%)              ty::Infer(ty::TyVar(vid)) => {
    4,532 ( 0.00%)                  Some(*self.inner.borrow_mut().type_variables().var_origin(vid))
        .                       }
       56 ( 0.00%)              _ => None,
        .                   }
    4,756 ( 0.00%)      }
        .           
   21,060 ( 0.00%)      pub fn freshener<'b>(&'b self) -> TypeFreshener<'b, 'tcx> {
        .                   freshen::TypeFreshener::new(self, false)
   21,060 ( 0.00%)      }
        .           
        .               /// Like `freshener`, but does not replace `'static` regions.
   62,237 ( 0.00%)      pub fn freshener_keep_static<'b>(&'b self) -> TypeFreshener<'b, 'tcx> {
        .                   freshen::TypeFreshener::new(self, true)
   62,237 ( 0.00%)      }
        .           
    1,628 ( 0.00%)      pub fn unsolved_variables(&self) -> Vec<Ty<'tcx>> {
      814 ( 0.00%)          let mut inner = self.inner.borrow_mut();
      814 ( 0.00%)          let mut vars: Vec<Ty<'_>> = inner
        .                       .type_variables()
        .                       .unsolved_variables()
        .                       .into_iter()
    2,266 ( 0.00%)              .map(|t| self.tcx.mk_ty_var(t))
        .                       .collect();
        .                   vars.extend(
        .                       (0..inner.int_unification_table().len())
        .                           .map(|i| ty::IntVid { index: i as u32 })
    3,554 ( 0.00%)                  .filter(|&vid| inner.int_unification_table().probe_value(vid).is_none())
       56 ( 0.00%)                  .map(|v| self.tcx.mk_int_var(v)),
        .                   );
        .                   vars.extend(
        .                       (0..inner.float_unification_table().len())
        .                           .map(|i| ty::FloatVid { index: i as u32 })
        .                           .filter(|&vid| inner.float_unification_table().probe_value(vid).is_none())
        .                           .map(|v| self.tcx.mk_float_var(v)),
        .                   );
        .                   vars
    2,849 ( 0.00%)      }
        .           
   32,141 ( 0.00%)      fn combine_fields(
        .                   &'a self,
        .                   trace: TypeTrace<'tcx>,
        .                   param_env: ty::ParamEnv<'tcx>,
        .               ) -> CombineFields<'a, 'tcx> {
  128,568 ( 0.00%)          CombineFields {
        .                       infcx: self,
  321,420 ( 0.01%)              trace,
        .                       cause: None,
        .                       param_env,
        .                       obligations: PredicateObligations::new(),
        .                   }
   32,141 ( 0.00%)      }
        .           
        .               /// Clear the "currently in a snapshot" flag, invoke the closure,
        .               /// then restore the flag to its original value. This flag is a
        .               /// debugging measure designed to detect cases where we start a
        .               /// snapshot, create type variables, and register obligations
        .               /// which may involve those type variables in the fulfillment cx,
        .               /// potentially leaving "dangling type variables" behind.
        .               /// In such cases, an assertion will fail when attempting to
-- line 753 ----------------------------------------
-- line 755 ----------------------------------------
        .               /// better than grovelling through megabytes of `RUSTC_LOG` output.
        .               ///
        .               /// HOWEVER, in some cases the flag is unhelpful. In particular, we
        .               /// sometimes create a "mini-fulfilment-cx" in which we enroll
        .               /// obligations. As long as this fulfillment cx is fully drained
        .               /// before we return, this is not a problem, as there won't be any
        .               /// escaping obligations in the main cx. In those cases, you can
        .               /// use this function.
       48 ( 0.00%)      pub fn save_and_restore_in_snapshot_flag<F, R>(&self, func: F) -> R
        .               where
        .                   F: FnOnce(&Self) -> R,
        .               {
        .                   let flag = self.in_snapshot.replace(false);
    4,884 ( 0.00%)          let result = func(self);
        .                   self.in_snapshot.set(flag);
        .                   result
       54 ( 0.00%)      }
        .           
  165,024 ( 0.00%)      fn start_snapshot(&self) -> CombinedSnapshot<'a, 'tcx> {
        .                   debug!("start_snapshot()");
        .           
        .                   let in_snapshot = self.in_snapshot.replace(true);
        .           
        .                   let mut inner = self.inner.borrow_mut();
        .           
  495,072 ( 0.01%)          CombinedSnapshot {
        .                       undo_snapshot: inner.undo_log.start_snapshot(),
        .                       region_constraints_snapshot: inner.unwrap_region_constraints().start_snapshot(),
        .                       universe: self.universe(),
        .                       was_in_snapshot: in_snapshot,
        .                       // Borrow typeck results "in progress" (i.e., during typeck)
        .                       // to ban writes from within a snapshot to them.
   82,512 ( 0.00%)              _in_progress_typeck_results: self
        .                           .in_progress_typeck_results
        .                           .map(|typeck_results| typeck_results.borrow()),
        .                   }
  330,048 ( 0.01%)      }
        .           
  273,823 ( 0.00%)      #[instrument(skip(self, snapshot), level = "debug")]
        .               fn rollback_to(&self, cause: &str, snapshot: CombinedSnapshot<'a, 'tcx>) {
        .                   let CombinedSnapshot {
   24,893 ( 0.00%)              undo_snapshot,
   24,893 ( 0.00%)              region_constraints_snapshot,
   24,893 ( 0.00%)              universe,
   24,893 ( 0.00%)              was_in_snapshot,
   49,786 ( 0.00%)              _in_progress_typeck_results,
        .                   } = snapshot;
        .           
        .                   self.in_snapshot.set(was_in_snapshot);
        .                   self.universe.set(universe);
        .           
        .                   let mut inner = self.inner.borrow_mut();
   24,893 ( 0.00%)          inner.rollback_to(undo_snapshot);
        .                   inner.unwrap_region_constraints().rollback_to(region_constraints_snapshot);
        .               }
        .           
  864,285 ( 0.01%)      #[instrument(skip(self, snapshot), level = "debug")]
        .               fn commit_from(&self, snapshot: CombinedSnapshot<'a, 'tcx>) {
        .                   let CombinedSnapshot {
   57,619 ( 0.00%)              undo_snapshot,
        .                       region_constraints_snapshot: _,
        .                       universe: _,
   57,619 ( 0.00%)              was_in_snapshot,
  115,238 ( 0.00%)              _in_progress_typeck_results,
        .                   } = snapshot;
        .           
        .                   self.in_snapshot.set(was_in_snapshot);
        .           
        .                   self.inner.borrow_mut().commit(undo_snapshot);
        .               }
        .           
        .               /// Executes `f` and commit the bindings.
   64,024 ( 0.00%)      #[instrument(skip(self, f), level = "debug")]
   78,507 ( 0.00%)      pub fn commit_unconditionally<R, F>(&self, f: F) -> R
        .               where
        .                   F: FnOnce(&CombinedSnapshot<'a, 'tcx>) -> R,
        .               {
    7,137 ( 0.00%)          let snapshot = self.start_snapshot();
   22,636 ( 0.00%)          let r = f(&snapshot);
   49,959 ( 0.00%)          self.commit_from(snapshot);
   42,443 ( 0.00%)          r
        .               }
        .           
        .               /// Execute `f` and commit the bindings if closure `f` returns `Ok(_)`.
  383,502 ( 0.01%)      #[instrument(skip(self, f), level = "debug")]
  473,953 ( 0.01%)      pub fn commit_if_ok<T, E, F>(&self, f: F) -> Result<T, E>
        .               where
        .                   F: FnOnce(&CombinedSnapshot<'a, 'tcx>) -> Result<T, E>,
        .               {
   74,365 ( 0.00%)          let snapshot = self.start_snapshot();
  219,050 ( 0.00%)          let r = f(&snapshot);
        .                   debug!("commit_if_ok() -- r.is_ok() = {}", r.is_ok());
   81,094 ( 0.00%)          match r {
        .                       Ok(_) => {
  358,851 ( 0.01%)                  self.commit_from(snapshot);
        .                       }
        .                       Err(_) => {
  135,184 ( 0.00%)                  self.rollback_to("commit_if_ok -- error", snapshot);
        .                       }
        .                   }
  412,672 ( 0.01%)          r
        .               }
        .           
        .               /// Execute `f` then unroll any bindings it creates.
   73,974 ( 0.00%)      #[instrument(skip(self, f), level = "debug")]
   89,205 ( 0.00%)      pub fn probe<R, F>(&self, f: F) -> R
        .               where
        .                   F: FnOnce(&CombinedSnapshot<'a, 'tcx>) -> R,
        .               {
   22,359 ( 0.00%)          let snapshot = self.start_snapshot();
   35,548 ( 0.00%)          let r = f(&snapshot);
  102,264 ( 0.00%)          self.rollback_to("probe", snapshot);
   13,935 ( 0.00%)          r
        .               }
        .           
        .               /// If `should_skip` is true, then execute `f` then unroll any bindings it creates.
        .               #[instrument(skip(self, f), level = "debug")]
        .               pub fn probe_maybe_skip_leak_check<R, F>(&self, should_skip: bool, f: F) -> R
        .               where
        .                   F: FnOnce(&CombinedSnapshot<'a, 'tcx>) -> R,
        .               {
-- line 875 ----------------------------------------
-- line 884 ----------------------------------------
        .                   r
        .               }
        .           
        .               /// Scan the constraints produced since `snapshot` began and returns:
        .               ///
        .               /// - `None` -- if none of them involve "region outlives" constraints
        .               /// - `Some(true)` -- if there are `'a: 'b` constraints where `'a` or `'b` is a placeholder
        .               /// - `Some(false)` -- if there are `'a: 'b` constraints but none involve placeholders
    4,550 ( 0.00%)      pub fn region_constraints_added_in_snapshot(
        .                   &self,
        .                   snapshot: &CombinedSnapshot<'a, 'tcx>,
        .               ) -> Option<bool> {
    9,100 ( 0.00%)          self.inner
        .                       .borrow_mut()
        .                       .unwrap_region_constraints()
        .                       .region_constraints_added_in_snapshot(&snapshot.undo_snapshot)
    6,825 ( 0.00%)      }
        .           
        .               pub fn add_given(&self, sub: ty::Region<'tcx>, sup: ty::RegionVid) {
        .                   self.inner.borrow_mut().unwrap_region_constraints().add_given(sub, sup);
        .               }
        .           
      360 ( 0.00%)      pub fn can_sub<T>(&self, param_env: ty::ParamEnv<'tcx>, a: T, b: T) -> UnitResult<'tcx>
        .               where
        .                   T: at::ToTrace<'tcx>,
        .               {
        .                   let origin = &ObligationCause::dummy();
        .                   self.probe(|_| {
        .                       self.at(origin, param_env).sub(a, b).map(|InferOk { obligations: _, .. }| {
        .                           // Ignore obligations, since we are unrolling
        .                           // everything anyway.
        .                       })
        .                   })
      270 ( 0.00%)      }
        .           
    1,512 ( 0.00%)      pub fn can_eq<T>(&self, param_env: ty::ParamEnv<'tcx>, a: T, b: T) -> UnitResult<'tcx>
        .               where
        .                   T: at::ToTrace<'tcx>,
        .               {
        .                   let origin = &ObligationCause::dummy();
        .                   self.probe(|_| {
        .                       self.at(origin, param_env).eq(a, b).map(|InferOk { obligations: _, .. }| {
        .                           // Ignore obligations, since we are unrolling
        .                           // everything anyway.
        .                       })
        .                   })
    1,134 ( 0.00%)      }
        .           
   19,270 ( 0.00%)      #[instrument(skip(self), level = "debug")]
        .               pub fn sub_regions(
        .                   &self,
        .                   origin: SubregionOrigin<'tcx>,
        .                   a: ty::Region<'tcx>,
        .                   b: ty::Region<'tcx>,
        .               ) {
   17,343 ( 0.00%)          self.inner.borrow_mut().unwrap_region_constraints().make_subregion(origin, a, b);
        .               }
        .           
        .               /// Require that the region `r` be equal to one of the regions in
        .               /// the set `regions`.
        .               #[instrument(skip(self), level = "debug")]
        .               pub fn member_constraint(
        .                   &self,
        .                   opaque_type_def_id: DefId,
-- line 947 ----------------------------------------
-- line 969 ----------------------------------------
        .               /// to `subtype_predicate` -- that is, "coercing" `a` to `b` winds up
        .               /// actually requiring `a <: b`. This is of course a valid coercion,
        .               /// but it's not as flexible as `FnCtxt::coerce` would be.
        .               ///
        .               /// (We may refactor this in the future, but there are a number of
        .               /// practical obstacles. Among other things, `FnCtxt::coerce` presently
        .               /// records adjustments that are required on the HIR in order to perform
        .               /// the coercion, and we don't currently have a way to manage that.)
        3 ( 0.00%)      pub fn coerce_predicate(
        .                   &self,
        .                   cause: &ObligationCause<'tcx>,
        .                   param_env: ty::ParamEnv<'tcx>,
        .                   predicate: ty::PolyCoercePredicate<'tcx>,
        .               ) -> Option<InferResult<'tcx, ()>> {
        2 ( 0.00%)          let subtype_predicate = predicate.map_bound(|p| ty::SubtypePredicate {
        .                       a_is_expected: false, // when coercing from `a` to `b`, `b` is expected
        .                       a: p.a,
        .                       b: p.b,
        .                   });
        5 ( 0.00%)          self.subtype_predicate(cause, param_env, subtype_predicate)
        4 ( 0.00%)      }
        .           
      876 ( 0.00%)      pub fn subtype_predicate(
        .                   &self,
        .                   cause: &ObligationCause<'tcx>,
        .                   param_env: ty::ParamEnv<'tcx>,
        .                   predicate: ty::PolySubtypePredicate<'tcx>,
        .               ) -> Option<InferResult<'tcx, ()>> {
        .                   // Check for two unresolved inference variables, in which case we can
        .                   // make no progress. This is partly a micro-optimization, but it's
        .                   // also an opportunity to "sub-unify" the variables. This isn't
-- line 999 ----------------------------------------
-- line 1002 ----------------------------------------
        .                   // earlier that they are sub-unified).
        .                   //
        .                   // Note that we can just skip the binders here because
        .                   // type variables can't (at present, at
        .                   // least) capture any of the things bound by this binder.
        .                   //
        .                   // Note that this sub here is not just for diagnostics - it has semantic
        .                   // effects as well.
       73 ( 0.00%)          let r_a = self.shallow_resolve(predicate.skip_binder().a);
       73 ( 0.00%)          let r_b = self.shallow_resolve(predicate.skip_binder().b);
      580 ( 0.00%)          match (r_a.kind(), r_b.kind()) {
      144 ( 0.00%)              (&ty::Infer(ty::TyVar(a_vid)), &ty::Infer(ty::TyVar(b_vid))) => {
        .                           self.inner.borrow_mut().type_variables().sub(a_vid, b_vid);
      144 ( 0.00%)                  return None;
        .                       }
        .                       _ => {}
        .                   }
        .           
        .                   Some(self.commit_if_ok(|_snapshot| {
        1 ( 0.00%)              let ty::SubtypePredicate { a_is_expected, a, b } =
        .                           self.replace_bound_vars_with_placeholders(predicate);
        .           
        2 ( 0.00%)              let ok = self.at(cause, param_env).sub_exp(a_is_expected, a, b)?;
        .           
        .                       Ok(ok.unit())
        .                   }))
      657 ( 0.00%)      }
        .           
    1,848 ( 0.00%)      pub fn region_outlives_predicate(
        .                   &self,
        .                   cause: &traits::ObligationCause<'tcx>,
        .                   predicate: ty::PolyRegionOutlivesPredicate<'tcx>,
        .               ) -> UnitResult<'tcx> {
        .                   self.commit_if_ok(|_snapshot| {
        .                       let ty::OutlivesPredicate(r_a, r_b) =
        .                           self.replace_bound_vars_with_placeholders(predicate);
        .                       let origin = SubregionOrigin::from_obligation_cause(cause, || {
        .                           RelateRegionParamBound(cause.span)
        .                       });
    1,540 ( 0.00%)              self.sub_regions(origin, r_b, r_a); // `b : a` ==> `a <= b`
        .                       Ok(())
        .                   })
    1,232 ( 0.00%)      }
        .           
        .               /// Number of type variables created so far.
       57 ( 0.00%)      pub fn num_ty_vars(&self) -> usize {
        .                   self.inner.borrow_mut().type_variables().num_vars()
      114 ( 0.00%)      }
        .           
   21,152 ( 0.00%)      pub fn next_ty_var_id(&self, origin: TypeVariableOrigin) -> TyVid {
  105,760 ( 0.00%)          self.inner.borrow_mut().type_variables().new_var(self.universe(), origin)
   31,728 ( 0.00%)      }
        .           
   18,102 ( 0.00%)      pub fn next_ty_var(&self, origin: TypeVariableOrigin) -> Ty<'tcx> {
   72,507 ( 0.00%)          self.tcx.mk_ty_var(self.next_ty_var_id(origin))
   27,153 ( 0.00%)      }
        .           
      232 ( 0.00%)      pub fn next_ty_var_in_universe(
        .                   &self,
        .                   origin: TypeVariableOrigin,
        .                   universe: ty::UniverseIndex,
        .               ) -> Ty<'tcx> {
    1,276 ( 0.00%)          let vid = self.inner.borrow_mut().type_variables().new_var(universe, origin);
      116 ( 0.00%)          self.tcx.mk_ty_var(vid)
      348 ( 0.00%)      }
        .           
        .               pub fn next_const_var(
        .                   &self,
        .                   ty: Ty<'tcx>,
        .                   origin: ConstVariableOrigin,
        .               ) -> &'tcx ty::Const<'tcx> {
        .                   self.tcx.mk_const_var(self.next_const_var_id(origin), ty)
        .               }
-- line 1074 ----------------------------------------
-- line 1090 ----------------------------------------
        .               pub fn next_const_var_id(&self, origin: ConstVariableOrigin) -> ConstVid<'tcx> {
        .                   self.inner.borrow_mut().const_unification_table().new_key(ConstVarValue {
        .                       origin,
        .                       val: ConstVariableValue::Unknown { universe: self.universe() },
        .                   })
        .               }
        .           
        .               fn next_int_var_id(&self) -> IntVid {
    4,695 ( 0.00%)          self.inner.borrow_mut().int_unification_table().new_key(None)
        .               }
        .           
    2,817 ( 0.00%)      pub fn next_int_var(&self) -> Ty<'tcx> {
        .                   self.tcx.mk_int_var(self.next_int_var_id())
    3,756 ( 0.00%)      }
        .           
        .               fn next_float_var_id(&self) -> FloatVid {
        .                   self.inner.borrow_mut().float_unification_table().new_key(None)
        .               }
        .           
        .               pub fn next_float_var(&self) -> Ty<'tcx> {
        .                   self.tcx.mk_float_var(self.next_float_var_id())
        .               }
        .           
        .               /// Creates a fresh region variable with the next available index.
        .               /// The variable will be created in the maximum universe created
        .               /// thus far, allowing it to name any region created thus far.
    4,970 ( 0.00%)      pub fn next_region_var(&self, origin: RegionVariableOrigin) -> ty::Region<'tcx> {
   92,820 ( 0.00%)          self.next_region_var_in_universe(origin, self.universe())
    9,940 ( 0.00%)      }
        .           
        .               /// Creates a fresh region variable with the next available index
        .               /// in the given universe; typically, you can use
        .               /// `next_region_var` and just use the maximal universe.
   33,200 ( 0.00%)      pub fn next_region_var_in_universe(
        .                   &self,
        .                   origin: RegionVariableOrigin,
        .                   universe: ty::UniverseIndex,
        .               ) -> ty::Region<'tcx> {
        .                   let region_var =
  215,800 ( 0.00%)              self.inner.borrow_mut().unwrap_region_constraints().new_region_var(universe, origin);
   83,000 ( 0.00%)          self.tcx.mk_region(ty::ReVar(region_var))
   49,800 ( 0.00%)      }
        .           
        .               /// Return the universe that the region `r` was created in.  For
        .               /// most regions (e.g., `'static`, named regions from the user,
        .               /// etc) this is the root universe U0. For inference variables or
        .               /// placeholders, however, it will return the universe which which
        .               /// they are associated.
    2,026 ( 0.00%)      pub fn universe_of_region(&self, r: ty::Region<'tcx>) -> ty::UniverseIndex {
        .                   self.inner.borrow_mut().unwrap_region_constraints().universe(r)
    3,039 ( 0.00%)      }
        .           
        .               /// Number of region variables created so far.
    2,800 ( 0.00%)      pub fn num_region_vars(&self) -> usize {
        .                   self.inner.borrow_mut().unwrap_region_constraints().num_region_vars()
    4,200 ( 0.00%)      }
        .           
        .               /// Just a convenient wrapper of `next_region_var` for using during NLL.
    5,690 ( 0.00%)      pub fn next_nll_region_var(&self, origin: NllRegionVariableOrigin) -> ty::Region<'tcx> {
        .                   self.next_region_var(RegionVariableOrigin::Nll(origin))
   11,380 ( 0.00%)      }
        .           
        .               /// Just a convenient wrapper of `next_region_var` for using during NLL.
        .               pub fn next_nll_region_var_in_universe(
        .                   &self,
        .                   origin: NllRegionVariableOrigin,
        .                   universe: ty::UniverseIndex,
        .               ) -> ty::Region<'tcx> {
        .                   self.next_region_var_in_universe(RegionVariableOrigin::Nll(origin), universe)
        .               }
        .           
  167,664 ( 0.00%)      pub fn var_for_def(&self, span: Span, param: &ty::GenericParamDef) -> GenericArg<'tcx> {
   95,234 ( 0.00%)          match param.kind {
        .                       GenericParamDefKind::Lifetime => {
        .                           // Create a region inference variable for the given
        .                           // region parameter definition.
    4,778 ( 0.00%)                  self.next_region_var(EarlyBoundRegion(span, param.name)).into()
        .                       }
        .                       GenericParamDefKind::Type { .. } => {
        .                           // Create a type inference variable for the given
        .                           // type parameter definition. The substitutions are
        .                           // for actual parameters that may be referred to by
        .                           // the default of this type parameter, if it exists.
        .                           // e.g., `struct Foo<A, B, C = (A, B)>(...);` when
        .                           // used in a path such as `Foo::<T, U>::new()` will
        .                           // use an inference variable for `C` with `[T, U]`
        .                           // as the substitutions for the default, `(T, U)`.
   58,344 ( 0.00%)                  let ty_var_id = self.inner.borrow_mut().type_variables().new_var(
        .                               self.universe(),
   72,930 ( 0.00%)                      TypeVariableOrigin {
        .                                   kind: TypeVariableOriginKind::TypeParameterDefinition(
   14,586 ( 0.00%)                              param.name,
   14,586 ( 0.00%)                              Some(param.def_id),
        .                                   ),
        .                                   span,
        .                               },
        .                           );
        .           
   14,586 ( 0.00%)                  self.tcx.mk_ty_var(ty_var_id).into()
        .                       }
        .                       GenericParamDefKind::Const { .. } => {
        .                           let origin = ConstVariableOrigin {
        .                               kind: ConstVariableOriginKind::ConstParameterDefinition(
        .                                   param.name,
        .                                   param.def_id,
        .                               ),
        .                               span,
        .                           };
        .                           let const_var_id =
   17,534 ( 0.00%)                      self.inner.borrow_mut().const_unification_table().new_key(ConstVarValue {
        .                                   origin,
        .                                   val: ConstVariableValue::Unknown { universe: self.universe() },
        .                               });
    1,594 ( 0.00%)                  self.tcx.mk_const_var(const_var_id, self.tcx.type_of(param.def_id)).into()
        .                       }
        .                   }
   12,752 ( 0.00%)      }
        .           
        .               /// Given a set of generics defined on a type or impl, returns a substitution mapping each
        .               /// type/region parameter to a fresh inference variable.
   40,278 ( 0.00%)      pub fn fresh_substs_for_item(&self, span: Span, def_id: DefId) -> SubstsRef<'tcx> {
  184,676 ( 0.00%)          InternalSubsts::for_item(self.tcx, def_id, |param, _| self.var_for_def(span, param))
   26,852 ( 0.00%)      }
        .           
        .               /// Returns `true` if errors have been reported since this infcx was
        .               /// created. This is sometimes used as a heuristic to skip
        .               /// reporting errors that often occur as a result of earlier
        .               /// errors, but where it's hard to be 100% sure (e.g., unresolved
        .               /// inference variables, regionck errors).
    3,078 ( 0.00%)      pub fn is_tainted_by_errors(&self) -> bool {
        .                   debug!(
        .                       "is_tainted_by_errors(err_count={}, err_count_on_creation={}, \
        .                        tainted_by_errors_flag={})",
        .                       self.tcx.sess.err_count(),
        .                       self.err_count_on_creation,
        .                       self.tainted_by_errors_flag.get()
        .                   );
        .           
   31,629 ( 0.00%)          if self.tcx.sess.err_count() > self.err_count_on_creation {
        .                       return true; // errors reported since this infcx was made
        .                   }
        .                   self.tainted_by_errors_flag.get()
    4,617 ( 0.00%)      }
        .           
        .               /// Set the "tainted by errors" flag to true. We call this when we
        .               /// observe an error from a prior pass.
        .               pub fn set_tainted_by_errors(&self) {
        .                   debug!("set_tainted_by_errors()");
        .                   self.tainted_by_errors_flag.set(true)
        .               }
        .           
        .               /// Process the region constraints and return any any errors that
        .               /// result. After this, no more unification operations should be
        .               /// done -- or the compiler will panic -- but it is legal to use
        .               /// `resolve_vars_if_possible` as well as `fully_resolve`.
   24,332 ( 0.00%)      pub fn resolve_regions(
        .                   &self,
        .                   region_context: DefId,
        .                   outlives_env: &OutlivesEnvironment<'tcx>,
        .                   mode: RegionckMode,
        .               ) -> Vec<RegionResolutionError<'tcx>> {
   66,044 ( 0.00%)          let (var_infos, data) = {
        .                       let mut inner = self.inner.borrow_mut();
        .                       let inner = &mut *inner;
    3,476 ( 0.00%)              assert!(
   10,428 ( 0.00%)                  self.is_tainted_by_errors() || inner.region_obligations.is_empty(),
        .                           "region_obligations not empty: {:#?}",
        .                           inner.region_obligations
        .                       );
        .                       inner
        .                           .region_constraint_storage
        .                           .take()
        .                           .expect("regions already resolved")
        .                           .with_log(&mut inner.undo_log)
        .                           .into_infos_and_data()
    3,476 ( 0.00%)          };
        .           
        .                   let region_rels =
    3,476 ( 0.00%)              &RegionRelations::new(self.tcx, region_context, outlives_env.free_region_map());
        .           
   31,284 ( 0.00%)          let (lexical_region_resolutions, errors) =
   83,424 ( 0.00%)              lexical_region_resolve::resolve(region_rels, var_infos, data, mode);
        .           
   13,904 ( 0.00%)          let old_value = self.lexical_region_resolutions.replace(Some(lexical_region_resolutions));
    3,476 ( 0.00%)          assert!(old_value.is_none());
        .           
        .                   errors
   31,284 ( 0.00%)      }
        .           
        .               /// Process the region constraints and report any errors that
        .               /// result. After this, no more unification operations should be
        .               /// done -- or the compiler will panic -- but it is legal to use
        .               /// `resolve_vars_if_possible` as well as `fully_resolve`.
   34,760 ( 0.00%)      pub fn resolve_regions_and_report_errors(
        .                   &self,
        .                   region_context: DefId,
        .                   outlives_env: &OutlivesEnvironment<'tcx>,
        .                   mode: RegionckMode,
        .               ) {
    6,952 ( 0.00%)          let errors = self.resolve_regions(region_context, outlives_env, mode);
        .           
   10,428 ( 0.00%)          if !self.is_tainted_by_errors() {
        .                       // As a heuristic, just skip reporting region errors
        .                       // altogether if other errors have been reported while
        .                       // this infcx was in use.  This is totally hokey but
        .                       // otherwise we have a hard time separating legit region
        .                       // errors from silly ones.
    6,952 ( 0.00%)              self.report_region_errors(&errors);
        .                   }
   17,380 ( 0.00%)      }
        .           
        .               /// Obtains (and clears) the current set of region
        .               /// constraints. The inference context is still usable: further
        .               /// unifications will simply add new constraints.
        .               ///
        .               /// This method is not meant to be used with normal lexical region
        .               /// resolution. Rather, it is used in the NLL mode as a kind of
        .               /// interim hack: basically we run normal type-check and generate
-- line 1307 ----------------------------------------
-- line 1319 ----------------------------------------
        .               }
        .           
        .               /// Gives temporary access to the region constraint data.
        .               pub fn with_region_constraints<R>(
        .                   &self,
        .                   op: impl FnOnce(&RegionConstraintData<'tcx>) -> R,
        .               ) -> R {
        .                   let mut inner = self.inner.borrow_mut();
    2,124 ( 0.00%)          op(inner.unwrap_region_constraints().data())
        .               }
        .           
        .               pub fn region_var_origin(&self, vid: ty::RegionVid) -> RegionVariableOrigin {
        .                   let mut inner = self.inner.borrow_mut();
        .                   let inner = &mut *inner;
        .                   inner
        .                       .region_constraint_storage
        .                       .as_mut()
-- line 1335 ----------------------------------------
-- line 1338 ----------------------------------------
        .                       .var_origin(vid)
        .               }
        .           
        .               /// Takes ownership of the list of variable regions. This implies
        .               /// that all the region constraints have already been taken, and
        .               /// hence that `resolve_regions_and_report_errors` can never be
        .               /// called. This is used only during NLL processing to "hand off" ownership
        .               /// of the set of region variables into the NLL region context.
    1,750 ( 0.00%)      pub fn take_region_var_origins(&self) -> VarInfos {
        .                   let mut inner = self.inner.borrow_mut();
    6,650 ( 0.00%)          let (var_infos, data) = inner
        .                       .region_constraint_storage
        .                       .take()
        .                       .expect("regions already resolved")
        .                       .with_log(&mut inner.undo_log)
      350 ( 0.00%)              .into_infos_and_data();
      350 ( 0.00%)          assert!(data.is_empty());
        .                   var_infos
    2,800 ( 0.00%)      }
        .           
        .               pub fn ty_to_string(&self, t: Ty<'tcx>) -> String {
        .                   self.resolve_vars_if_possible(t).to_string()
        .               }
        .           
        .               /// If `TyVar(vid)` resolves to a type, return that type. Else, return the
        .               /// universe index of `TyVar(vid)`.
    5,766 ( 0.00%)      pub fn probe_ty_var(&self, vid: TyVid) -> Result<Ty<'tcx>, ty::UniverseIndex> {
        .                   use self::type_variable::TypeVariableValue;
        .           
   17,298 ( 0.00%)          match self.inner.borrow_mut().type_variables().probe(vid) {
        .                       TypeVariableValue::Known { value } => Ok(value),
        .                       TypeVariableValue::Unknown { universe } => Err(universe),
        .                   }
   20,181 ( 0.00%)      }
        .           
        .               /// Resolve any type variables found in `value` -- but only one
        .               /// level.  So, if the variable `?X` is bound to some type
        .               /// `Foo<?Y>`, then this would return `Foo<?Y>` (but `?Y` may
        .               /// itself be bound to a type).
        .               ///
        .               /// Useful when you only need to inspect the outermost level of
        .               /// the type and don't care about nested types (or perhaps you
        .               /// will be resolving them as well, e.g. in a loop).
        .               pub fn shallow_resolve<T>(&self, value: T) -> T
        .               where
        .                   T: TypeFoldable<'tcx>,
        .               {
  160,521 ( 0.00%)          value.fold_with(&mut ShallowResolver { infcx: self })
        .               }
        .           
   13,196 ( 0.00%)      pub fn root_var(&self, var: ty::TyVid) -> ty::TyVid {
        .                   self.inner.borrow_mut().type_variables().root_var(var)
   19,794 ( 0.00%)      }
        .           
        .               /// Where possible, replaces type/const variables in
        .               /// `value` with their final value. Note that region variables
        .               /// are unaffected. If a type/const variable has not been unified, it
        .               /// is left as is. This is an idempotent operation that does
        .               /// not affect inference state in any way and so you can do it
        .               /// at will.
    4,604 ( 0.00%)      pub fn resolve_vars_if_possible<T>(&self, value: T) -> T
        .               where
        .                   T: TypeFoldable<'tcx>,
        .               {
  198,998 ( 0.00%)          if !value.needs_infer() {
  131,836 ( 0.00%)              return value; // Avoid duplicated subst-folding.
        .                   }
  197,270 ( 0.00%)          let mut r = resolve::OpportunisticVarResolver::new(self);
  197,934 ( 0.00%)          value.fold_with(&mut r)
    5,755 ( 0.00%)      }
        .           
        .               /// Returns the first unresolved variable contained in `T`. In the
        .               /// process of visiting `T`, this will resolve (where possible)
        .               /// type variables in `T`, but it never constructs the final,
        .               /// resolved type, so it's more efficient than
        .               /// `resolve_vars_if_possible()`.
        .               pub fn unresolved_type_vars<T>(&self, value: &T) -> Option<(Ty<'tcx>, Option<Span>)>
        .               where
-- line 1415 ----------------------------------------
-- line 1490 ----------------------------------------
        .                   expected: &'tcx ty::Const<'tcx>,
        .                   actual: &'tcx ty::Const<'tcx>,
        .                   err: TypeError<'tcx>,
        .               ) -> DiagnosticBuilder<'tcx> {
        .                   let trace = TypeTrace::consts(cause, true, expected, actual);
        .                   self.report_and_explain_type_error(trace, &err)
        .               }
        .           
   28,206 ( 0.00%)      pub fn replace_bound_vars_with_fresh_vars<T>(
        .                   &self,
        .                   span: Span,
        .                   lbrct: LateBoundRegionConversionTime,
        .                   value: ty::Binder<'tcx, T>,
        .               ) -> (T, BTreeMap<ty::BoundRegion, ty::Region<'tcx>>)
        .               where
        .                   T: TypeFoldable<'tcx>,
        .               {
        .                   let fld_r =
   62,390 ( 0.00%)              |br: ty::BoundRegion| self.next_region_var(LateBoundRegion(span, br.kind, lbrct));
        .                   let fld_t = |_| {
        .                       self.next_ty_var(TypeVariableOrigin {
        .                           kind: TypeVariableOriginKind::MiscVariable,
        .                           span,
        .                       })
        .                   };
        .                   let fld_c = |_, ty| {
        .                       self.next_const_var(
        .                           ty,
        .                           ConstVariableOrigin { kind: ConstVariableOriginKind::MiscVariable, span },
        .                       )
        .                   };
   71,728 ( 0.00%)          self.tcx.replace_bound_vars(value, fld_r, fld_t, fld_c)
   18,804 ( 0.00%)      }
        .           
        .               /// See the [`region_constraints::RegionConstraintCollector::verify_generic_bound`] method.
        .               pub fn verify_generic_bound(
        .                   &self,
        .                   origin: SubregionOrigin<'tcx>,
        .                   kind: GenericKind<'tcx>,
        .                   a: ty::Region<'tcx>,
        .                   bound: VerifyBound<'tcx>,
-- line 1530 ----------------------------------------
-- line 1551 ----------------------------------------
        .               /// its `ParamEnv`, since `FulfillmentContext` doesn't use probing.
        .               pub fn clear_caches(&self) {
        .                   self.selection_cache.clear();
        .                   self.evaluation_cache.clear();
        .                   self.inner.borrow_mut().projection_cache().clear();
        .               }
        .           
        .               pub fn universe(&self) -> ty::UniverseIndex {
  242,748 ( 0.00%)          self.universe.get()
  100,108 ( 0.00%)      }
        .           
        .               /// Creates and return a fresh universe that extends all previous
        .               /// universes. Updates `self.universe` to that new universe.
        .               pub fn create_next_universe(&self) -> ty::UniverseIndex {
        .                   let u = self.universe.get().next_universe();
        .                   self.universe.set(u);
        .                   u
        .               }
-- line 1568 ----------------------------------------
-- line 1574 ----------------------------------------
        .               /// constant has generic parameters in scope the substitutions are used to evaluate the value of
        .               /// the constant. For example in `fn foo<T>() { let _ = [0; bar::<T>()]; }` the repeat count
        .               /// constant `bar::<T>()` requires a substitution for `T`, if the substitution for `T` is still
        .               /// too generic for the constant to be evaluated then `Err(ErrorHandled::TooGeneric)` is
        .               /// returned.
        .               ///
        .               /// This handles inferences variables within both `param_env` and `substs` by
        .               /// performing the operation on their respective canonical forms.
       78 ( 0.00%)      pub fn const_eval_resolve(
        .                   &self,
        .                   param_env: ty::ParamEnv<'tcx>,
        .                   unevaluated: ty::Unevaluated<'tcx>,
        .                   span: Option<Span>,
        .               ) -> EvalToConstValueResult<'tcx> {
        6 ( 0.00%)          let substs = self.resolve_vars_if_possible(unevaluated.substs);
        .           
        .                   // Postpone the evaluation of constants whose substs depend on inference
        .                   // variables
        .                   if substs.has_infer_types_or_consts() {
        .                       return Err(ErrorHandled::TooGeneric);
        .                   }
        .           
        6 ( 0.00%)          let param_env_erased = self.tcx.erase_regions(param_env);
        .                   let substs_erased = self.tcx.erase_regions(substs);
        .           
        .                   let unevaluated = ty::Unevaluated {
        .                       def: unevaluated.def,
        .                       substs: substs_erased,
       12 ( 0.00%)              promoted: unevaluated.promoted,
        .                   };
        .           
        .                   // The return value is the evaluated value which doesn't contain any reference to inference
        .                   // variables, thus we don't need to substitute back the original values.
       72 ( 0.00%)          self.tcx.const_eval_resolve(param_env_erased, unevaluated, span)
       54 ( 0.00%)      }
        .           
        .               /// If `typ` is a type variable of some kind, resolve it one level
        .               /// (but do not resolve types found in the result). If `typ` is
        .               /// not a type variable, just return it unmodified.
        .               // FIXME(eddyb) inline into `ShallowResolver::visit_ty`.
2,072,096 ( 0.03%)      fn shallow_resolve_ty(&self, typ: Ty<'tcx>) -> Ty<'tcx> {
1,274,374 ( 0.02%)          match *typ.kind() {
        .                       ty::Infer(ty::TyVar(v)) => {
        .                           // Not entirely obvious: if `typ` is a type variable,
        .                           // it can be resolved to an int/float variable, which
        .                           // can then be recursively resolved, hence the
        .                           // recursion. Note though that we prevent type
        .                           // variables from unifying to other type variables
        .                           // directly (though they may be embedded
        .                           // structurally), and we prevent cycles in any case,
        .                           // so this recursion should always be of very limited
        .                           // depth.
        .                           //
        .                           // Note: if these two lines are combined into one we get
        .                           // dynamic borrow errors on `self.inner`.
  647,364 ( 0.01%)                  let known = self.inner.borrow_mut().type_variables().probe(v).known();
        .                           known.map_or(typ, |t| self.shallow_resolve_ty(t))
        .                       }
        .           
   97,192 ( 0.00%)              ty::Infer(ty::IntVar(v)) => self
        .                           .inner
        .                           .borrow_mut()
        .                           .int_unification_table()
        .                           .probe_value(v)
   33,159 ( 0.00%)                  .map(|v| v.to_type(self.tcx))
        .                           .unwrap_or(typ),
        .           
        .                       ty::Infer(ty::FloatVar(v)) => self
        .                           .inner
        .                           .borrow_mut()
        .                           .float_unification_table()
        .                           .probe_value(v)
        .                           .map(|v| v.to_type(self.tcx))
        .                           .unwrap_or(typ),
        .           
        .                       _ => typ,
        .                   }
2,331,108 ( 0.04%)      }
        .           
        .               /// `ty_or_const_infer_var_changed` is equivalent to one of these two:
        .               ///   * `shallow_resolve(ty) != ty` (where `ty.kind = ty::Infer(_)`)
        .               ///   * `shallow_resolve(ct) != ct` (where `ct.kind = ty::ConstKind::Infer(_)`)
        .               ///
        .               /// However, `ty_or_const_infer_var_changed` is more efficient. It's always
        .               /// inlined, despite being large, because it has only two call sites that
        .               /// are extremely hot (both in `traits::fulfill`'s checking of `stalled_on`
-- line 1659 ----------------------------------------
-- line 1662 ----------------------------------------
        .               #[inline(always)]
        .               pub fn ty_or_const_infer_var_changed(&self, infer_var: TyOrConstInferVar<'tcx>) -> bool {
        .                   match infer_var {
        .                       TyOrConstInferVar::Ty(v) => {
        .                           use self::type_variable::TypeVariableValue;
        .           
        .                           // If `inlined_probe` returns a `Known` value, it never equals
        .                           // `ty::Infer(ty::TyVar(v))`.
1,199,771 ( 0.02%)                  match self.inner.borrow_mut().type_variables().inlined_probe(v) {
        .                               TypeVariableValue::Unknown { .. } => false,
        .                               TypeVariableValue::Known { .. } => true,
        .                           }
        .                       }
        .           
        .                       TyOrConstInferVar::TyInt(v) => {
        .                           // If `inlined_probe_value` returns a value it's always a
        .                           // `ty::Int(_)` or `ty::UInt(_)`, which never matches a
        .                           // `ty::Infer(_)`.
   52,642 ( 0.00%)                  self.inner.borrow_mut().int_unification_table().inlined_probe_value(v).is_some()
        .                       }
        .           
        .                       TyOrConstInferVar::TyFloat(v) => {
        .                           // If `probe_value` returns a value it's always a
        .                           // `ty::Float(_)`, which never matches a `ty::Infer(_)`.
        .                           //
        .                           // Not `inlined_probe_value(v)` because this call site is colder.
        .                           self.inner.borrow_mut().float_unification_table().probe_value(v).is_some()
-- line 1688 ----------------------------------------
-- line 1716 ----------------------------------------
        .               /// Equivalent to `ty::ConstKind::Infer(ty::InferConst::Var(_))`.
        .               Const(ConstVid<'tcx>),
        .           }
        .           
        .           impl<'tcx> TyOrConstInferVar<'tcx> {
        .               /// Tries to extract an inference variable from a type or a constant, returns `None`
        .               /// for types other than `ty::Infer(_)` (or `InferTy::Fresh*`) and
        .               /// for constants other than `ty::ConstKind::Infer(_)` (or `InferConst::Fresh`).
   12,727 ( 0.00%)      pub fn maybe_from_generic_arg(arg: GenericArg<'tcx>) -> Option<Self> {
        .                   match arg.unpack() {
        .                       GenericArgKind::Type(ty) => Self::maybe_from_ty(ty),
        .                       GenericArgKind::Const(ct) => Self::maybe_from_const(ct),
        .                       GenericArgKind::Lifetime(_) => None,
        .                   }
   12,727 ( 0.00%)      }
        .           
        .               /// Tries to extract an inference variable from a type, returns `None`
        .               /// for types other than `ty::Infer(_)` (or `InferTy::Fresh*`).
      142 ( 0.00%)      pub fn maybe_from_ty(ty: Ty<'tcx>) -> Option<Self> {
  114,797 ( 0.00%)          match *ty.kind() {
   24,714 ( 0.00%)              ty::Infer(ty::TyVar(v)) => Some(TyOrConstInferVar::Ty(v)),
    1,024 ( 0.00%)              ty::Infer(ty::IntVar(v)) => Some(TyOrConstInferVar::TyInt(v)),
        .                       ty::Infer(ty::FloatVar(v)) => Some(TyOrConstInferVar::TyFloat(v)),
        .                       _ => None,
        .                   }
      142 ( 0.00%)      }
        .           
        .               /// Tries to extract an inference variable from a constant, returns `None`
        .               /// for constants other than `ty::ConstKind::Infer(_)` (or `InferConst::Fresh`).
        .               pub fn maybe_from_const(ct: &'tcx ty::Const<'tcx>) -> Option<Self> {
        .                   match ct.val {
        .                       ty::ConstKind::Infer(InferConst::Var(v)) => Some(TyOrConstInferVar::Const(v)),
        .                       _ => None,
        .                   }
-- line 1749 ----------------------------------------
-- line 1755 ----------------------------------------
        .           }
        .           
        .           impl<'a, 'tcx> TypeFolder<'tcx> for ShallowResolver<'a, 'tcx> {
        .               fn tcx<'b>(&'b self) -> TyCtxt<'tcx> {
        .                   self.infcx.tcx
        .               }
        .           
        .               fn fold_ty(&mut self, ty: Ty<'tcx>) -> Ty<'tcx> {
  374,421 ( 0.01%)          self.infcx.shallow_resolve_ty(ty)
        .               }
        .           
    7,536 ( 0.00%)      fn fold_const(&mut self, ct: &'tcx ty::Const<'tcx>) -> &'tcx ty::Const<'tcx> {
    7,320 ( 0.00%)          if let ty::Const { val: ty::ConstKind::Infer(InferConst::Var(vid)), .. } = ct {
    8,880 ( 0.00%)              self.infcx
        .                           .inner
        .                           .borrow_mut()
        .                           .const_unification_table()
    5,328 ( 0.00%)                  .probe_value(*vid)
        .                           .val
        .                           .known()
        .                           .unwrap_or(ct)
        .                   } else {
        .                       ct
        .                   }
    9,420 ( 0.00%)      }
        .           }
        .           
        .           impl<'tcx> TypeTrace<'tcx> {
        .               pub fn span(&self) -> Span {
        .                   self.cause.span
        .               }
        .           
        .               pub fn types(
-- line 1787 ----------------------------------------
-- line 1818 ----------------------------------------
        .                       CompareImplTypeObligation { span, .. } => span,
        .                   }
        .               }
        .           
        .               pub fn from_obligation_cause<F>(cause: &traits::ObligationCause<'tcx>, default: F) -> Self
        .               where
        .                   F: FnOnce() -> Self,
        .               {
   11,778 ( 0.00%)          match *cause.code() {
    3,401 ( 0.00%)              traits::ObligationCauseCode::ReferenceOutlivesReferent(ref_type) => {
   17,005 ( 0.00%)                  SubregionOrigin::ReferenceOutlivesReferent(ref_type, cause.span)
        .                       }
        .           
        .                       traits::ObligationCauseCode::CompareImplMethodObligation {
        .                           impl_item_def_id,
        .                           trait_item_def_id,
        .                       } => SubregionOrigin::CompareImplMethodObligation {
        .                           span: cause.span,
        .                           impl_item_def_id,
-- line 1836 ----------------------------------------

2,757,864 ( 0.05%)  <counts for unidentified lines in /usr/home/liquid/rust/worktree-benchmarking/compiler/rustc_infer/src/infer/mod.rs>

--------------------------------------------------------------------------------
-- Auto-annotated source: /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs
--------------------------------------------------------------------------------
Ir                  

-- line 111 ----------------------------------------
         .           const EMPTY: u8 = 0b1111_1111;
         .           
         .           /// Control byte value for a deleted bucket.
         .           const DELETED: u8 = 0b1000_0000;
         .           
         .           /// Checks whether a control byte represents a full bucket (top bit is clear).
         .           #[inline]
         .           fn is_full(ctrl: u8) -> bool {
 1,636,980 ( 0.03%)      ctrl & 0x80 == 0
         .           }
         .           
         .           /// Checks whether a control byte represents a special value (top bit is set).
         .           #[inline]
         .           fn is_special(ctrl: u8) -> bool {
         .               ctrl & 0x80 != 0
         .           }
         .           
         .           /// Checks whether a special control value is EMPTY (just check 1 bit).
         .           #[inline]
         .           fn special_is_empty(ctrl: u8) -> bool {
         .               debug_assert!(is_special(ctrl));
   118,902 ( 0.00%)      ctrl & 0x01 != 0
         .           }
         .           
         .           /// Primary hash function, used to select the initial bucket to probe from.
         .           #[inline]
         .           #[allow(clippy::cast_possible_truncation)]
         .           fn h1(hash: u64) -> usize {
         .               // On 32-bit platforms we simply ignore the higher hash bits.
         .               hash as usize
-- line 140 ----------------------------------------
-- line 143 ----------------------------------------
         .           /// Secondary hash function, saved in the low 7 bits of the control byte.
         .           #[inline]
         .           #[allow(clippy::cast_possible_truncation)]
         .           fn h2(hash: u64) -> u8 {
         .               // Grab the top 7 bits of the hash. While the hash is normally a full 64-bit
         .               // value, some hash functions (such as FxHash) produce a usize result
         .               // instead, which means that the top 32 bits are 0 on 32-bit platforms.
         .               let hash_len = usize::min(mem::size_of::<usize>(), mem::size_of::<u64>());
30,045,141 ( 0.51%)      let top7 = hash >> (hash_len * 8 - 7);
         .               (top7 & 0x7f) as u8 // truncation
         .           }
         .           
         .           /// Probe sequence based on triangular numbers, which is guaranteed (since our
         .           /// table size is a power of two) to visit every group of elements exactly once.
         .           ///
         .           /// A triangular probe has us jump by 1 more group every time. So first we
         .           /// jump by 1 group (meaning we just continue our linear scan), then 2 groups
-- line 159 ----------------------------------------
-- line 170 ----------------------------------------
         .               #[inline]
         .               fn move_next(&mut self, bucket_mask: usize) {
         .                   // We should have found an empty bucket by now and ended the probe.
         .                   debug_assert!(
         .                       self.stride <= bucket_mask,
         .                       "Went past end of probe sequence"
         .                   );
         .           
   216,434 ( 0.00%)          self.stride += Group::WIDTH;
   216,434 ( 0.00%)          self.pos += self.stride;
   185,435 ( 0.00%)          self.pos &= bucket_mask;
         .               }
         .           }
         .           
         .           /// Returns the number of buckets needed to hold the given number of items,
         .           /// taking the maximum load factor into account.
         .           ///
         .           /// Returns `None` if an overflow occurs.
         .           // Workaround for emscripten bug emscripten-core/emscripten-fastcomp#258
         .           #[cfg_attr(target_os = "emscripten", inline(never))]
         .           #[cfg_attr(not(target_os = "emscripten"), inline)]
         .           fn capacity_to_buckets(cap: usize) -> Option<usize> {
         .               debug_assert_ne!(cap, 0);
         .           
         .               // For small tables we require at least 1 empty bucket so that lookups are
         .               // guaranteed to terminate if an element doesn't exist in the table.
   118,614 ( 0.00%)      if cap < 8 {
         .                   // We don't bother with a table size of 2 buckets since that can only
         .                   // hold a single element. Instead we skip directly to a 4 bucket table
         .                   // which can hold 3 elements.
   243,275 ( 0.00%)          return Some(if cap < 4 { 4 } else { 8 });
         .               }
         .           
         .               // Otherwise require 1/8 buckets to be empty (87.5% load)
         .               //
         .               // Be careful when modifying this, calculate_layout relies on the
         .               // overflow check here.
    63,912 ( 0.00%)      let adjusted_cap = cap.checked_mul(8)? / 7;
         .           
         .               // Any overflows will have been caught by the checked_mul. Also, any
         .               // rounding errors from the division above will be cleaned up by
         .               // next_power_of_two (which can't overflow because of the previous division).
         .               Some(adjusted_cap.next_power_of_two())
         .           }
         .           
         .           /// Returns the maximum effective capacity for the given bucket mask, taking
         .           /// the maximum load factor into account.
         .           #[inline]
         .           fn bucket_mask_to_capacity(bucket_mask: usize) -> usize {
   298,941 ( 0.01%)      if bucket_mask < 8 {
         .                   // For tables with 1/2/4/8 buckets, we always reserve one empty slot.
         .                   // Keep in mind that the bucket mask is one less than the bucket count.
         .                   bucket_mask
         .               } else {
         .                   // For larger tables we reserve 12.5% of the slots as empty.
    79,206 ( 0.00%)          ((bucket_mask + 1) / 8) * 7
         .               }
         .           }
         .           
         .           /// Helper which allows the max calculation for ctrl_align to be statically computed for each T
         .           /// while keeping the rest of `calculate_layout_for` independent of `T`
         .           #[derive(Copy, Clone)]
         .           struct TableLayout {
         .               size: usize,
-- line 233 ----------------------------------------
-- line 246 ----------------------------------------
         .           
         .               #[inline]
         .               fn calculate_layout_for(self, buckets: usize) -> Option<(Layout, usize)> {
         .                   debug_assert!(buckets.is_power_of_two());
         .           
         .                   let TableLayout { size, ctrl_align } = self;
         .                   // Manual layout calculation since Layout methods are not yet stable.
         .                   let ctrl_offset =
   249,764 ( 0.00%)              size.checked_mul(buckets)?.checked_add(ctrl_align - 1)? & !(ctrl_align - 1);
   328,325 ( 0.01%)          let len = ctrl_offset.checked_add(buckets + Group::WIDTH)?;
         .           
         .                   Some((
         .                       unsafe { Layout::from_size_align_unchecked(len, ctrl_align) },
         .                       ctrl_offset,
         .                   ))
         .               }
         .           }
         .           
-- line 263 ----------------------------------------
-- line 337 ----------------------------------------
         .                   }
         .               }
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub unsafe fn drop(&self) {
         .                   self.as_ptr().drop_in_place();
         .               }
         .               #[inline]
         .               pub unsafe fn read(&self) -> T {
       778 ( 0.00%)          self.as_ptr().read()
         .               }
         .               #[inline]
         .               pub unsafe fn write(&self, val: T) {
         .                   self.as_ptr().write(val);
         .               }
         .               #[inline]
         .               pub unsafe fn as_ref<'a>(&self) -> &'a T {
         .                   &*self.as_ptr()
-- line 353 ----------------------------------------
-- line 422 ----------------------------------------
         .               /// Creates a new empty hash table without allocating any memory, using the
         .               /// given allocator.
         .               ///
         .               /// In effect this returns a table with exactly 1 bucket. However we can
         .               /// leave the data pointer dangling since that bucket is never written to
         .               /// due to our load factor forcing us to always have at least 1 free bucket.
         .               #[inline]
         .               pub fn new_in(alloc: A) -> Self {
     1,074 ( 0.00%)          Self {
         .                       table: RawTableInner::new_in(alloc),
         .                       marker: PhantomData,
         .                   }
         .               }
         .           
         .               /// Allocates a new hash table with the given number of buckets.
         .               ///
         .               /// The control bytes are left uninitialized.
-- line 438 ----------------------------------------
-- line 440 ----------------------------------------
         .               unsafe fn new_uninitialized(
         .                   alloc: A,
         .                   buckets: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
         .                   debug_assert!(buckets.is_power_of_two());
         .           
         .                   Ok(Self {
       280 ( 0.00%)              table: RawTableInner::new_uninitialized(
         .                           alloc,
         .                           TableLayout::new::<T>(),
         .                           buckets,
         .                           fallibility,
         .                       )?,
         .                       marker: PhantomData,
         .                   })
         .               }
-- line 456 ----------------------------------------
-- line 458 ----------------------------------------
         .               /// Attempts to allocate a new hash table with at least enough capacity
         .               /// for inserting the given number of elements without reallocating.
         .               fn fallible_with_capacity(
         .                   alloc: A,
         .                   capacity: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
         .                   Ok(Self {
    12,294 ( 0.00%)              table: RawTableInner::fallible_with_capacity(
         .                           alloc,
         .                           TableLayout::new::<T>(),
         .                           capacity,
         .                           fallibility,
         .                       )?,
         .                       marker: PhantomData,
         .                   })
         .               }
-- line 474 ----------------------------------------
-- line 527 ----------------------------------------
         .                   debug_assert_ne!(self.table.bucket_mask, 0);
         .                   debug_assert!(index < self.buckets());
         .                   Bucket::from_base_index(self.data_end(), index)
         .               }
         .           
         .               /// Erases an element from the table without dropping it.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[deprecated(since = "0.8.1", note = "use erase or remove instead")]
    26,613 ( 0.00%)      pub unsafe fn erase_no_drop(&mut self, item: &Bucket<T>) {
    26,613 ( 0.00%)          let index = self.bucket_index(item);
         .                   self.table.erase(index);
    53,226 ( 0.00%)      }
         .           
         .               /// Erases an element from the table, dropping it in place.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[allow(clippy::needless_pass_by_value)]
         .               #[allow(deprecated)]
         .               pub unsafe fn erase(&mut self, item: Bucket<T>) {
         .                   // Erase the element from the table first since drop might panic.
    25,178 ( 0.00%)          self.erase_no_drop(&item);
         .                   item.drop();
         .               }
         .           
         .               /// Finds and erases an element from the table, dropping it in place.
         .               /// Returns true if an element was found.
         .               #[cfg(feature = "raw")]
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn erase_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> bool {
-- line 554 ----------------------------------------
-- line 563 ----------------------------------------
         .                   }
         .               }
         .           
         .               /// Removes an element from the table, returning it.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[allow(clippy::needless_pass_by_value)]
         .               #[allow(deprecated)]
         .               pub unsafe fn remove(&mut self, item: Bucket<T>) -> T {
    28,048 ( 0.00%)          self.erase_no_drop(&item);
       132 ( 0.00%)          item.read()
         .               }
         .           
         .               /// Finds and removes an element from the table, returning it.
         .               #[cfg_attr(feature = "inline-more", inline)]
   600,158 ( 0.01%)      pub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T> {
         .                   // Avoid `Option::map` because it bloats LLVM IR.
     1,492 ( 0.00%)          match self.find(hash, eq) {
     9,622 ( 0.00%)              Some(bucket) => Some(unsafe { self.remove(bucket) }),
   148,261 ( 0.00%)              None => None,
         .                   }
   807,392 ( 0.01%)      }
         .           
         .               /// Marks all table buckets as empty without dropping their contents.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn clear_no_drop(&mut self) {
         .                   self.table.clear_no_drop();
         .               }
         .           
         .               /// Removes all elements from the table without freeing the backing memory.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn clear(&mut self) {
         .                   // Ensure that the table is reset even if one of the drops panic
         .                   let mut self_ = guard(self, |self_| self_.clear_no_drop());
         .                   unsafe {
         1 ( 0.00%)              self_.drop_elements();
         .                   }
         .               }
         .           
         7 ( 0.00%)      unsafe fn drop_elements(&mut self) {
    14,206 ( 0.00%)          if mem::needs_drop::<T>() && !self.is_empty() {
         .                       for item in self.iter() {
         .                           item.drop();
         .                       }
         .                   }
         8 ( 0.00%)      }
         .           
         .               /// Shrinks the table to fit `max(self.len(), min_size)` elements.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64) {
         .                   // Calculate the minimal number of elements that we need to reserve
         .                   // space for.
         .                   let min_size = usize::max(self.table.items, min_size);
         .                   if min_size == 0 {
-- line 615 ----------------------------------------
-- line 642 ----------------------------------------
         .                       }
         .                   }
         .               }
         .           
         .               /// Ensures that at least `additional` items can be inserted into the table
         .               /// without reallocation.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64) {
   344,147 ( 0.01%)          if additional > self.table.growth_left {
         .                       // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.
   221,477 ( 0.00%)              if self
         .                           .reserve_rehash(additional, hasher, Fallibility::Infallible)
         .                           .is_err()
         .                       {
         .                           unsafe { hint::unreachable_unchecked() }
         .                       }
         .                   }
         .               }
         .           
-- line 660 ----------------------------------------
-- line 671 ----------------------------------------
         .                   } else {
         .                       Ok(())
         .                   }
         .               }
         .           
         .               /// Out-of-line slow path for `reserve` and `try_reserve`.
         .               #[cold]
         .               #[inline(never)]
   466,506 ( 0.01%)      fn reserve_rehash(
         .                   &mut self,
         .                   additional: usize,
         .                   hasher: impl Fn(&T) -> u64,
         .                   fallibility: Fallibility,
         .               ) -> Result<(), TryReserveError> {
         .                   unsafe {
         .                       self.table.reserve_rehash_inner(
         .                           additional,
-- line 687 ----------------------------------------
-- line 690 ----------------------------------------
         .                           TableLayout::new::<T>(),
         .                           if mem::needs_drop::<T>() {
         .                               Some(mem::transmute(ptr::drop_in_place::<T> as unsafe fn(*mut T)))
         .                           } else {
         .                               None
         .                           },
         .                       )
         .                   }
   367,120 ( 0.01%)      }
         .           
         .               /// Allocates a new table of a different size and moves the contents of the
         .               /// current table into it.
         .               fn resize(
         .                   &mut self,
         .                   capacity: usize,
         .                   hasher: impl Fn(&T) -> u64,
         .                   fallibility: Fallibility,
-- line 706 ----------------------------------------
-- line 714 ----------------------------------------
         .                       )
         .                   }
         .               }
         .           
         .               /// Inserts a new element into the table, and returns its raw bucket.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg_attr(feature = "inline-more", inline)]
 2,601,458 ( 0.04%)      pub fn insert(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> Bucket<T> {
         .                   unsafe {
         .                       let mut index = self.table.find_insert_slot(hash);
         .           
         .                       // We can avoid growing the table once we have reached our load
         .                       // factor if we are replacing a tombstone. This works since the
         .                       // number of EMPTY slots does not change in this case.
     3,843 ( 0.00%)              let old_ctrl = *self.table.ctrl(index);
 1,671,253 ( 0.03%)              if unlikely(self.table.growth_left == 0 && special_is_empty(old_ctrl)) {
         .                           self.reserve(1, hasher);
         .                           index = self.table.find_insert_slot(hash);
         .                       }
         .           
         .                       self.table.record_item_insert_at(index, old_ctrl, hash);
         .           
         .                       let bucket = self.bucket(index);
         4 ( 0.00%)              bucket.write(value);
         .                       bucket
         .                   }
 1,903,011 ( 0.03%)      }
         .           
         .               /// Attempts to insert a new element without growing the table and return its raw bucket.
         .               ///
         .               /// Returns an `Err` containing the given element if inserting it would require growing the
         .               /// table.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg(feature = "raw")]
-- line 749 ----------------------------------------
-- line 760 ----------------------------------------
         .                       }
         .                   }
         .               }
         .           
         .               /// Inserts a new element into the table, and returns a mutable reference to it.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg_attr(feature = "inline-more", inline)]
   565,112 ( 0.01%)      pub fn insert_entry(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> &mut T {
        46 ( 0.00%)          unsafe { self.insert(hash, value, hasher).as_mut() }
   423,834 ( 0.01%)      }
         .           
         .               /// Inserts a new element into the table, without growing the table.
         .               ///
         .               /// There must be enough space in the table to insert the new element.
         .               ///
         .               /// This does not check if the given element already exists in the table.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               #[cfg(any(feature = "raw", feature = "rustc-internal-api"))]
       505 ( 0.00%)      pub unsafe fn insert_no_grow(&mut self, hash: u64, value: T) -> Bucket<T> {
   329,938 ( 0.01%)          let (index, old_ctrl) = self.table.prepare_insert_slot(hash);
    26,793 ( 0.00%)          let bucket = self.table.bucket(index);
         .           
         .                   // If we are replacing a DELETED entry then we don't need to update
         .                   // the load counter.
   667,235 ( 0.01%)          self.table.growth_left -= special_is_empty(old_ctrl) as usize;
         .           
         .                   bucket.write(value);
   555,083 ( 0.01%)          self.table.items += 1;
         .                   bucket
     1,000 ( 0.00%)      }
         .           
         .               /// Temporary removes a bucket, applying the given function to the removed
         .               /// element and optionally put back the returned value in the same bucket.
         .               ///
         .               /// Returns `true` if the bucket still contains an element
         .               ///
         .               /// This does not check if the given bucket is actually occupied.
         .               #[cfg_attr(feature = "inline-more", inline)]
-- line 798 ----------------------------------------
-- line 813 ----------------------------------------
         .                       true
         .                   } else {
         .                       false
         .                   }
         .               }
         .           
         .               /// Searches for an element in the table.
         .               #[inline]
    16,469 ( 0.00%)      pub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>> {
    10,585 ( 0.00%)          let result = self.table.find_inner(hash, &mut |index| unsafe {
    15,530 ( 0.00%)              eq(self.bucket(index).as_ref())
     6,079 ( 0.00%)          });
         .           
         .                   // Avoid `Option::map` because it bloats LLVM IR.
         .                   match result {
     1,777 ( 0.00%)              Some(index) => Some(unsafe { self.bucket(index) }),
         .                       None => None,
         .                   }
    18,584 ( 0.00%)      }
         .           
         .               /// Gets a reference to an element in the table.
         .               #[inline]
         .               pub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T> {
         .                   // Avoid `Option::map` because it bloats LLVM IR.
    20,564 ( 0.00%)          match self.find(hash, eq) {
         .                       Some(bucket) => Some(unsafe { bucket.as_ref() }),
         .                       None => None,
         .                   }
         .               }
         .           
         .               /// Gets a mutable reference to an element in the table.
         .               #[inline]
       462 ( 0.00%)      pub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T> {
         .                   // Avoid `Option::map` because it bloats LLVM IR.
     8,721 ( 0.00%)          match self.find(hash, eq) {
         .                       Some(bucket) => Some(unsafe { bucket.as_mut() }),
         .                       None => None,
         .                   }
       528 ( 0.00%)      }
         .           
         .               /// Attempts to get mutable references to `N` entries in the table at once.
         .               ///
         .               /// Returns an array of length `N` with the results of each query.
         .               ///
         .               /// At most one mutable reference will be returned to any entry. `None` will be returned if any
         .               /// of the hashes are duplicates. `None` will be returned if the hash is not found.
         .               ///
-- line 859 ----------------------------------------
-- line 920 ----------------------------------------
         .               #[inline]
         .               pub fn len(&self) -> usize {
         .                   self.table.items
         .               }
         .           
         .               /// Returns `true` if the table contains no elements.
         .               #[inline]
         .               pub fn is_empty(&self) -> bool {
   973,315 ( 0.02%)          self.len() == 0
         .               }
         .           
         .               /// Returns the number of buckets in the table.
         .               #[inline]
         .               pub fn buckets(&self) -> usize {
         .                   self.table.bucket_mask + 1
         .               }
         .           
-- line 936 ----------------------------------------
-- line 938 ----------------------------------------
         .               /// the caller to ensure that the `RawTable` outlives the `RawIter`.
         .               /// Because we cannot make the `next` method unsafe on the `RawIter`
         .               /// struct, we have to make the `iter` method unsafe.
         .               #[inline]
         .               pub unsafe fn iter(&self) -> RawIter<T> {
         .                   let data = Bucket::from_base_index(self.data_end(), 0);
         .                   RawIter {
         .                       iter: RawIterRange::new(self.table.ctrl.as_ptr(), data, self.table.buckets()),
   108,863 ( 0.00%)              items: self.table.items,
         .                   }
         .               }
         .           
         .               /// Returns an iterator over occupied buckets that could match a given hash.
         .               ///
         .               /// `RawTable` only stores 7 bits of the hash value, so this iterator may
         .               /// return items that have a hash value different than the one provided. You
         .               /// should always validate the returned values before using them.
-- line 954 ----------------------------------------
-- line 995 ----------------------------------------
         .               /// Iteration starts at the provided iterator's current location.
         .               ///
         .               /// It is up to the caller to ensure that the iterator is valid for this
         .               /// `RawTable` and covers all items that remain in the table.
         .               pub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T, A> {
         .                   debug_assert_eq!(iter.len(), self.len());
         .           
         .                   let alloc = self.table.alloc.clone();
     4,792 ( 0.00%)          let allocation = self.into_allocation();
     3,594 ( 0.00%)          RawIntoIter {
     5,990 ( 0.00%)              iter,
         .                       allocation,
         .                       marker: PhantomData,
         .                       alloc,
         .                   }
         .               }
         .           
         .               /// Converts the table into a raw allocation. The contents of the table
         .               /// should be dropped using a `RawIter` before freeing the allocation.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               pub(crate) fn into_allocation(self) -> Option<(NonNull<u8>, Layout)> {
     1,818 ( 0.00%)          let alloc = if self.table.is_empty_singleton() {
         .                       None
         .                   } else {
         .                       // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.
         .                       let (layout, ctrl_offset) = match calculate_layout::<T>(self.table.buckets()) {
         .                           Some(lco) => lco,
         .                           None => unsafe { hint::unreachable_unchecked() },
         .                       };
         .                       Some((
       298 ( 0.00%)                  unsafe { NonNull::new_unchecked(self.table.ctrl.as_ptr().sub(ctrl_offset)) },
         .                           layout,
         .                       ))
         .                   };
         .                   mem::forget(self);
         .                   alloc
         .               }
         .           }
         .           
-- line 1033 ----------------------------------------
-- line 1042 ----------------------------------------
         .               T: Sync,
         .               A: Sync,
         .           {
         .           }
         .           
         .           impl<A> RawTableInner<A> {
         .               #[inline]
         .               const fn new_in(alloc: A) -> Self {
   616,144 ( 0.01%)          Self {
         .                       // Be careful to cast the entire slice to a raw pointer.
         .                       ctrl: unsafe { NonNull::new_unchecked(Group::static_empty() as *const _ as *mut u8) },
         .                       bucket_mask: 0,
         .                       items: 0,
         .                       growth_left: 0,
         .                       alloc,
         .                   }
         .               }
         .           }
         .           
         .           impl<A: Allocator + Clone> RawTableInner<A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
   465,898 ( 0.01%)      unsafe fn new_uninitialized(
         .                   alloc: A,
         .                   table_layout: TableLayout,
         .                   buckets: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
         .                   debug_assert!(buckets.is_power_of_two());
         .           
         .                   // Avoid `Option::ok_or_else` because it bloats LLVM IR.
-- line 1071 ----------------------------------------
-- line 1078 ----------------------------------------
         .                   // exceed `isize::MAX`. We can skip this check on 64-bit systems since
         .                   // such allocations will never succeed anyways.
         .                   //
         .                   // This mirrors what Vec does in the standard library.
         .                   if mem::size_of::<usize>() < 8 && layout.size() > isize::MAX as usize {
         .                       return Err(fallibility.capacity_overflow());
         .                   }
         .           
   101,532 ( 0.00%)          let ptr: NonNull<u8> = match do_alloc(&alloc, layout) {
         .                       Ok(block) => block.cast(),
         .                       Err(_) => return Err(fallibility.alloc_err(layout)),
         .                   };
         .           
         .                   let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));
   256,764 ( 0.00%)          Ok(Self {
         .                       ctrl,
   102,157 ( 0.00%)              bucket_mask: buckets - 1,
         .                       items: 0,
         .                       growth_left: bucket_mask_to_capacity(buckets - 1),
         .                       alloc,
         .                   })
   339,128 ( 0.01%)      }
         .           
         .               #[inline]
    28,830 ( 0.00%)      fn fallible_with_capacity(
         .                   alloc: A,
         .                   table_layout: TableLayout,
         .                   capacity: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<Self, TryReserveError> {
     7,470 ( 0.00%)          if capacity == 0 {
     5,875 ( 0.00%)              Ok(Self::new_in(alloc))
         .                   } else {
         .                       unsafe {
         .                           let buckets =
         .                               capacity_to_buckets(capacity).ok_or_else(|| fallibility.capacity_overflow())?;
         .           
   211,978 ( 0.00%)                  let result = Self::new_uninitialized(alloc, table_layout, buckets, fallibility)?;
         .                           result.ctrl(0).write_bytes(EMPTY, result.num_ctrl_bytes());
         .           
    14,940 ( 0.00%)                  Ok(result)
         .                       }
         .                   }
    28,830 ( 0.00%)      }
         .           
         .               /// Searches for an empty or deleted bucket which is suitable for inserting
         .               /// a new element and sets the hash for that slot.
         .               ///
         .               /// There must be at least 1 empty bucket in the table.
         .               #[inline]
   118,407 ( 0.00%)      unsafe fn prepare_insert_slot(&self, hash: u64) -> (usize, u8) {
         .                   let index = self.find_insert_slot(hash);
   118,407 ( 0.00%)          let old_ctrl = *self.ctrl(index);
         .                   self.set_ctrl_h2(index, hash);
         .                   (index, old_ctrl)
   236,814 ( 0.00%)      }
         .           
         .               /// Searches for an empty or deleted bucket which is suitable for inserting
         .               /// a new element.
         .               ///
         .               /// There must be at least 1 empty bucket in the table.
         .               #[inline]
         .               fn find_insert_slot(&self, hash: u64) -> usize {
         .                   let mut probe_seq = self.probe_seq(hash);
         .                   loop {
         .                       unsafe {
         .                           let group = Group::load(self.ctrl(probe_seq.pos));
 1,070,979 ( 0.02%)                  if let Some(bit) = group.match_empty_or_deleted().lowest_set_bit() {
 3,125,326 ( 0.05%)                      let result = (probe_seq.pos + bit) & self.bucket_mask;
         .           
         .                               // In tables smaller than the group width, trailing control
         .                               // bytes outside the range of the table are filled with
         .                               // EMPTY entries. These will unfortunately trigger a
         .                               // match, but once masked may point to a full bucket that
         .                               // is already occupied. We detect this situation here and
         .                               // perform a second scan starting at the beginning of the
         .                               // table. This second scan is guaranteed to find an empty
         .                               // slot (due to the load factor) before hitting the trailing
         .                               // control bytes (containing EMPTY).
 1,459,298 ( 0.02%)                      if unlikely(is_full(*self.ctrl(result))) {
         .                                   debug_assert!(self.bucket_mask < Group::WIDTH);
         .                                   debug_assert_ne!(probe_seq.pos, 0);
         .                                   return Group::load_aligned(self.ctrl(0))
         .                                       .match_empty_or_deleted()
         .                                       .lowest_set_bit_nonzero();
         .                               }
         .           
         .                               return result;
-- line 1165 ----------------------------------------
-- line 1171 ----------------------------------------
         .           
         .               /// Searches for an element in the table. This uses dynamic dispatch to reduce the amount of
         .               /// code generated, but it is eliminated by LLVM optimizations.
         .               #[inline]
         .               fn find_inner(&self, hash: u64, eq: &mut dyn FnMut(usize) -> bool) -> Option<usize> {
         .                   let h2_hash = h2(hash);
         .                   let mut probe_seq = self.probe_seq(hash);
         .           
    59,856 ( 0.00%)          loop {
         .                       let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };
         .           
 3,454,592 ( 0.06%)              for bit in group.match_byte(h2_hash) {
 6,550,973 ( 0.11%)                  let index = (probe_seq.pos + bit) & self.bucket_mask;
         .           
 4,185,432 ( 0.07%)                  if likely(eq(index)) {
         .                               return Some(index);
         .                           }
         .                       }
         .           
 1,066,836 ( 0.02%)              if likely(group.match_empty().any_bit_set()) {
         .                           return None;
         .                       }
         .           
         .                       probe_seq.move_next(self.bucket_mask);
         .                   }
         .               }
         .           
         .               #[allow(clippy::mut_mut)]
-- line 1198 ----------------------------------------
-- line 1225 ----------------------------------------
         .                   Bucket::from_base_index(self.data_end(), index)
         .               }
         .           
         .               #[inline]
         .               unsafe fn bucket_ptr(&self, index: usize, size_of: usize) -> *mut u8 {
         .                   debug_assert_ne!(self.bucket_mask, 0);
         .                   debug_assert!(index < self.buckets());
         .                   let base: *mut u8 = self.data_end().as_ptr();
 3,827,872 ( 0.06%)          base.sub((index + 1) * size_of)
         .               }
         .           
         .               #[inline]
         .               unsafe fn data_end<T>(&self) -> NonNull<T> {
         .                   NonNull::new_unchecked(self.ctrl.as_ptr().cast())
         .               }
         .           
         .               /// Returns an iterator-like object for a probe sequence on the table.
         .               ///
         .               /// This iterator never terminates, but is guaranteed to visit each bucket
         .               /// group exactly once. The loop using `probe_seq` must terminate upon
         .               /// reaching a group containing an empty bucket.
         .               #[inline]
         .               fn probe_seq(&self, hash: u64) -> ProbeSeq {
         .                   ProbeSeq {
19,448,648 ( 0.33%)              pos: h1(hash) & self.bucket_mask,
         .                       stride: 0,
         .                   }
         .               }
         .           
         .               /// Returns the index of a bucket for which a value must be inserted if there is enough rooom
         .               /// in the table, otherwise returns error
         .               #[cfg(feature = "raw")]
         .               #[inline]
-- line 1257 ----------------------------------------
-- line 1263 ----------------------------------------
         .                   } else {
         .                       self.record_item_insert_at(index, old_ctrl, hash);
         .                       Ok(index)
         .                   }
         .               }
         .           
         .               #[inline]
         .               unsafe fn record_item_insert_at(&mut self, index: usize, old_ctrl: u8, hash: u64) {
 2,088,387 ( 0.04%)          self.growth_left -= special_is_empty(old_ctrl) as usize;
         .                   self.set_ctrl_h2(index, hash);
 1,670,688 ( 0.03%)          self.items += 1;
         .               }
         .           
         .               #[inline]
         .               fn is_in_same_group(&self, i: usize, new_i: usize, hash: u64) -> bool {
         .                   let probe_seq_pos = self.probe_seq(hash).pos;
         .                   let probe_index =
         .                       |pos: usize| (pos.wrapping_sub(probe_seq_pos) & self.bucket_mask) / Group::WIDTH;
         .                   probe_index(i) == probe_index(new_i)
-- line 1281 ----------------------------------------
-- line 1312 ----------------------------------------
         .                   // replicate the buckets at the end of the trailing group. For example
         .                   // with 2 buckets and a group size of 4, the control bytes will look
         .                   // like this:
         .                   //
         .                   //     Real    |             Replicated
         .                   // ---------------------------------------------
         .                   // | [A] | [B] | [EMPTY] | [EMPTY] | [A] | [B] |
         .                   // ---------------------------------------------
 3,045,694 ( 0.05%)          let index2 = ((index.wrapping_sub(Group::WIDTH)) & self.bucket_mask) + Group::WIDTH;
         .           
 1,015,058 ( 0.02%)          *self.ctrl(index) = ctrl;
 1,016,345 ( 0.02%)          *self.ctrl(index2) = ctrl;
         .               }
         .           
         .               /// Returns a pointer to a control byte.
         .               #[inline]
         .               unsafe fn ctrl(&self, index: usize) -> *mut u8 {
         .                   debug_assert!(index < self.num_ctrl_bytes());
         .                   self.ctrl.as_ptr().add(index)
         .               }
         .           
         .               #[inline]
         .               fn buckets(&self) -> usize {
   306,617 ( 0.01%)          self.bucket_mask + 1
         .               }
         .           
         .               #[inline]
         .               fn num_ctrl_bytes(&self) -> usize {
   270,251 ( 0.00%)          self.bucket_mask + 1 + Group::WIDTH
         .               }
         .           
         .               #[inline]
         .               fn is_empty_singleton(&self) -> bool {
 1,221,090 ( 0.02%)          self.bucket_mask == 0
         .               }
         .           
         .               #[allow(clippy::mut_mut)]
         .               #[inline]
         .               unsafe fn prepare_resize(
         .                   &self,
         .                   table_layout: TableLayout,
         .                   capacity: usize,
         .                   fallibility: Fallibility,
         .               ) -> Result<crate::scopeguard::ScopeGuard<Self, impl FnMut(&mut Self)>, TryReserveError> {
         .                   debug_assert!(self.items <= capacity);
         .           
         .                   // Allocate and initialize the new table.
     1,722 ( 0.00%)          let mut new_table = RawTableInner::fallible_with_capacity(
         .                       self.alloc.clone(),
         .                       table_layout,
         .                       capacity,
         .                       fallibility,
         .                   )?;
   139,329 ( 0.00%)          new_table.growth_left -= self.items;
         .                   new_table.items = self.items;
         .           
         .                   // The hash function may panic, in which case we simply free the new
         .                   // table without dropping any elements that may have been copied into
         .                   // it.
         .                   //
         .                   // This guard is also used to free the old table on success, see
         .                   // the comment at the bottom of this function.
         .                   Ok(guard(new_table, move |self_| {
    57,391 ( 0.00%)              if !self_.is_empty_singleton() {
         .                           self_.free_buckets(table_layout);
         .                       }
         .                   }))
         .               }
         .           
         .               /// Reserves or rehashes to make room for `additional` more elements.
         .               ///
         .               /// This uses dynamic dispatch to reduce the amount of
-- line 1383 ----------------------------------------
-- line 1388 ----------------------------------------
         .                   &mut self,
         .                   additional: usize,
         .                   hasher: &dyn Fn(&mut Self, usize) -> u64,
         .                   fallibility: Fallibility,
         .                   layout: TableLayout,
         .                   drop: Option<fn(*mut u8)>,
         .               ) -> Result<(), TryReserveError> {
         .                   // Avoid `Option::ok_or_else` because it bloats LLVM IR.
   114,782 ( 0.00%)          let new_items = match self.items.checked_add(additional) {
         .                       Some(new_items) => new_items,
         .                       None => return Err(fallibility.capacity_overflow()),
         .                   };
   114,782 ( 0.00%)          let full_capacity = bucket_mask_to_capacity(self.bucket_mask);
   258,206 ( 0.00%)          if new_items <= full_capacity / 2 {
         .                       // Rehash in-place without re-allocating if we have plenty of spare
         .                       // capacity that is locked up due to DELETED entries.
         .                       self.rehash_in_place(hasher, layout.size, drop);
         .                       Ok(())
         .                   } else {
         .                       // Otherwise, conservatively resize to at least the next size up
         .                       // to avoid churning deletes into frequent rehashes.
         .                       self.resize_inner(
    57,391 ( 0.00%)                  usize::max(new_items, full_capacity + 1),
         .                           hasher,
         .                           fallibility,
         .                           layout,
         .                       )
         .                   }
         .               }
         .           
         .               /// Allocates a new table of a different size and moves the contents of the
-- line 1418 ----------------------------------------
-- line 1424 ----------------------------------------
         .               #[inline(always)]
         .               unsafe fn resize_inner(
         .                   &mut self,
         .                   capacity: usize,
         .                   hasher: &dyn Fn(&mut Self, usize) -> u64,
         .                   fallibility: Fallibility,
         .                   layout: TableLayout,
         .               ) -> Result<(), TryReserveError> {
     4,368 ( 0.00%)          let mut new_table = self.prepare_resize(layout, capacity, fallibility)?;
         .           
         .                   // Copy all elements to the new table.
         .                   for i in 0..self.buckets() {
   595,354 ( 0.01%)              if !is_full(*self.ctrl(i)) {
         .                           continue;
         .                       }
         .           
         .                       // This may panic.
         .                       let hash = hasher(self, i);
         .           
         .                       // We can use a simpler version of insert() here since:
         .                       // - there are no DELETED entries.
-- line 1444 ----------------------------------------
-- line 1454 ----------------------------------------
         .                   }
         .           
         .                   // We successfully copied all elements without panicking. Now replace
         .                   // self with the new table. The old table will have its memory freed but
         .                   // the items will not be dropped (since they have been moved into the
         .                   // new table).
         .                   mem::swap(self, &mut new_table);
         .           
    57,391 ( 0.00%)          Ok(())
         .               }
         .           
         .               /// Rehashes the contents of the table in place (i.e. without changing the
         .               /// allocation).
         .               ///
         .               /// If `hasher` panics then some the table's contents may be lost.
         .               ///
         .               /// This uses dynamic dispatch to reduce the amount of
-- line 1470 ----------------------------------------
-- line 1554 ----------------------------------------
         .               #[inline]
         .               unsafe fn free_buckets(&mut self, table_layout: TableLayout) {
         .                   // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.
         .                   let (layout, ctrl_offset) = match table_layout.calculate_layout_for(self.buckets()) {
         .                       Some(lco) => lco,
         .                       None => hint::unreachable_unchecked(),
         .                   };
         .                   self.alloc.deallocate(
    46,262 ( 0.00%)              NonNull::new_unchecked(self.ctrl.as_ptr().sub(ctrl_offset)),
         .                       layout,
         .                   );
         .               }
         .           
         .               /// Marks all table buckets as empty without dropping their contents.
         .               #[inline]
         .               fn clear_no_drop(&mut self) {
     8,784 ( 0.00%)          if !self.is_empty_singleton() {
         .                       unsafe {
         .                           self.ctrl(0).write_bytes(EMPTY, self.num_ctrl_bytes());
         .                       }
         .                   }
    10,960 ( 0.00%)          self.items = 0;
     8,784 ( 0.00%)          self.growth_left = bucket_mask_to_capacity(self.bucket_mask);
         .               }
         .           
         .               #[inline]
         .               unsafe fn erase(&mut self, index: usize) {
         .                   debug_assert!(is_full(*self.ctrl(index)));
    87,469 ( 0.00%)          let index_before = index.wrapping_sub(Group::WIDTH) & self.bucket_mask;
         .                   let empty_before = Group::load(self.ctrl(index_before)).match_empty();
         .                   let empty_after = Group::load(self.ctrl(index)).match_empty();
         .           
         .                   // If we are inside a continuous block of Group::WIDTH full or deleted
         .                   // cells then a probe window may have seen a full block when trying to
         .                   // insert. We therefore need to keep that block non-empty so that
         .                   // lookups will continue searching to the next probe window.
         .                   //
         .                   // Note that in this context `leading_zeros` refers to the bytes at the
         .                   // end of a group, while `trailing_zeros` refers to the bytes at the
         .                   // beginning of a group.
   349,876 ( 0.01%)          let ctrl = if empty_before.leading_zeros() + empty_after.trailing_zeros() >= Group::WIDTH {
         .                       DELETED
         .                   } else {
   425,905 ( 0.01%)              self.growth_left += 1;
         .                       EMPTY
         .                   };
         .                   self.set_ctrl(index, ctrl);
   349,876 ( 0.01%)          self.items -= 1;
         .               }
         .           }
         .           
         .           impl<T: Clone, A: Allocator + Clone> Clone for RawTable<T, A> {
     2,880 ( 0.00%)      fn clone(&self) -> Self {
       417 ( 0.00%)          if self.table.is_empty_singleton() {
         .                       Self::new_in(self.table.alloc.clone())
         .                   } else {
         .                       unsafe {
         .                           let mut new_table = ManuallyDrop::new(
         .                               // Avoid `Result::ok_or_else` because it bloats LLVM IR.
         .                               match Self::new_uninitialized(
         .                                   self.table.alloc.clone(),
         .                                   self.table.buckets(),
-- line 1615 ----------------------------------------
-- line 1624 ----------------------------------------
         .                               // We need to free the memory allocated for the new table.
         .                               new_table.free_buckets();
         .                           });
         .           
         .                           // Return the newly created table.
         .                           ManuallyDrop::into_inner(new_table)
         .                       }
         .                   }
     3,240 ( 0.00%)      }
         .           
         .               fn clone_from(&mut self, source: &Self) {
         .                   if source.table.is_empty_singleton() {
         .                       *self = Self::new_in(self.table.alloc.clone());
         .                   } else {
         .                       unsafe {
         .                           // First, drop all our elements without clearing the control bytes.
         .                           self.drop_elements();
-- line 1640 ----------------------------------------
-- line 1687 ----------------------------------------
         .                       .table
         .                       .ctrl(0)
         .                       .copy_to_nonoverlapping(self.table.ctrl(0), self.table.num_ctrl_bytes());
         .                   source
         .                       .data_start()
         .                       .copy_to_nonoverlapping(self.data_start(), self.table.buckets());
         .           
         .                   self.table.items = source.table.items;
       112 ( 0.00%)          self.table.growth_left = source.table.growth_left;
         .               }
         .           }
         .           
         .           impl<T: Clone, A: Allocator + Clone> RawTable<T, A> {
         .               /// Common code for clone and clone_from. Assumes `self.buckets() == source.buckets()`.
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               unsafe fn clone_from_impl(&mut self, source: &Self, mut on_panic: impl FnMut(&mut Self)) {
         .                   // Copy the control bytes unchanged. We do this in a single pass
-- line 1703 ----------------------------------------
-- line 1790 ----------------------------------------
         .               fn default() -> Self {
         .                   Self::new_in(Default::default())
         .               }
         .           }
         .           
         .           #[cfg(feature = "nightly")]
         .           unsafe impl<#[may_dangle] T, A: Allocator + Clone> Drop for RawTable<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
   470,689 ( 0.01%)      fn drop(&mut self) {
   521,922 ( 0.01%)          if !self.table.is_empty_singleton() {
         .                       unsafe {
         .                           self.drop_elements();
         .                           self.free_buckets();
         .                       }
         .                   }
   487,806 ( 0.01%)      }
         .           }
         .           #[cfg(not(feature = "nightly"))]
         .           impl<T, A: Allocator + Clone> Drop for RawTable<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn drop(&mut self) {
         .                   if !self.table.is_empty_singleton() {
         .                       unsafe {
         .                           self.drop_elements();
-- line 1813 ----------------------------------------
-- line 1817 ----------------------------------------
         .               }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> IntoIterator for RawTable<T, A> {
         .               type Item = T;
         .               type IntoIter = RawIntoIter<T, A>;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
     4,792 ( 0.00%)      fn into_iter(self) -> RawIntoIter<T, A> {
         .                   unsafe {
         .                       let iter = self.iter();
         .                       self.into_iter_from(iter)
         .                   }
     5,990 ( 0.00%)      }
         .           }
         .           
         .           /// Iterator over a sub-range of a table. Unlike `RawIter` this iterator does
         .           /// not track an item count.
         .           pub(crate) struct RawIterRange<T> {
         .               // Mask of full buckets in the current group. Bits are cleared from this
         .               // mask as each element is processed.
         .               current_group: BitMask,
-- line 1838 ----------------------------------------
-- line 1934 ----------------------------------------
         .           
         .           impl<T> Iterator for RawIterRange<T> {
         .               type Item = Bucket<T>;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn next(&mut self) -> Option<Bucket<T>> {
         .                   unsafe {
         .                       loop {
   237,163 ( 0.00%)                  if let Some(index) = self.current_group.lowest_set_bit() {
    29,720 ( 0.00%)                      self.current_group = self.current_group.remove_lowest_bit();
    48,249 ( 0.00%)                      return Some(self.data.next_n(index));
         .                           }
         .           
   222,157 ( 0.00%)                  if self.next_ctrl >= self.end {
         .                               return None;
         .                           }
         .           
         .                           // We might read past self.end up to the next group boundary,
         .                           // but this is fine because it only occurs on tables smaller
         .                           // than the group size where the trailing control bytes are all
         .                           // EMPTY. On larger tables self.end is guaranteed to be aligned
         .                           // to the group size (since tables are power-of-two sized).
     3,601 ( 0.00%)                  self.current_group = Group::load_aligned(self.next_ctrl).match_full();
     4,840 ( 0.00%)                  self.data = self.data.next_n(Group::WIDTH);
     5,346 ( 0.00%)                  self.next_ctrl = self.next_ctrl.add(Group::WIDTH);
         .                       }
         .                   }
         .               }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         .                   // We don't have an item count, so just guess based on the range size.
         .                   (
-- line 1966 ----------------------------------------
-- line 2102 ----------------------------------------
         .                           }
         .                       } else {
         .                           // We must have already iterated past the removed item.
         .                       }
         .                   }
         .               }
         .           
         .               unsafe fn drop_elements(&mut self) {
       935 ( 0.00%)          if mem::needs_drop::<T>() && self.len() != 0 {
         .                       for item in self {
         .                           item.drop();
         .                       }
         .                   }
         .               }
         .           }
         .           
         .           impl<T> Clone for RawIter<T> {
-- line 2118 ----------------------------------------
-- line 2124 ----------------------------------------
         .                   }
         .               }
         .           }
         .           
         .           impl<T> Iterator for RawIter<T> {
         .               type Item = Bucket<T>;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
    33,976 ( 0.00%)      fn next(&mut self) -> Option<Bucket<T>> {
    93,340 ( 0.00%)          if let Some(b) = self.iter.next() {
   409,875 ( 0.01%)              self.items -= 1;
         .                       Some(b)
         .                   } else {
         .                       // We don't check against items == 0 here to allow the
         .                       // compiler to optimize away the item count entirely if the
         .                       // iterator length is never queried.
         .                       debug_assert_eq!(self.items, 0);
         .                       None
         .                   }
    67,952 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         .                   (self.items, Some(self.items))
         .               }
         .           }
         .           
         .           impl<T> ExactSizeIterator for RawIter<T> {}
-- line 2151 ----------------------------------------
-- line 2177 ----------------------------------------
         .               T: Sync,
         .               A: Sync,
         .           {
         .           }
         .           
         .           #[cfg(feature = "nightly")]
         .           unsafe impl<#[may_dangle] T, A: Allocator + Clone> Drop for RawIntoIter<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
     1,410 ( 0.00%)      fn drop(&mut self) {
         .                   unsafe {
         .                       // Drop all remaining elements
         .                       self.iter.drop_elements();
         .           
         .                       // Free the table
     8,616 ( 0.00%)              if let Some((ptr, layout)) = self.allocation {
         .                           self.alloc.deallocate(ptr, layout);
         .                       }
         .                   }
       168 ( 0.00%)      }
         .           }
         .           #[cfg(not(feature = "nightly"))]
         .           impl<T, A: Allocator + Clone> Drop for RawIntoIter<T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn drop(&mut self) {
         .                   unsafe {
         .                       // Drop all remaining elements
         .                       self.iter.drop_elements();
-- line 2203 ----------------------------------------
-- line 2209 ----------------------------------------
         .                   }
         .               }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> Iterator for RawIntoIter<T, A> {
         .               type Item = T;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
       740 ( 0.00%)      fn next(&mut self) -> Option<T> {
       423 ( 0.00%)          unsafe { Some(self.iter.next()?.read()) }
     1,757 ( 0.00%)      }
         .           
         .               #[inline]
         .               fn size_hint(&self) -> (usize, Option<usize>) {
         8 ( 0.00%)          self.iter.size_hint()
         .               }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> ExactSizeIterator for RawIntoIter<T, A> {}
         .           impl<T, A: Allocator + Clone> FusedIterator for RawIntoIter<T, A> {}
         .           
         .           /// Iterator which consumes elements without freeing the table storage.
         .           pub struct RawDrain<'a, T, A: Allocator + Clone = Global> {
-- line 2231 ----------------------------------------
-- line 2259 ----------------------------------------
         .           where
         .               T: Sync,
         .               A: Sync,
         .           {
         .           }
         .           
         .           impl<T, A: Allocator + Clone> Drop for RawDrain<'_, T, A> {
         .               #[cfg_attr(feature = "inline-more", inline)]
     1,016 ( 0.00%)      fn drop(&mut self) {
         .                   unsafe {
         .                       // Drop all remaining elements. Note that this may panic.
         .                       self.iter.drop_elements();
         .           
         .                       // Reset the contents of the table now that all elements have been
         .                       // dropped.
         .                       self.table.clear_no_drop();
         .           
         .                       // Move the now empty table back to its original location.
       127 ( 0.00%)              self.orig_table
         .                           .as_ptr()
         .                           .copy_from_nonoverlapping(&*self.table, 1);
         .                   }
     1,016 ( 0.00%)      }
         .           }
         .           
         .           impl<T, A: Allocator + Clone> Iterator for RawDrain<'_, T, A> {
         .               type Item = T;
         .           
         .               #[cfg_attr(feature = "inline-more", inline)]
         .               fn next(&mut self) -> Option<T> {
         .                   unsafe {
-- line 2289 ----------------------------------------

10,657,391 ( 0.18%)  <counts for unidentified lines in /usr/home/liquid/.cargo/registry/src/github.com-1ecc6299db9ec823/hashbrown-0.12.0/src/raw/mod.rs>

--------------------------------------------------------------------------------
The following files chosen for auto-annotation could not be found:
--------------------------------------------------------------------------------
  ./elf/dl-lookup.c
  ./malloc/malloc.c
  ./string/../sysdeps/x86_64/multiarch/memcmp-avx2-movbe.S
  ./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
  ./string/../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S
  /tmp/gcc-build/x86_64-unknown-linux-gnu/libstdc++-v3/libsupc++/../../../../gcc-5.5.0/libstdc++-v3/libsupc++/new_op.cc

--------------------------------------------------------------------------------
Ir                   
--------------------------------------------------------------------------------
149,710,483 ( 2.52%)  events annotated

